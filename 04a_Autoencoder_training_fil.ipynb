{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lMElGYUIljFH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import glob\n",
    "import sklearn \n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Activation, Dense, LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data import\n",
    "wt_filtered =glob.glob('wt_filtered*50.lccdata')\n",
    "\n",
    "# filtered wt LCC data import\n",
    "wt_f_var_names = ['wt_3f', 'wt_12f', 'wt_20f']\n",
    "    \n",
    "for var, file in zip(wt_f_var_names, wt_filtered):\n",
    "    globals()[var] = pd.read_csv(file,sep='\\t').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "# filtered mutant LCC data import\n",
    "\n",
    "D132H_filtered =glob.glob('D132H_filtered*_50.lccdata')\n",
    "\n",
    "D132H_f_var_names = ['D132H_3f', 'D132H_12f', 'D132H_20f']\n",
    "    \n",
    "for var, file in zip(D132H_f_var_names, D132H_filtered):\n",
    "    globals()[var] = pd.read_csv(file, sep='\\t').drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT for window size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>19</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.3049</td>\n",
       "      <td>30.7508</td>\n",
       "      <td>24.7567</td>\n",
       "      <td>23.1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.4792</td>\n",
       "      <td>28.1640</td>\n",
       "      <td>23.8363</td>\n",
       "      <td>23.2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.5636</td>\n",
       "      <td>30.2936</td>\n",
       "      <td>24.8655</td>\n",
       "      <td>23.4604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.4733</td>\n",
       "      <td>29.5746</td>\n",
       "      <td>21.3842</td>\n",
       "      <td>22.6630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0147</td>\n",
       "      <td>27.5496</td>\n",
       "      <td>23.8249</td>\n",
       "      <td>22.3185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>14.7258</td>\n",
       "      <td>8.4287</td>\n",
       "      <td>24.3534</td>\n",
       "      <td>22.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>15.5602</td>\n",
       "      <td>7.1757</td>\n",
       "      <td>24.9417</td>\n",
       "      <td>24.1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>15.4532</td>\n",
       "      <td>7.1490</td>\n",
       "      <td>23.8513</td>\n",
       "      <td>27.4276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>15.1188</td>\n",
       "      <td>7.5725</td>\n",
       "      <td>25.4096</td>\n",
       "      <td>26.8701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>15.4409</td>\n",
       "      <td>7.2976</td>\n",
       "      <td>26.2683</td>\n",
       "      <td>24.6460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            16       19       29       30\n",
       "0      17.3049  30.7508  24.7567  23.1634\n",
       "1      22.4792  28.1640  23.8363  23.2798\n",
       "2      25.5636  30.2936  24.8655  23.4604\n",
       "3      26.4733  29.5746  21.3842  22.6630\n",
       "4      24.0147  27.5496  23.8249  22.3185\n",
       "...        ...      ...      ...      ...\n",
       "39995  14.7258   8.4287  24.3534  22.6400\n",
       "39996  15.5602   7.1757  24.9417  24.1508\n",
       "39997  15.4532   7.1490  23.8513  27.4276\n",
       "39998  15.1188   7.5725  25.4096  26.8701\n",
       "39999  15.4409   7.2976  26.2683  24.6460\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------\n",
      "D132H for window size = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>20</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.7095</td>\n",
       "      <td>46.4135</td>\n",
       "      <td>38.2248</td>\n",
       "      <td>42.8092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.4667</td>\n",
       "      <td>46.4414</td>\n",
       "      <td>34.7611</td>\n",
       "      <td>41.1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.7000</td>\n",
       "      <td>47.2786</td>\n",
       "      <td>30.2701</td>\n",
       "      <td>34.9940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.4481</td>\n",
       "      <td>44.8032</td>\n",
       "      <td>33.4548</td>\n",
       "      <td>38.2540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.1022</td>\n",
       "      <td>44.0575</td>\n",
       "      <td>33.0935</td>\n",
       "      <td>39.0292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>6.9673</td>\n",
       "      <td>28.1672</td>\n",
       "      <td>15.1968</td>\n",
       "      <td>12.9232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>7.2460</td>\n",
       "      <td>27.9588</td>\n",
       "      <td>15.2995</td>\n",
       "      <td>12.7038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>7.3270</td>\n",
       "      <td>27.8777</td>\n",
       "      <td>16.1102</td>\n",
       "      <td>13.1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>7.2212</td>\n",
       "      <td>28.3756</td>\n",
       "      <td>16.5540</td>\n",
       "      <td>13.4088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>7.5046</td>\n",
       "      <td>27.6225</td>\n",
       "      <td>15.5801</td>\n",
       "      <td>13.1174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             7       20       26       27\n",
       "0      18.7095  46.4135  38.2248  42.8092\n",
       "1      13.4667  46.4414  34.7611  41.1095\n",
       "2      15.7000  47.2786  30.2701  34.9940\n",
       "3      15.4481  44.8032  33.4548  38.2540\n",
       "4      20.1022  44.0575  33.0935  39.0292\n",
       "...        ...      ...      ...      ...\n",
       "39995   6.9673  28.1672  15.1968  12.9232\n",
       "39996   7.2460  27.9588  15.2995  12.7038\n",
       "39997   7.3270  27.8777  16.1102  13.1354\n",
       "39998   7.2212  28.3756  16.5540  13.4088\n",
       "39999   7.5046  27.6225  15.5801  13.1174\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of dataset\n",
    "\n",
    "print('WT for window size = 3')\n",
    "display(wt_3f)\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------')\n",
    "print('D132H for window size = 20')\n",
    "display(D132H_20f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concateneate wt and mutant dataframes and rename columns\n",
    "\n",
    "wt_f = pd.concat([wt_3f, wt_12f, wt_20f], axis = 1)\n",
    "    \n",
    "D132H_f = pd.concat([D132H_3f, D132H_12f, D132H_20f], axis = 1)\n",
    "\n",
    "colnames = [*range(0,10)]\n",
    "colnames\n",
    "wt_f.columns = colnames\n",
    "D132H_f.columns = colnames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered wt data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.3049</td>\n",
       "      <td>30.7508</td>\n",
       "      <td>24.7567</td>\n",
       "      <td>23.1634</td>\n",
       "      <td>14.2374</td>\n",
       "      <td>40.1886</td>\n",
       "      <td>6.3249</td>\n",
       "      <td>9.6718</td>\n",
       "      <td>6.0082</td>\n",
       "      <td>9.6574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.4792</td>\n",
       "      <td>28.1640</td>\n",
       "      <td>23.8363</td>\n",
       "      <td>23.2798</td>\n",
       "      <td>14.5602</td>\n",
       "      <td>36.3229</td>\n",
       "      <td>6.3105</td>\n",
       "      <td>10.6216</td>\n",
       "      <td>5.9996</td>\n",
       "      <td>11.2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.5636</td>\n",
       "      <td>30.2936</td>\n",
       "      <td>24.8655</td>\n",
       "      <td>23.4604</td>\n",
       "      <td>17.4329</td>\n",
       "      <td>41.2223</td>\n",
       "      <td>5.7233</td>\n",
       "      <td>11.4243</td>\n",
       "      <td>7.3021</td>\n",
       "      <td>11.5329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.4733</td>\n",
       "      <td>29.5746</td>\n",
       "      <td>21.3842</td>\n",
       "      <td>22.6630</td>\n",
       "      <td>20.1207</td>\n",
       "      <td>39.2809</td>\n",
       "      <td>5.4864</td>\n",
       "      <td>10.7079</td>\n",
       "      <td>6.4156</td>\n",
       "      <td>10.7262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0147</td>\n",
       "      <td>27.5496</td>\n",
       "      <td>23.8249</td>\n",
       "      <td>22.3185</td>\n",
       "      <td>15.6335</td>\n",
       "      <td>38.7009</td>\n",
       "      <td>5.4673</td>\n",
       "      <td>12.0023</td>\n",
       "      <td>6.3573</td>\n",
       "      <td>11.2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>14.7258</td>\n",
       "      <td>8.4287</td>\n",
       "      <td>24.3534</td>\n",
       "      <td>22.6400</td>\n",
       "      <td>16.9755</td>\n",
       "      <td>31.9599</td>\n",
       "      <td>4.9712</td>\n",
       "      <td>8.9677</td>\n",
       "      <td>10.1179</td>\n",
       "      <td>8.9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>15.5602</td>\n",
       "      <td>7.1757</td>\n",
       "      <td>24.9417</td>\n",
       "      <td>24.1508</td>\n",
       "      <td>17.0192</td>\n",
       "      <td>29.9824</td>\n",
       "      <td>4.8021</td>\n",
       "      <td>9.0623</td>\n",
       "      <td>10.1026</td>\n",
       "      <td>8.6752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>15.4532</td>\n",
       "      <td>7.1490</td>\n",
       "      <td>23.8513</td>\n",
       "      <td>27.4276</td>\n",
       "      <td>18.5272</td>\n",
       "      <td>29.4126</td>\n",
       "      <td>5.9590</td>\n",
       "      <td>10.3438</td>\n",
       "      <td>8.6309</td>\n",
       "      <td>9.4556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>15.1188</td>\n",
       "      <td>7.5725</td>\n",
       "      <td>25.4096</td>\n",
       "      <td>26.8701</td>\n",
       "      <td>17.1766</td>\n",
       "      <td>32.6983</td>\n",
       "      <td>4.3996</td>\n",
       "      <td>10.3760</td>\n",
       "      <td>9.5901</td>\n",
       "      <td>9.3513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>15.4409</td>\n",
       "      <td>7.2976</td>\n",
       "      <td>26.2683</td>\n",
       "      <td>24.6460</td>\n",
       "      <td>17.7794</td>\n",
       "      <td>33.5279</td>\n",
       "      <td>5.2675</td>\n",
       "      <td>10.8606</td>\n",
       "      <td>8.6371</td>\n",
       "      <td>9.7884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1        2        3        4        5       6        7  \\\n",
       "0      17.3049  30.7508  24.7567  23.1634  14.2374  40.1886  6.3249   9.6718   \n",
       "1      22.4792  28.1640  23.8363  23.2798  14.5602  36.3229  6.3105  10.6216   \n",
       "2      25.5636  30.2936  24.8655  23.4604  17.4329  41.2223  5.7233  11.4243   \n",
       "3      26.4733  29.5746  21.3842  22.6630  20.1207  39.2809  5.4864  10.7079   \n",
       "4      24.0147  27.5496  23.8249  22.3185  15.6335  38.7009  5.4673  12.0023   \n",
       "...        ...      ...      ...      ...      ...      ...     ...      ...   \n",
       "39995  14.7258   8.4287  24.3534  22.6400  16.9755  31.9599  4.9712   8.9677   \n",
       "39996  15.5602   7.1757  24.9417  24.1508  17.0192  29.9824  4.8021   9.0623   \n",
       "39997  15.4532   7.1490  23.8513  27.4276  18.5272  29.4126  5.9590  10.3438   \n",
       "39998  15.1188   7.5725  25.4096  26.8701  17.1766  32.6983  4.3996  10.3760   \n",
       "39999  15.4409   7.2976  26.2683  24.6460  17.7794  33.5279  5.2675  10.8606   \n",
       "\n",
       "             8        9  \n",
       "0       6.0082   9.6574  \n",
       "1       5.9996  11.2509  \n",
       "2       7.3021  11.5329  \n",
       "3       6.4156  10.7262  \n",
       "4       6.3573  11.2367  \n",
       "...        ...      ...  \n",
       "39995  10.1179   8.9430  \n",
       "39996  10.1026   8.6752  \n",
       "39997   8.6309   9.4556  \n",
       "39998   9.5901   9.3513  \n",
       "39999   8.6371   9.7884  \n",
       "\n",
       "[40000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------\n",
      "Filtered D132H data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.2144</td>\n",
       "      <td>41.6730</td>\n",
       "      <td>36.3674</td>\n",
       "      <td>31.2519</td>\n",
       "      <td>13.4055</td>\n",
       "      <td>41.6856</td>\n",
       "      <td>18.7095</td>\n",
       "      <td>46.4135</td>\n",
       "      <td>38.2248</td>\n",
       "      <td>42.8092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.2545</td>\n",
       "      <td>39.3565</td>\n",
       "      <td>35.5082</td>\n",
       "      <td>29.8643</td>\n",
       "      <td>12.0150</td>\n",
       "      <td>40.2262</td>\n",
       "      <td>13.4667</td>\n",
       "      <td>46.4414</td>\n",
       "      <td>34.7611</td>\n",
       "      <td>41.1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.2448</td>\n",
       "      <td>42.7255</td>\n",
       "      <td>33.4780</td>\n",
       "      <td>30.7351</td>\n",
       "      <td>17.0081</td>\n",
       "      <td>41.7220</td>\n",
       "      <td>15.7000</td>\n",
       "      <td>47.2786</td>\n",
       "      <td>30.2701</td>\n",
       "      <td>34.9940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.1229</td>\n",
       "      <td>42.3124</td>\n",
       "      <td>35.9424</td>\n",
       "      <td>31.0427</td>\n",
       "      <td>15.6520</td>\n",
       "      <td>40.4408</td>\n",
       "      <td>15.4481</td>\n",
       "      <td>44.8032</td>\n",
       "      <td>33.4548</td>\n",
       "      <td>38.2540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.7239</td>\n",
       "      <td>40.8462</td>\n",
       "      <td>34.5238</td>\n",
       "      <td>27.3446</td>\n",
       "      <td>20.7450</td>\n",
       "      <td>38.0932</td>\n",
       "      <td>20.1022</td>\n",
       "      <td>44.0575</td>\n",
       "      <td>33.0935</td>\n",
       "      <td>39.0292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>23.9089</td>\n",
       "      <td>22.5600</td>\n",
       "      <td>12.8804</td>\n",
       "      <td>14.6848</td>\n",
       "      <td>14.0324</td>\n",
       "      <td>23.2605</td>\n",
       "      <td>6.9673</td>\n",
       "      <td>28.1672</td>\n",
       "      <td>15.1968</td>\n",
       "      <td>12.9232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>22.1314</td>\n",
       "      <td>22.9405</td>\n",
       "      <td>13.7161</td>\n",
       "      <td>15.5070</td>\n",
       "      <td>14.9455</td>\n",
       "      <td>22.4160</td>\n",
       "      <td>7.2460</td>\n",
       "      <td>27.9588</td>\n",
       "      <td>15.2995</td>\n",
       "      <td>12.7038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>20.4286</td>\n",
       "      <td>22.6088</td>\n",
       "      <td>13.4875</td>\n",
       "      <td>15.1243</td>\n",
       "      <td>14.0516</td>\n",
       "      <td>22.7481</td>\n",
       "      <td>7.3270</td>\n",
       "      <td>27.8777</td>\n",
       "      <td>16.1102</td>\n",
       "      <td>13.1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>24.2292</td>\n",
       "      <td>22.1429</td>\n",
       "      <td>13.4961</td>\n",
       "      <td>15.4669</td>\n",
       "      <td>14.0350</td>\n",
       "      <td>23.5958</td>\n",
       "      <td>7.2212</td>\n",
       "      <td>28.3756</td>\n",
       "      <td>16.5540</td>\n",
       "      <td>13.4088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>22.6882</td>\n",
       "      <td>21.6749</td>\n",
       "      <td>13.6403</td>\n",
       "      <td>15.3245</td>\n",
       "      <td>14.3382</td>\n",
       "      <td>22.8859</td>\n",
       "      <td>7.5046</td>\n",
       "      <td>27.6225</td>\n",
       "      <td>15.5801</td>\n",
       "      <td>13.1174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1        2        3        4        5        6        7  \\\n",
       "0      32.2144  41.6730  36.3674  31.2519  13.4055  41.6856  18.7095  46.4135   \n",
       "1      32.2545  39.3565  35.5082  29.8643  12.0150  40.2262  13.4667  46.4414   \n",
       "2      30.2448  42.7255  33.4780  30.7351  17.0081  41.7220  15.7000  47.2786   \n",
       "3      31.1229  42.3124  35.9424  31.0427  15.6520  40.4408  15.4481  44.8032   \n",
       "4      32.7239  40.8462  34.5238  27.3446  20.7450  38.0932  20.1022  44.0575   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "39995  23.9089  22.5600  12.8804  14.6848  14.0324  23.2605   6.9673  28.1672   \n",
       "39996  22.1314  22.9405  13.7161  15.5070  14.9455  22.4160   7.2460  27.9588   \n",
       "39997  20.4286  22.6088  13.4875  15.1243  14.0516  22.7481   7.3270  27.8777   \n",
       "39998  24.2292  22.1429  13.4961  15.4669  14.0350  23.5958   7.2212  28.3756   \n",
       "39999  22.6882  21.6749  13.6403  15.3245  14.3382  22.8859   7.5046  27.6225   \n",
       "\n",
       "             8        9  \n",
       "0      38.2248  42.8092  \n",
       "1      34.7611  41.1095  \n",
       "2      30.2701  34.9940  \n",
       "3      33.4548  38.2540  \n",
       "4      33.0935  39.0292  \n",
       "...        ...      ...  \n",
       "39995  15.1968  12.9232  \n",
       "39996  15.2995  12.7038  \n",
       "39997  16.1102  13.1354  \n",
       "39998  16.5540  13.4088  \n",
       "39999  15.5801  13.1174  \n",
       "\n",
       "[40000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of dataset\n",
    "print('Filtered wt data')\n",
    "display(wt_f)\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------')\n",
    "print('Filtered D132H data')\n",
    "display(D132H_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre processing\n",
    "\n",
    "def preprocessing(wt, mutant):\n",
    "    \n",
    "    wt_label = np.zeros(len(wt)) # Set wt labels to 0\n",
    "    \n",
    "    mutant_label = np.ones(len(mutant))\n",
    "    \n",
    "    # Concatenate data frames and label arrays\n",
    "\n",
    "    X_train_full = pd.concat([wt.reset_index(), mutant.reset_index()])\n",
    "    y_train_full = np.concatenate((wt_label, mutant_label))\n",
    "    \n",
    "    #Drop index column and normalise training data\n",
    "    X_train_full = X_train_full.drop(columns = 'index')\n",
    "    \n",
    "    X_train_full= X_train_full.div(100)\n",
    "    \n",
    "    # Separate training and validation sets and print relevant shapes\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, stratify=y_train_full, test_size=0.2)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(X_valid.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_valid.shape)\n",
    "    \n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 10)\n",
      "(16000, 10)\n",
      "(64000,)\n",
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "X_train_f, X_valid_f, y_train_f, y_valid_f = preprocessing(wt_f, D132H_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save shuffled validation datasets (for use in downstream analysis)\n",
    "X_valid_f.to_csv('X_val.csv')\n",
    "\n",
    "y_valid_f_df = pd.DataFrame({'class':y_valid_f})\n",
    "y_valid_f_df.to_csv('y_val_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get autoencoder model\n",
    "def get_ae(train_data, LeReLU_alpha=0.01):\n",
    "    \n",
    "    #Input layer\n",
    "    input_layer = Input(shape=(train_data.shape[1]), name='ae_input')\n",
    "    \n",
    "    encoder = Dense(256, activation=LeakyReLU(alpha=LeReLU_alpha), name='e1')(input_layer)\n",
    "    encoder = Dense(64, activation=LeakyReLU(alpha=LeReLU_alpha), name='e2')(encoder)\n",
    "\n",
    "    encoded = Dense(2, activation=LeakyReLU(alpha=LeReLU_alpha), name='ae_latent')(encoder)\n",
    "    \n",
    "    decoder = Dense(64, activation=LeakyReLU(alpha=LeReLU_alpha), name='d1')(encoded)\n",
    "    decoder = Dense(256, activation=LeakyReLU(alpha=LeReLU_alpha), name='d2')(decoder)\n",
    "\n",
    "    output_layer = Dense(train_data.shape[1], activation=LeakyReLU(alpha=LeReLU_alpha), name='ae_output')(decoder)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ae for filtered data\n",
    "autoencoder = get_ae(X_train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      " d1 (Dense)                  (None, 64)                192       \n",
      "                                                                 \n",
      " d2 (Dense)                  (None, 256)               16640     \n",
      "                                                                 \n",
      " ae_output (Dense)           (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,796\n",
      "Trainable params: 38,796\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print summary of ae model\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "autoencoder.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(learning_rate = 0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 9.7282e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 8.3932e-04 - val_loss: 7.6654e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 7.5513e-04 - val_loss: 7.1825e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 7.1937e-04 - val_loss: 7.0641e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 7.0069e-04 - val_loss: 6.9315e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.8876e-04 - val_loss: 6.8673e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.7891e-04 - val_loss: 6.6477e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.6990e-04 - val_loss: 6.7533e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.6182e-04 - val_loss: 6.7563e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.5015e-04 - val_loss: 6.3932e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.4332e-04 - val_loss: 6.5399e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.4107e-04 - val_loss: 6.3568e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.3891e-04 - val_loss: 6.6434e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.3773e-04 - val_loss: 6.3209e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2371e-04 - val_loss: 6.2789e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2891e-04 - val_loss: 6.2990e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.3426e-04 - val_loss: 6.5502e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.3257e-04 - val_loss: 6.1024e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1980e-04 - val_loss: 6.2254e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2423e-04 - val_loss: 6.0935e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1715e-04 - val_loss: 6.2806e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2462e-04 - val_loss: 5.9305e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0881e-04 - val_loss: 5.8087e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1518e-04 - val_loss: 5.9004e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1370e-04 - val_loss: 5.8502e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0066e-04 - val_loss: 5.8587e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0479e-04 - val_loss: 5.8399e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0073e-04 - val_loss: 5.9975e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0969e-04 - val_loss: 5.9124e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9827e-04 - val_loss: 5.9614e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9376e-04 - val_loss: 5.7090e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8980e-04 - val_loss: 5.9160e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0787e-04 - val_loss: 5.8871e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1539e-04 - val_loss: 6.9939e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.7330e-04 - val_loss: 6.8149e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.5179e-04 - val_loss: 6.3041e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0273e-04 - val_loss: 5.9538e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0799e-04 - val_loss: 6.0627e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0197e-04 - val_loss: 5.7916e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8562e-04 - val_loss: 5.9002e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8120e-04 - val_loss: 5.7718e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7960e-04 - val_loss: 5.8636e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8187e-04 - val_loss: 5.9298e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7879e-04 - val_loss: 5.8222e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8369e-04 - val_loss: 5.7263e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8247e-04 - val_loss: 6.1301e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8038e-04 - val_loss: 5.9943e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7866e-04 - val_loss: 5.5752e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7640e-04 - val_loss: 5.7981e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8466e-04 - val_loss: 6.3397e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9122e-04 - val_loss: 5.6404e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6970e-04 - val_loss: 5.6661e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7716e-04 - val_loss: 5.6192e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7987e-04 - val_loss: 5.8547e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7331e-04 - val_loss: 6.0186e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7643e-04 - val_loss: 5.8156e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7241e-04 - val_loss: 5.5235e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0596e-04 - val_loss: 5.8275e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.4760e-04 - val_loss: 7.0236e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.3401e-04 - val_loss: 6.2582e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1402e-04 - val_loss: 6.0414e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1153e-04 - val_loss: 6.0137e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0254e-04 - val_loss: 6.0685e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0914e-04 - val_loss: 6.0113e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9294e-04 - val_loss: 5.9533e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9987e-04 - val_loss: 6.1515e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9451e-04 - val_loss: 5.8197e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9562e-04 - val_loss: 5.8296e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8195e-04 - val_loss: 5.9468e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8469e-04 - val_loss: 5.9164e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8408e-04 - val_loss: 5.7553e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8015e-04 - val_loss: 5.7548e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8260e-04 - val_loss: 5.8690e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8216e-04 - val_loss: 5.9038e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7405e-04 - val_loss: 5.6948e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7715e-04 - val_loss: 6.0624e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8295e-04 - val_loss: 6.0047e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8134e-04 - val_loss: 6.3214e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7590e-04 - val_loss: 5.6391e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6671e-04 - val_loss: 5.7804e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7342e-04 - val_loss: 5.9603e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7414e-04 - val_loss: 5.6861e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7880e-04 - val_loss: 5.7209e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7334e-04 - val_loss: 6.6809e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7721e-04 - val_loss: 5.6935e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7122e-04 - val_loss: 5.7036e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7042e-04 - val_loss: 5.6358e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6293e-04 - val_loss: 5.5300e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6689e-04 - val_loss: 5.7330e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6140e-04 - val_loss: 5.6671e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5765e-04 - val_loss: 5.5738e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7031e-04 - val_loss: 5.7041e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7077e-04 - val_loss: 5.6413e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5391e-04 - val_loss: 5.5668e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6386e-04 - val_loss: 5.7544e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5770e-04 - val_loss: 5.6929e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6656e-04 - val_loss: 5.5984e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6322e-04 - val_loss: 5.4468e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6761e-04 - val_loss: 5.6515e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5604e-04 - val_loss: 5.5048e-04\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_0\\assets\n",
      "  1%|▊                                                                             | 1/100 [10:21<17:05:37, 621.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4977e-04 - val_loss: 5.6087e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6218e-04 - val_loss: 5.4907e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5748e-04 - val_loss: 5.6512e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6581e-04 - val_loss: 5.5283e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5604e-04 - val_loss: 5.4013e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5512e-04 - val_loss: 5.4346e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5084e-04 - val_loss: 5.7533e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5544e-04 - val_loss: 5.4752e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5080e-04 - val_loss: 5.6676e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4870e-04 - val_loss: 5.4109e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5034e-04 - val_loss: 5.6183e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4590e-04 - val_loss: 5.4197e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5077e-04 - val_loss: 5.4865e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5847e-04 - val_loss: 5.6318e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5826e-04 - val_loss: 5.6539e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5673e-04 - val_loss: 5.5539e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4346e-04 - val_loss: 5.7106e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5380e-04 - val_loss: 5.4343e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5766e-04 - val_loss: 5.5509e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5375e-04 - val_loss: 5.6090e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5036e-04 - val_loss: 5.5429e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5353e-04 - val_loss: 5.4833e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4576e-04 - val_loss: 5.4718e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4590e-04 - val_loss: 5.5440e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4739e-04 - val_loss: 5.4150e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4356e-04 - val_loss: 5.4891e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4726e-04 - val_loss: 5.6061e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3866e-04 - val_loss: 5.4818e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5036e-04 - val_loss: 5.9300e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4498e-04 - val_loss: 5.3750e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3745e-04 - val_loss: 5.3486e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3723e-04 - val_loss: 5.4787e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4039e-04 - val_loss: 5.2951e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4082e-04 - val_loss: 5.5991e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4379e-04 - val_loss: 5.3782e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4939e-04 - val_loss: 5.6150e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5585e-04 - val_loss: 5.6836e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5620e-04 - val_loss: 5.3721e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4650e-04 - val_loss: 5.3644e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3756e-04 - val_loss: 5.4187e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3600e-04 - val_loss: 5.3611e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4097e-04 - val_loss: 5.3855e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6447e-04 - val_loss: 5.4745e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4750e-04 - val_loss: 5.5257e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5076e-04 - val_loss: 5.4723e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4344e-04 - val_loss: 5.2860e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3415e-04 - val_loss: 5.4087e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5096e-04 - val_loss: 5.4497e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6093e-04 - val_loss: 5.4044e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5110e-04 - val_loss: 6.1225e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4926e-04 - val_loss: 5.4112e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4415e-04 - val_loss: 5.4785e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4338e-04 - val_loss: 5.7766e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3582e-04 - val_loss: 5.5437e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4838e-04 - val_loss: 5.7309e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7428e-04 - val_loss: 5.3913e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3547e-04 - val_loss: 5.3854e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8291e-04 - val_loss: 6.2479e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6427e-04 - val_loss: 5.4085e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4544e-04 - val_loss: 6.0141e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6893e-04 - val_loss: 5.4735e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4029e-04 - val_loss: 5.4849e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4711e-04 - val_loss: 5.3366e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3349e-04 - val_loss: 5.6322e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5009e-04 - val_loss: 5.7820e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4318e-04 - val_loss: 5.3318e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4992e-04 - val_loss: 5.5334e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.2371e-04 - val_loss: 5.7586e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4984e-04 - val_loss: 5.4585e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9763e-04 - val_loss: 6.4358e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1238e-04 - val_loss: 6.4532e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9787e-04 - val_loss: 6.0885e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0263e-04 - val_loss: 5.9173e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8855e-04 - val_loss: 5.8527e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8359e-04 - val_loss: 5.4630e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5520e-04 - val_loss: 5.6658e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5927e-04 - val_loss: 5.8789e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9457e-04 - val_loss: 6.1870e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0119e-04 - val_loss: 5.9304e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9889e-04 - val_loss: 6.7196e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0687e-04 - val_loss: 5.7182e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7637e-04 - val_loss: 5.5792e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7307e-04 - val_loss: 5.4939e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5277e-04 - val_loss: 5.5522e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4665e-04 - val_loss: 5.3426e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4063e-04 - val_loss: 5.3817e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3114e-04 - val_loss: 5.4029e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3906e-04 - val_loss: 5.2539e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3346e-04 - val_loss: 5.2934e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2957e-04 - val_loss: 5.3740e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3024e-04 - val_loss: 5.4073e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4683e-04 - val_loss: 5.3305e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2506e-04 - val_loss: 5.3821e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3342e-04 - val_loss: 5.2780e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3232e-04 - val_loss: 5.3683e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6189e-04 - val_loss: 5.5122e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3394e-04 - val_loss: 5.4569e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4541e-04 - val_loss: 5.7301e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3498e-04 - val_loss: 5.3175e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3953e-04 - val_loss: 5.3069e-04\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_1\\assets\n",
      "  2%|█▌                                                                            | 2/100 [21:07<17:07:06, 628.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3678e-04 - val_loss: 5.2510e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3662e-04 - val_loss: 5.3350e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5175e-04 - val_loss: 5.3870e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2612e-04 - val_loss: 5.1907e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4751e-04 - val_loss: 6.1222e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9083e-04 - val_loss: 5.8593e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8749e-04 - val_loss: 6.2416e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8503e-04 - val_loss: 5.7317e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7558e-04 - val_loss: 5.8759e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8302e-04 - val_loss: 5.7213e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7873e-04 - val_loss: 5.7060e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6513e-04 - val_loss: 5.4856e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5416e-04 - val_loss: 5.7374e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6011e-04 - val_loss: 5.7504e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5845e-04 - val_loss: 5.6386e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5111e-04 - val_loss: 5.5869e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6321e-04 - val_loss: 5.4841e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6318e-04 - val_loss: 5.5850e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6820e-04 - val_loss: 6.1445e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5821e-04 - val_loss: 5.6731e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5869e-04 - val_loss: 5.7921e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6726e-04 - val_loss: 5.7116e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6030e-04 - val_loss: 5.4883e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6030e-04 - val_loss: 5.4591e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6482e-04 - val_loss: 5.5842e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7096e-04 - val_loss: 6.0273e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7055e-04 - val_loss: 6.0440e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8219e-04 - val_loss: 5.6581e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6466e-04 - val_loss: 5.5047e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8159e-04 - val_loss: 5.6412e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4611e-04 - val_loss: 5.5691e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7165e-04 - val_loss: 5.4154e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6138e-04 - val_loss: 5.5320e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6316e-04 - val_loss: 5.7311e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8236e-04 - val_loss: 5.9700e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7574e-04 - val_loss: 5.7184e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7627e-04 - val_loss: 5.9484e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7430e-04 - val_loss: 5.6191e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0770e-04 - val_loss: 6.5093e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.4521e-04 - val_loss: 6.2314e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2347e-04 - val_loss: 6.3148e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8726e-04 - val_loss: 5.5606e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6084e-04 - val_loss: 5.6738e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0487e-04 - val_loss: 5.9452e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8398e-04 - val_loss: 5.8217e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8192e-04 - val_loss: 5.6789e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9018e-04 - val_loss: 5.6352e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6212e-04 - val_loss: 5.6498e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6376e-04 - val_loss: 5.7569e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6023e-04 - val_loss: 5.6765e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4922e-04 - val_loss: 5.4187e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6279e-04 - val_loss: 5.6199e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5104e-04 - val_loss: 5.5285e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6879e-04 - val_loss: 5.8974e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6940e-04 - val_loss: 5.5920e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5926e-04 - val_loss: 5.5280e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5581e-04 - val_loss: 5.5786e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6871e-04 - val_loss: 5.6189e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5123e-04 - val_loss: 5.4384e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4051e-04 - val_loss: 5.4194e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3997e-04 - val_loss: 5.2526e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3650e-04 - val_loss: 5.5785e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6264e-04 - val_loss: 6.1238e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0413e-04 - val_loss: 5.7046e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0018e-04 - val_loss: 5.9640e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9047e-04 - val_loss: 5.6414e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7783e-04 - val_loss: 5.5109e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7243e-04 - val_loss: 5.8679e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6967e-04 - val_loss: 5.5186e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5985e-04 - val_loss: 5.6663e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5540e-04 - val_loss: 5.7222e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4839e-04 - val_loss: 5.6767e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6237e-04 - val_loss: 5.5810e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5645e-04 - val_loss: 5.6549e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6063e-04 - val_loss: 5.6739e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6262e-04 - val_loss: 5.7206e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6926e-04 - val_loss: 5.6993e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7645e-04 - val_loss: 5.6141e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8175e-04 - val_loss: 5.6847e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5967e-04 - val_loss: 5.5252e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6722e-04 - val_loss: 5.7175e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5925e-04 - val_loss: 5.4990e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5171e-04 - val_loss: 5.5721e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6551e-04 - val_loss: 5.3572e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6971e-04 - val_loss: 5.5621e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5881e-04 - val_loss: 5.4431e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5493e-04 - val_loss: 5.6032e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5678e-04 - val_loss: 5.3907e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4813e-04 - val_loss: 5.5116e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4754e-04 - val_loss: 5.4394e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5199e-04 - val_loss: 5.4730e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4620e-04 - val_loss: 5.3630e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4492e-04 - val_loss: 5.6083e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4444e-04 - val_loss: 5.3173e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4801e-04 - val_loss: 5.5640e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4025e-04 - val_loss: 5.2718e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4012e-04 - val_loss: 5.5642e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6014e-04 - val_loss: 5.6489e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4408e-04 - val_loss: 5.3049e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3434e-04 - val_loss: 5.4469e-04\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_2\\assets\n",
      "  3%|██▎                                                                           | 3/100 [31:33<16:55:12, 627.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4199e-04 - val_loss: 5.7223e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5590e-04 - val_loss: 5.4300e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4127e-04 - val_loss: 5.4184e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3992e-04 - val_loss: 5.3116e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4118e-04 - val_loss: 5.5384e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4185e-04 - val_loss: 5.2158e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3354e-04 - val_loss: 5.3261e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4394e-04 - val_loss: 5.5558e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5665e-04 - val_loss: 5.4929e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4300e-04 - val_loss: 5.3927e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4021e-04 - val_loss: 5.4305e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4498e-04 - val_loss: 5.2657e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4270e-04 - val_loss: 5.5793e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6331e-04 - val_loss: 5.8409e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6005e-04 - val_loss: 5.5467e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5342e-04 - val_loss: 5.5660e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6688e-04 - val_loss: 5.8103e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7295e-04 - val_loss: 5.7174e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7119e-04 - val_loss: 5.6801e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7681e-04 - val_loss: 5.7576e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7175e-04 - val_loss: 5.7617e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6945e-04 - val_loss: 5.4897e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6008e-04 - val_loss: 5.5150e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6672e-04 - val_loss: 5.5120e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5651e-04 - val_loss: 5.4131e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6748e-04 - val_loss: 5.6076e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6419e-04 - val_loss: 5.5360e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5098e-04 - val_loss: 5.5732e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7043e-04 - val_loss: 5.5677e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5690e-04 - val_loss: 5.5834e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5231e-04 - val_loss: 5.4711e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5925e-04 - val_loss: 5.6639e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5156e-04 - val_loss: 5.5605e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6771e-04 - val_loss: 5.4565e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5423e-04 - val_loss: 5.4675e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4678e-04 - val_loss: 5.5448e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4347e-04 - val_loss: 5.5111e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4590e-04 - val_loss: 5.5261e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4015e-04 - val_loss: 5.3404e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4414e-04 - val_loss: 5.8702e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4162e-04 - val_loss: 5.4304e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6989e-04 - val_loss: 5.6087e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5948e-04 - val_loss: 5.3726e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4513e-04 - val_loss: 5.3725e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4600e-04 - val_loss: 5.7061e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5252e-04 - val_loss: 5.3168e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4123e-04 - val_loss: 5.2979e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5274e-04 - val_loss: 5.5357e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6311e-04 - val_loss: 5.4754e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3748e-04 - val_loss: 5.2353e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3855e-04 - val_loss: 5.3138e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4424e-04 - val_loss: 5.3728e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3914e-04 - val_loss: 5.4061e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6418e-04 - val_loss: 5.6679e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4240e-04 - val_loss: 5.4724e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4111e-04 - val_loss: 5.2842e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3986e-04 - val_loss: 5.5807e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4197e-04 - val_loss: 5.4843e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6417e-04 - val_loss: 5.5953e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4212e-04 - val_loss: 5.4121e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4744e-04 - val_loss: 6.0029e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5162e-04 - val_loss: 5.4622e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5550e-04 - val_loss: 5.3482e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2956e-04 - val_loss: 5.3296e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2324e-04 - val_loss: 5.5140e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4524e-04 - val_loss: 5.4604e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3740e-04 - val_loss: 5.3415e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4145e-04 - val_loss: 5.3341e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5341e-04 - val_loss: 5.6586e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3378e-04 - val_loss: 5.2740e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2897e-04 - val_loss: 5.3071e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4107e-04 - val_loss: 5.4763e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3940e-04 - val_loss: 5.3124e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4350e-04 - val_loss: 5.2632e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4800e-04 - val_loss: 5.5664e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6012e-04 - val_loss: 5.6554e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4942e-04 - val_loss: 5.3847e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4847e-04 - val_loss: 5.4485e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4981e-04 - val_loss: 5.4570e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6812e-04 - val_loss: 5.6009e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6131e-04 - val_loss: 5.6637e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5545e-04 - val_loss: 5.5693e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6561e-04 - val_loss: 5.6344e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6560e-04 - val_loss: 5.7502e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7073e-04 - val_loss: 5.6628e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5182e-04 - val_loss: 5.5645e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4104e-04 - val_loss: 5.3938e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5035e-04 - val_loss: 5.9115e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6891e-04 - val_loss: 5.4521e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4513e-04 - val_loss: 5.4135e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3843e-04 - val_loss: 5.4056e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3179e-04 - val_loss: 5.4225e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3673e-04 - val_loss: 5.3356e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3521e-04 - val_loss: 5.3063e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3160e-04 - val_loss: 5.3591e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5181e-04 - val_loss: 5.5651e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6600e-04 - val_loss: 5.6325e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6113e-04 - val_loss: 5.7430e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8834e-04 - val_loss: 5.9220e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6593e-04 - val_loss: 5.4232e-04\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_3\\assets\n",
      "  4%|███                                                                           | 4/100 [42:55<17:11:01, 644.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3589e-04 - val_loss: 5.2118e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2785e-04 - val_loss: 5.2310e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3211e-04 - val_loss: 5.3931e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4615e-04 - val_loss: 5.3117e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3204e-04 - val_loss: 5.3591e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5135e-04 - val_loss: 5.4602e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3061e-04 - val_loss: 5.1765e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2345e-04 - val_loss: 5.3917e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2606e-04 - val_loss: 5.1786e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5874e-04 - val_loss: 5.8614e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7759e-04 - val_loss: 5.9316e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6121e-04 - val_loss: 5.5249e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6225e-04 - val_loss: 5.5801e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5650e-04 - val_loss: 5.4648e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5661e-04 - val_loss: 5.4448e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4878e-04 - val_loss: 5.5664e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4136e-04 - val_loss: 5.3346e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3893e-04 - val_loss: 5.5605e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4323e-04 - val_loss: 5.4172e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4838e-04 - val_loss: 5.6931e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6673e-04 - val_loss: 5.7175e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7693e-04 - val_loss: 5.6887e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8365e-04 - val_loss: 5.9283e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8166e-04 - val_loss: 5.8162e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0413e-04 - val_loss: 6.0519e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1301e-04 - val_loss: 6.0986e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1058e-04 - val_loss: 6.1532e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8400e-04 - val_loss: 5.6581e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7716e-04 - val_loss: 5.7903e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7562e-04 - val_loss: 5.7182e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7501e-04 - val_loss: 5.8712e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8692e-04 - val_loss: 5.9826e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 6.1642e-04 - val_loss: 6.1296e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8170e-04 - val_loss: 5.5960e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7253e-04 - val_loss: 5.8334e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8081e-04 - val_loss: 5.9789e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1122e-04 - val_loss: 5.8559e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9425e-04 - val_loss: 5.7933e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7542e-04 - val_loss: 5.7322e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8638e-04 - val_loss: 6.1245e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8059e-04 - val_loss: 5.8572e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7158e-04 - val_loss: 5.6789e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7310e-04 - val_loss: 5.5305e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8324e-04 - val_loss: 5.4627e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6399e-04 - val_loss: 5.9635e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7014e-04 - val_loss: 5.7636e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6619e-04 - val_loss: 5.4518e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6072e-04 - val_loss: 5.5514e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5740e-04 - val_loss: 5.3290e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5304e-04 - val_loss: 5.4511e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6343e-04 - val_loss: 5.6421e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5644e-04 - val_loss: 5.4863e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5605e-04 - val_loss: 5.7168e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6526e-04 - val_loss: 5.6634e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5134e-04 - val_loss: 5.4645e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5257e-04 - val_loss: 5.5163e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5499e-04 - val_loss: 5.5801e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6390e-04 - val_loss: 5.6055e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5802e-04 - val_loss: 5.5475e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4428e-04 - val_loss: 5.3278e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5417e-04 - val_loss: 5.4176e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5735e-04 - val_loss: 5.6516e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8147e-04 - val_loss: 5.9021e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7651e-04 - val_loss: 5.4739e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4549e-04 - val_loss: 5.4413e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6013e-04 - val_loss: 5.5706e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7644e-04 - val_loss: 5.6763e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6875e-04 - val_loss: 5.9550e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5346e-04 - val_loss: 5.3989e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5317e-04 - val_loss: 5.3766e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4981e-04 - val_loss: 5.4049e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5002e-04 - val_loss: 5.6167e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5395e-04 - val_loss: 5.5798e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6323e-04 - val_loss: 5.7234e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5637e-04 - val_loss: 5.5310e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7050e-04 - val_loss: 5.6666e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8611e-04 - val_loss: 5.7758e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7118e-04 - val_loss: 5.6160e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6153e-04 - val_loss: 5.6678e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6304e-04 - val_loss: 5.5003e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5706e-04 - val_loss: 5.4491e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7434e-04 - val_loss: 5.6665e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8723e-04 - val_loss: 5.7730e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6783e-04 - val_loss: 5.6747e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5376e-04 - val_loss: 5.5940e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6724e-04 - val_loss: 5.6391e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7354e-04 - val_loss: 5.5828e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5378e-04 - val_loss: 5.5256e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5619e-04 - val_loss: 5.5105e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6564e-04 - val_loss: 5.6089e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4686e-04 - val_loss: 5.5734e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5047e-04 - val_loss: 5.3414e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5832e-04 - val_loss: 5.5285e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6034e-04 - val_loss: 5.9242e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6732e-04 - val_loss: 5.4483e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6063e-04 - val_loss: 5.7349e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8946e-04 - val_loss: 5.5288e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6327e-04 - val_loss: 5.5210e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6115e-04 - val_loss: 5.4798e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4608e-04 - val_loss: 5.4560e-04\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_4\\assets\n",
      "  5%|███▉                                                                          | 5/100 [54:46<17:31:50, 664.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4256e-04 - val_loss: 5.4561e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6526e-04 - val_loss: 5.7314e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8386e-04 - val_loss: 5.4369e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6382e-04 - val_loss: 5.6248e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8850e-04 - val_loss: 5.5897e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6617e-04 - val_loss: 5.3524e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4006e-04 - val_loss: 5.6478e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5997e-04 - val_loss: 5.9222e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6675e-04 - val_loss: 5.4713e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5680e-04 - val_loss: 6.0255e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6735e-04 - val_loss: 5.4158e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4644e-04 - val_loss: 5.5073e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3997e-04 - val_loss: 5.4730e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5722e-04 - val_loss: 5.9858e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5817e-04 - val_loss: 5.4658e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5519e-04 - val_loss: 5.3346e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5603e-04 - val_loss: 5.8389e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4953e-04 - val_loss: 5.5265e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4767e-04 - val_loss: 5.2760e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4104e-04 - val_loss: 5.3697e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5105e-04 - val_loss: 5.3266e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5106e-04 - val_loss: 5.4757e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4793e-04 - val_loss: 5.4042e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3956e-04 - val_loss: 5.4762e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6196e-04 - val_loss: 5.3468e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3915e-04 - val_loss: 5.5499e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4530e-04 - val_loss: 5.4461e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5321e-04 - val_loss: 5.5055e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5270e-04 - val_loss: 5.5331e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4653e-04 - val_loss: 5.4585e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4425e-04 - val_loss: 5.3679e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4320e-04 - val_loss: 5.5070e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7147e-04 - val_loss: 5.4401e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4924e-04 - val_loss: 5.5933e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7602e-04 - val_loss: 5.5707e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5025e-04 - val_loss: 5.2767e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4176e-04 - val_loss: 5.3512e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4533e-04 - val_loss: 5.3551e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3946e-04 - val_loss: 5.4610e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3147e-04 - val_loss: 5.4342e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2907e-04 - val_loss: 5.4852e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5137e-04 - val_loss: 5.4787e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4965e-04 - val_loss: 5.8369e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5167e-04 - val_loss: 5.6263e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4342e-04 - val_loss: 5.4088e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4339e-04 - val_loss: 5.3455e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2976e-04 - val_loss: 5.4014e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5656e-04 - val_loss: 5.4494e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4835e-04 - val_loss: 5.9099e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3811e-04 - val_loss: 5.3921e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3366e-04 - val_loss: 5.3408e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3377e-04 - val_loss: 5.6101e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3700e-04 - val_loss: 5.3908e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3695e-04 - val_loss: 5.5796e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4647e-04 - val_loss: 5.3648e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5375e-04 - val_loss: 5.6313e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4173e-04 - val_loss: 5.3334e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3643e-04 - val_loss: 5.4852e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4199e-04 - val_loss: 5.3190e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3690e-04 - val_loss: 5.4952e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6975e-04 - val_loss: 5.4186e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3747e-04 - val_loss: 5.3915e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3138e-04 - val_loss: 5.2269e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3660e-04 - val_loss: 5.3069e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8345e-04 - val_loss: 5.2842e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4330e-04 - val_loss: 5.1911e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4574e-04 - val_loss: 5.4401e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8040e-04 - val_loss: 7.0901e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8651e-04 - val_loss: 6.0081e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7089e-04 - val_loss: 5.2751e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3448e-04 - val_loss: 5.4023e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7476e-04 - val_loss: 5.8329e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4139e-04 - val_loss: 5.3501e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4774e-04 - val_loss: 5.6403e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5012e-04 - val_loss: 5.4510e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7420e-04 - val_loss: 6.2211e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4211e-04 - val_loss: 5.2705e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2319e-04 - val_loss: 5.4991e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3750e-04 - val_loss: 5.3842e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2700e-04 - val_loss: 5.2844e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3327e-04 - val_loss: 5.5054e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2999e-04 - val_loss: 5.3198e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4341e-04 - val_loss: 5.3044e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4016e-04 - val_loss: 5.4878e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5764e-04 - val_loss: 7.5674e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.8647e-04 - val_loss: 5.6913e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4179e-04 - val_loss: 5.3097e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2261e-04 - val_loss: 5.3783e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3264e-04 - val_loss: 5.3290e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2506e-04 - val_loss: 5.3028e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2005e-04 - val_loss: 5.2829e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3164e-04 - val_loss: 5.3715e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2629e-04 - val_loss: 5.3569e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4352e-04 - val_loss: 5.4153e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2959e-04 - val_loss: 5.3478e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4025e-04 - val_loss: 5.4199e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2716e-04 - val_loss: 5.3950e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2944e-04 - val_loss: 5.1889e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3041e-04 - val_loss: 5.2831e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5000e-04 - val_loss: 5.8513e-04\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_5\\assets\n",
      "  6%|████▌                                                                       | 6/100 [1:06:05<17:27:23, 668.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4948e-04 - val_loss: 5.5915e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2203e-04 - val_loss: 5.4520e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1749e-04 - val_loss: 5.3105e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3846e-04 - val_loss: 5.3323e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4278e-04 - val_loss: 5.4279e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3437e-04 - val_loss: 5.3427e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1826e-04 - val_loss: 5.2700e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2885e-04 - val_loss: 5.3835e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5136e-04 - val_loss: 5.2007e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1949e-04 - val_loss: 5.2211e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1941e-04 - val_loss: 5.5062e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2668e-04 - val_loss: 5.1623e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1635e-04 - val_loss: 5.2206e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2096e-04 - val_loss: 5.3097e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2643e-04 - val_loss: 6.0620e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8915e-04 - val_loss: 5.4065e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5510e-04 - val_loss: 5.4926e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4308e-04 - val_loss: 5.3997e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5318e-04 - val_loss: 5.8853e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6431e-04 - val_loss: 5.4479e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3660e-04 - val_loss: 5.2102e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3494e-04 - val_loss: 5.3622e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2820e-04 - val_loss: 5.3333e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2841e-04 - val_loss: 5.2572e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2099e-04 - val_loss: 5.3411e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2106e-04 - val_loss: 5.3218e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2617e-04 - val_loss: 5.3760e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3738e-04 - val_loss: 5.3363e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2199e-04 - val_loss: 5.1915e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1738e-04 - val_loss: 5.2026e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2861e-04 - val_loss: 5.3723e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2285e-04 - val_loss: 5.1947e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4753e-04 - val_loss: 5.9775e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4625e-04 - val_loss: 5.4862e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3732e-04 - val_loss: 5.4387e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4112e-04 - val_loss: 5.2998e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4970e-04 - val_loss: 5.5817e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4281e-04 - val_loss: 5.3084e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3382e-04 - val_loss: 5.3550e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1701e-04 - val_loss: 5.1755e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2199e-04 - val_loss: 5.2433e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2666e-04 - val_loss: 5.4464e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2619e-04 - val_loss: 5.3492e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2742e-04 - val_loss: 5.2068e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6633e-04 - val_loss: 5.4602e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2569e-04 - val_loss: 5.2919e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3762e-04 - val_loss: 6.0008e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6573e-04 - val_loss: 5.7146e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6852e-04 - val_loss: 5.6027e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4916e-04 - val_loss: 5.3580e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2667e-04 - val_loss: 5.3516e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3213e-04 - val_loss: 5.3415e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3912e-04 - val_loss: 5.3745e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3204e-04 - val_loss: 5.3405e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4468e-04 - val_loss: 5.6957e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3729e-04 - val_loss: 5.2408e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2389e-04 - val_loss: 5.0967e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2745e-04 - val_loss: 5.2222e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2786e-04 - val_loss: 5.1436e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2172e-04 - val_loss: 5.3467e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2620e-04 - val_loss: 5.3029e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4373e-04 - val_loss: 5.3748e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2366e-04 - val_loss: 5.2250e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2529e-04 - val_loss: 5.3990e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2628e-04 - val_loss: 5.2067e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1859e-04 - val_loss: 5.2966e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2445e-04 - val_loss: 5.3489e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2902e-04 - val_loss: 5.2332e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1974e-04 - val_loss: 5.5840e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2828e-04 - val_loss: 5.3633e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2835e-04 - val_loss: 5.1745e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2090e-04 - val_loss: 5.2756e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2193e-04 - val_loss: 5.4257e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2032e-04 - val_loss: 5.2632e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2242e-04 - val_loss: 5.3163e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2857e-04 - val_loss: 5.2353e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2540e-04 - val_loss: 5.4611e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2795e-04 - val_loss: 5.3394e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2313e-04 - val_loss: 5.1834e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2051e-04 - val_loss: 5.2890e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1658e-04 - val_loss: 5.0642e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2967e-04 - val_loss: 5.5348e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2434e-04 - val_loss: 5.1082e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2765e-04 - val_loss: 5.3437e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3330e-04 - val_loss: 5.4374e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5802e-04 - val_loss: 5.6299e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5697e-04 - val_loss: 5.3782e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5861e-04 - val_loss: 5.5364e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4301e-04 - val_loss: 5.4817e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4332e-04 - val_loss: 5.3523e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3179e-04 - val_loss: 5.3527e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3908e-04 - val_loss: 5.2813e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4002e-04 - val_loss: 5.1197e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2406e-04 - val_loss: 5.5125e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1929e-04 - val_loss: 5.1624e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4392e-04 - val_loss: 5.5918e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2000e-04 - val_loss: 5.0502e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1610e-04 - val_loss: 5.0874e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6955e-04 - val_loss: 6.1953e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.3672e-04 - val_loss: 6.2564e-04\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_6\\assets\n",
      "  7%|█████▎                                                                      | 7/100 [1:17:04<17:12:02, 665.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1262e-04 - val_loss: 6.0156e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1191e-04 - val_loss: 6.0825e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0010e-04 - val_loss: 6.0274e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1298e-04 - val_loss: 6.1306e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9616e-04 - val_loss: 5.9539e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8314e-04 - val_loss: 6.1083e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9229e-04 - val_loss: 5.8009e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8833e-04 - val_loss: 5.7900e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8879e-04 - val_loss: 5.8812e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8113e-04 - val_loss: 5.9335e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8724e-04 - val_loss: 5.8386e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9180e-04 - val_loss: 6.0353e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8340e-04 - val_loss: 5.8843e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7661e-04 - val_loss: 5.7389e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9132e-04 - val_loss: 6.3071e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8188e-04 - val_loss: 5.7960e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8704e-04 - val_loss: 5.9874e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7826e-04 - val_loss: 5.6847e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7341e-04 - val_loss: 6.0102e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2752e-04 - val_loss: 6.1337e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1249e-04 - val_loss: 6.2264e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9212e-04 - val_loss: 6.0885e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9282e-04 - val_loss: 5.9617e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8895e-04 - val_loss: 5.7382e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7819e-04 - val_loss: 5.8370e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8586e-04 - val_loss: 6.0205e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9083e-04 - val_loss: 5.8602e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8289e-04 - val_loss: 5.7851e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8320e-04 - val_loss: 5.8867e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7692e-04 - val_loss: 5.7924e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6662e-04 - val_loss: 5.7175e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7963e-04 - val_loss: 5.6565e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7195e-04 - val_loss: 5.6308e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6235e-04 - val_loss: 5.7157e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6837e-04 - val_loss: 5.5999e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6152e-04 - val_loss: 5.5406e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5429e-04 - val_loss: 5.5001e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6264e-04 - val_loss: 5.6228e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6914e-04 - val_loss: 5.6287e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5346e-04 - val_loss: 5.4808e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8013e-04 - val_loss: 5.8448e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8047e-04 - val_loss: 5.8714e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9012e-04 - val_loss: 5.9790e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9556e-04 - val_loss: 5.8242e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9251e-04 - val_loss: 5.7408e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9335e-04 - val_loss: 5.9133e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9095e-04 - val_loss: 5.8339e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9520e-04 - val_loss: 5.8259e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0144e-04 - val_loss: 5.8003e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7931e-04 - val_loss: 5.5554e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5926e-04 - val_loss: 5.3705e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6787e-04 - val_loss: 5.8271e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9404e-04 - val_loss: 5.5266e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8050e-04 - val_loss: 5.5022e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6152e-04 - val_loss: 5.4933e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9648e-04 - val_loss: 6.7897e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0280e-04 - val_loss: 6.3116e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9365e-04 - val_loss: 5.5584e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4582e-04 - val_loss: 5.4657e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6545e-04 - val_loss: 5.6036e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5431e-04 - val_loss: 5.3074e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3873e-04 - val_loss: 5.5159e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5766e-04 - val_loss: 5.5523e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6019e-04 - val_loss: 5.6103e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5810e-04 - val_loss: 5.3976e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4006e-04 - val_loss: 5.3610e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6177e-04 - val_loss: 5.8223e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4774e-04 - val_loss: 5.4767e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0518e-04 - val_loss: 5.8148e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5530e-04 - val_loss: 5.4100e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4014e-04 - val_loss: 5.4443e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5651e-04 - val_loss: 5.5916e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5008e-04 - val_loss: 5.6238e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6629e-04 - val_loss: 5.6832e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5180e-04 - val_loss: 5.3979e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6929e-04 - val_loss: 5.7281e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6870e-04 - val_loss: 5.6532e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6818e-04 - val_loss: 5.6537e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4573e-04 - val_loss: 5.4106e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3804e-04 - val_loss: 5.1581e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4349e-04 - val_loss: 5.3760e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4349e-04 - val_loss: 5.4581e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6358e-04 - val_loss: 5.7110e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4906e-04 - val_loss: 5.3587e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4700e-04 - val_loss: 5.6121e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4355e-04 - val_loss: 5.2142e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3374e-04 - val_loss: 5.3931e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3297e-04 - val_loss: 5.4041e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3699e-04 - val_loss: 5.3038e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3282e-04 - val_loss: 5.6736e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3943e-04 - val_loss: 5.4619e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4070e-04 - val_loss: 5.4779e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3270e-04 - val_loss: 5.4135e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2874e-04 - val_loss: 5.1214e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3223e-04 - val_loss: 5.3522e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3561e-04 - val_loss: 5.2829e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2172e-04 - val_loss: 5.1633e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4794e-04 - val_loss: 5.6990e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8401e-04 - val_loss: 5.7721e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3052e-04 - val_loss: 5.2302e-04\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_7\\assets\n",
      "  8%|██████                                                                      | 8/100 [1:27:49<16:51:07, 659.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4133e-04 - val_loss: 5.4279e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3434e-04 - val_loss: 5.2436e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4188e-04 - val_loss: 5.7383e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6362e-04 - val_loss: 5.8010e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5404e-04 - val_loss: 5.6733e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5098e-04 - val_loss: 5.3444e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2745e-04 - val_loss: 5.3326e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4697e-04 - val_loss: 5.7019e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3880e-04 - val_loss: 5.3979e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3141e-04 - val_loss: 5.2783e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2675e-04 - val_loss: 5.3502e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3435e-04 - val_loss: 5.3460e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5404e-04 - val_loss: 6.5297e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7537e-04 - val_loss: 5.2497e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4195e-04 - val_loss: 5.5540e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6130e-04 - val_loss: 5.5676e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5217e-04 - val_loss: 5.5450e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4336e-04 - val_loss: 5.3557e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3801e-04 - val_loss: 5.5430e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3565e-04 - val_loss: 5.5893e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3829e-04 - val_loss: 5.4961e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3349e-04 - val_loss: 5.4552e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4415e-04 - val_loss: 5.3641e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5093e-04 - val_loss: 5.8159e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4767e-04 - val_loss: 5.7011e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6049e-04 - val_loss: 5.6584e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5665e-04 - val_loss: 5.5200e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5003e-04 - val_loss: 5.7897e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4746e-04 - val_loss: 5.3812e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4136e-04 - val_loss: 5.4367e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3816e-04 - val_loss: 5.4821e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3925e-04 - val_loss: 5.4852e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3401e-04 - val_loss: 5.2433e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4367e-04 - val_loss: 5.3325e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3606e-04 - val_loss: 5.2772e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6109e-04 - val_loss: 5.5898e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4016e-04 - val_loss: 5.3885e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3304e-04 - val_loss: 5.3403e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3097e-04 - val_loss: 5.2936e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2671e-04 - val_loss: 5.3179e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3936e-04 - val_loss: 5.4689e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3802e-04 - val_loss: 5.6721e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5421e-04 - val_loss: 5.3535e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3913e-04 - val_loss: 5.4384e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4517e-04 - val_loss: 5.4549e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3806e-04 - val_loss: 5.5136e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2809e-04 - val_loss: 5.2750e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3942e-04 - val_loss: 5.2777e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7485e-04 - val_loss: 5.7793e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0488e-04 - val_loss: 5.4310e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4800e-04 - val_loss: 5.3431e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4260e-04 - val_loss: 5.5965e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3573e-04 - val_loss: 5.4181e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4115e-04 - val_loss: 5.3822e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5080e-04 - val_loss: 5.2908e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2552e-04 - val_loss: 5.4010e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3532e-04 - val_loss: 5.4387e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3676e-04 - val_loss: 5.3110e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3040e-04 - val_loss: 5.3080e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6589e-04 - val_loss: 6.2328e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.8314e-04 - val_loss: 6.7611e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1142e-04 - val_loss: 6.5830e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2432e-04 - val_loss: 5.8539e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6127e-04 - val_loss: 5.2742e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3774e-04 - val_loss: 5.2822e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2779e-04 - val_loss: 5.2546e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3181e-04 - val_loss: 5.3153e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2290e-04 - val_loss: 5.2010e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2564e-04 - val_loss: 5.1988e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2596e-04 - val_loss: 5.3708e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2392e-04 - val_loss: 5.3604e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3886e-04 - val_loss: 5.3856e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5213e-04 - val_loss: 5.6765e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6868e-04 - val_loss: 5.3186e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3658e-04 - val_loss: 5.3773e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4595e-04 - val_loss: 5.4262e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3489e-04 - val_loss: 5.4786e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2913e-04 - val_loss: 5.2584e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3667e-04 - val_loss: 5.3622e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3336e-04 - val_loss: 5.4096e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3116e-04 - val_loss: 5.2892e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3576e-04 - val_loss: 5.5295e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5196e-04 - val_loss: 5.4292e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2955e-04 - val_loss: 5.2264e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4421e-04 - val_loss: 5.3092e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3733e-04 - val_loss: 5.5582e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8745e-04 - val_loss: 5.3287e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7159e-04 - val_loss: 5.6224e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5798e-04 - val_loss: 5.4177e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3883e-04 - val_loss: 5.5105e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4496e-04 - val_loss: 5.5401e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6340e-04 - val_loss: 5.6949e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5454e-04 - val_loss: 5.4959e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6202e-04 - val_loss: 5.4472e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5157e-04 - val_loss: 5.4803e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5871e-04 - val_loss: 5.6982e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5537e-04 - val_loss: 5.5259e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5477e-04 - val_loss: 5.4552e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5885e-04 - val_loss: 5.5028e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4654e-04 - val_loss: 5.4880e-04\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_8\\assets\n",
      "  9%|██████▊                                                                     | 9/100 [1:38:28<16:31:08, 653.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6168e-04 - val_loss: 5.3464e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3406e-04 - val_loss: 5.4269e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4072e-04 - val_loss: 5.6260e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4052e-04 - val_loss: 5.5051e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7989e-04 - val_loss: 5.6826e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4829e-04 - val_loss: 5.3838e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4617e-04 - val_loss: 5.5376e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5451e-04 - val_loss: 5.9001e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6412e-04 - val_loss: 5.4561e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5070e-04 - val_loss: 5.3412e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5237e-04 - val_loss: 5.5241e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6550e-04 - val_loss: 5.5428e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3643e-04 - val_loss: 5.3356e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3333e-04 - val_loss: 5.4060e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3302e-04 - val_loss: 5.2467e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4076e-04 - val_loss: 5.6356e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3994e-04 - val_loss: 5.4233e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5622e-04 - val_loss: 5.6064e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6457e-04 - val_loss: 5.6566e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3734e-04 - val_loss: 5.4386e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4622e-04 - val_loss: 5.3122e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3275e-04 - val_loss: 5.2354e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3517e-04 - val_loss: 5.4561e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3952e-04 - val_loss: 5.5145e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7256e-04 - val_loss: 5.3467e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5200e-04 - val_loss: 5.4264e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2965e-04 - val_loss: 5.2169e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6750e-04 - val_loss: 6.1395e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9910e-04 - val_loss: 5.7146e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1614e-04 - val_loss: 6.1030e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1233e-04 - val_loss: 6.0531e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1551e-04 - val_loss: 6.2722e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2115e-04 - val_loss: 5.8087e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7823e-04 - val_loss: 6.3623e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6833e-04 - val_loss: 5.6233e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7062e-04 - val_loss: 5.6945e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6583e-04 - val_loss: 5.5363e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5792e-04 - val_loss: 5.5160e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6267e-04 - val_loss: 5.5426e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6360e-04 - val_loss: 5.5814e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6410e-04 - val_loss: 5.6944e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7996e-04 - val_loss: 5.8603e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7931e-04 - val_loss: 5.5536e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7291e-04 - val_loss: 5.8007e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8210e-04 - val_loss: 5.7318e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6973e-04 - val_loss: 5.7137e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6763e-04 - val_loss: 5.5588e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6465e-04 - val_loss: 5.8214e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8029e-04 - val_loss: 5.5243e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5979e-04 - val_loss: 5.5065e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7826e-04 - val_loss: 5.5923e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5583e-04 - val_loss: 5.5071e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5804e-04 - val_loss: 5.7836e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6651e-04 - val_loss: 5.6634e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6213e-04 - val_loss: 5.6706e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5622e-04 - val_loss: 5.4789e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5355e-04 - val_loss: 5.5511e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6294e-04 - val_loss: 5.5957e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5930e-04 - val_loss: 5.5745e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5520e-04 - val_loss: 5.3909e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3752e-04 - val_loss: 5.4048e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3991e-04 - val_loss: 5.3558e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4873e-04 - val_loss: 5.5578e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4418e-04 - val_loss: 5.4740e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5478e-04 - val_loss: 5.6457e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5384e-04 - val_loss: 5.9535e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6031e-04 - val_loss: 5.7262e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5044e-04 - val_loss: 5.7545e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5343e-04 - val_loss: 5.4265e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4604e-04 - val_loss: 5.5414e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5303e-04 - val_loss: 5.6120e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5655e-04 - val_loss: 5.6965e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6470e-04 - val_loss: 5.6866e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7173e-04 - val_loss: 5.6916e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7627e-04 - val_loss: 5.6608e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6091e-04 - val_loss: 5.5960e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6165e-04 - val_loss: 5.5033e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5052e-04 - val_loss: 5.6261e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3869e-04 - val_loss: 5.3091e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4247e-04 - val_loss: 5.5575e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7016e-04 - val_loss: 5.8600e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3959e-04 - val_loss: 5.3974e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4371e-04 - val_loss: 5.2869e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5305e-04 - val_loss: 5.5207e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3716e-04 - val_loss: 5.3493e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3392e-04 - val_loss: 5.2995e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2868e-04 - val_loss: 5.4079e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4340e-04 - val_loss: 5.6820e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4076e-04 - val_loss: 5.4469e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4213e-04 - val_loss: 5.4198e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3298e-04 - val_loss: 5.4293e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7414e-04 - val_loss: 5.5604e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3689e-04 - val_loss: 5.4958e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3677e-04 - val_loss: 5.1329e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4557e-04 - val_loss: 5.3990e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3713e-04 - val_loss: 5.3475e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2600e-04 - val_loss: 5.4397e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2896e-04 - val_loss: 5.3693e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2647e-04 - val_loss: 5.2299e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2101e-04 - val_loss: 5.0839e-04\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_9\\assets\n",
      " 10%|███████▌                                                                   | 10/100 [1:49:34<16:25:31, 657.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2754e-04 - val_loss: 5.2472e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3039e-04 - val_loss: 5.2658e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1886e-04 - val_loss: 5.2405e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1921e-04 - val_loss: 5.3084e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2311e-04 - val_loss: 5.4319e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3887e-04 - val_loss: 5.6094e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4242e-04 - val_loss: 5.3594e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3375e-04 - val_loss: 5.2663e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4562e-04 - val_loss: 5.5314e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7898e-04 - val_loss: 5.2840e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2434e-04 - val_loss: 5.1438e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1883e-04 - val_loss: 5.2972e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3909e-04 - val_loss: 5.2090e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6708e-04 - val_loss: 5.7942e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6949e-04 - val_loss: 5.6990e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3155e-04 - val_loss: 5.4399e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2924e-04 - val_loss: 5.2262e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1682e-04 - val_loss: 5.3739e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4925e-04 - val_loss: 5.5708e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4233e-04 - val_loss: 5.4918e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4263e-04 - val_loss: 5.3262e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2078e-04 - val_loss: 5.3122e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2265e-04 - val_loss: 5.2116e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3616e-04 - val_loss: 5.2900e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3785e-04 - val_loss: 5.1941e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3323e-04 - val_loss: 5.2320e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3588e-04 - val_loss: 6.2238e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.2491e-04 - val_loss: 6.6366e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.5834e-04 - val_loss: 5.9291e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5660e-04 - val_loss: 5.6249e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5373e-04 - val_loss: 5.6539e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4019e-04 - val_loss: 5.2950e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3352e-04 - val_loss: 5.5659e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4167e-04 - val_loss: 5.3750e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3245e-04 - val_loss: 5.3768e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3180e-04 - val_loss: 5.4561e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0101e-04 - val_loss: 6.9728e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.7135e-04 - val_loss: 6.5660e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.6160e-04 - val_loss: 6.5338e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.5547e-04 - val_loss: 6.6209e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.7414e-04 - val_loss: 6.6777e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.7464e-04 - val_loss: 8.4637e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.6803e-04 - val_loss: 6.4450e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.4995e-04 - val_loss: 6.4562e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.4565e-04 - val_loss: 6.3755e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.4490e-04 - val_loss: 6.3581e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.3603e-04 - val_loss: 6.3713e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.4034e-04 - val_loss: 6.4001e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.3616e-04 - val_loss: 6.3972e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2757e-04 - val_loss: 6.2101e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1979e-04 - val_loss: 5.9323e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0786e-04 - val_loss: 5.9565e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9974e-04 - val_loss: 6.0359e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0064e-04 - val_loss: 6.0005e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9549e-04 - val_loss: 5.9195e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8695e-04 - val_loss: 5.7482e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0719e-04 - val_loss: 6.0259e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0075e-04 - val_loss: 5.9014e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9295e-04 - val_loss: 6.0400e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8514e-04 - val_loss: 5.7080e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8149e-04 - val_loss: 5.8732e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8289e-04 - val_loss: 5.8587e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7850e-04 - val_loss: 5.8184e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8338e-04 - val_loss: 5.9156e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8153e-04 - val_loss: 5.7032e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6551e-04 - val_loss: 5.6032e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7233e-04 - val_loss: 5.8161e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7740e-04 - val_loss: 5.7011e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8205e-04 - val_loss: 5.6195e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6723e-04 - val_loss: 5.9974e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7348e-04 - val_loss: 5.5625e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6419e-04 - val_loss: 5.6904e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9087e-04 - val_loss: 5.5454e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6844e-04 - val_loss: 5.6763e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6034e-04 - val_loss: 5.8019e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6620e-04 - val_loss: 5.6081e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6126e-04 - val_loss: 5.6939e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6513e-04 - val_loss: 5.5444e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6119e-04 - val_loss: 5.5814e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5839e-04 - val_loss: 5.5234e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7293e-04 - val_loss: 5.6431e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6582e-04 - val_loss: 5.6977e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7188e-04 - val_loss: 5.5849e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6584e-04 - val_loss: 5.6907e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5727e-04 - val_loss: 5.6533e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5269e-04 - val_loss: 5.4882e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4825e-04 - val_loss: 5.4617e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4612e-04 - val_loss: 5.5386e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5344e-04 - val_loss: 5.4628e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5586e-04 - val_loss: 5.8786e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7059e-04 - val_loss: 5.4387e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4543e-04 - val_loss: 5.5076e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4960e-04 - val_loss: 5.4135e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5373e-04 - val_loss: 5.6883e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5336e-04 - val_loss: 5.6142e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5668e-04 - val_loss: 5.7230e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6250e-04 - val_loss: 5.9990e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5081e-04 - val_loss: 5.6964e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4772e-04 - val_loss: 5.6149e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4236e-04 - val_loss: 5.4809e-04\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_10\\assets\n",
      " 11%|████████▎                                                                  | 11/100 [2:01:03<16:29:08, 666.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5427e-04 - val_loss: 5.3506e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4164e-04 - val_loss: 5.4045e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4371e-04 - val_loss: 5.6179e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4595e-04 - val_loss: 5.5332e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4173e-04 - val_loss: 5.3644e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3932e-04 - val_loss: 5.4253e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4751e-04 - val_loss: 5.4445e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4643e-04 - val_loss: 5.6174e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4693e-04 - val_loss: 5.4872e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4030e-04 - val_loss: 5.3554e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4123e-04 - val_loss: 5.5019e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6191e-04 - val_loss: 5.9111e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6699e-04 - val_loss: 5.6206e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8177e-04 - val_loss: 6.2710e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7120e-04 - val_loss: 5.3712e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4154e-04 - val_loss: 5.3734e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4617e-04 - val_loss: 5.4545e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3641e-04 - val_loss: 5.4229e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5030e-04 - val_loss: 5.6406e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4196e-04 - val_loss: 5.4853e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3642e-04 - val_loss: 5.5571e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3937e-04 - val_loss: 5.5462e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3297e-04 - val_loss: 5.2648e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4384e-04 - val_loss: 5.4269e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7700e-04 - val_loss: 5.9326e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3859e-04 - val_loss: 5.5257e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4249e-04 - val_loss: 5.3139e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3773e-04 - val_loss: 5.3598e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7145e-04 - val_loss: 5.4730e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3577e-04 - val_loss: 5.3356e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4931e-04 - val_loss: 5.6996e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5119e-04 - val_loss: 5.4831e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3295e-04 - val_loss: 5.4674e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4960e-04 - val_loss: 5.3179e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5014e-04 - val_loss: 5.5048e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5348e-04 - val_loss: 5.4538e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4616e-04 - val_loss: 5.2368e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2545e-04 - val_loss: 5.2166e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4058e-04 - val_loss: 5.6079e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4991e-04 - val_loss: 5.3122e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2891e-04 - val_loss: 5.2948e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3068e-04 - val_loss: 5.3752e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5628e-04 - val_loss: 5.3981e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4392e-04 - val_loss: 5.3001e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2328e-04 - val_loss: 5.2192e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2247e-04 - val_loss: 5.2022e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2867e-04 - val_loss: 5.3624e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3096e-04 - val_loss: 5.5196e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2790e-04 - val_loss: 5.2454e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2896e-04 - val_loss: 5.8898e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4253e-04 - val_loss: 5.2190e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2976e-04 - val_loss: 5.4709e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3385e-04 - val_loss: 5.1945e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3664e-04 - val_loss: 5.2812e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3982e-04 - val_loss: 5.5082e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6932e-04 - val_loss: 5.9642e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7186e-04 - val_loss: 5.4778e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3708e-04 - val_loss: 5.2593e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3160e-04 - val_loss: 5.4183e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3043e-04 - val_loss: 5.3880e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3172e-04 - val_loss: 5.3259e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2941e-04 - val_loss: 5.3315e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2650e-04 - val_loss: 5.1921e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3277e-04 - val_loss: 5.4998e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 8.2219e-04 - val_loss: 6.3724e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0382e-04 - val_loss: 5.8169e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7747e-04 - val_loss: 5.6739e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6544e-04 - val_loss: 5.6634e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6778e-04 - val_loss: 5.5995e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7693e-04 - val_loss: 5.7074e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6615e-04 - val_loss: 5.6189e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6924e-04 - val_loss: 6.1489e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8036e-04 - val_loss: 6.0504e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7815e-04 - val_loss: 5.6221e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5369e-04 - val_loss: 5.8927e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6459e-04 - val_loss: 5.6800e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5521e-04 - val_loss: 5.5873e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5295e-04 - val_loss: 5.5897e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5262e-04 - val_loss: 5.4574e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5044e-04 - val_loss: 5.5456e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6532e-04 - val_loss: 5.5027e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5328e-04 - val_loss: 5.5038e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5626e-04 - val_loss: 5.4515e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5719e-04 - val_loss: 5.8096e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9907e-04 - val_loss: 5.7280e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5045e-04 - val_loss: 5.6840e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8149e-04 - val_loss: 5.6986e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4997e-04 - val_loss: 5.4113e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5289e-04 - val_loss: 5.7237e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6513e-04 - val_loss: 5.5269e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4680e-04 - val_loss: 5.4754e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6814e-04 - val_loss: 5.6584e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5578e-04 - val_loss: 5.5204e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5763e-04 - val_loss: 5.7263e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7026e-04 - val_loss: 5.6465e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6489e-04 - val_loss: 5.8779e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5364e-04 - val_loss: 5.6836e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5899e-04 - val_loss: 5.4598e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4133e-04 - val_loss: 5.3868e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4999e-04 - val_loss: 5.5205e-04\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_11\\assets\n",
      " 12%|█████████                                                                  | 12/100 [2:12:53<16:36:54, 679.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6000e-04 - val_loss: 5.7525e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5395e-04 - val_loss: 5.3487e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4669e-04 - val_loss: 5.5624e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4540e-04 - val_loss: 5.8217e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4215e-04 - val_loss: 5.4123e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4333e-04 - val_loss: 5.5651e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4709e-04 - val_loss: 5.4893e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5128e-04 - val_loss: 5.3951e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4409e-04 - val_loss: 5.3378e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4212e-04 - val_loss: 5.4057e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5291e-04 - val_loss: 5.4774e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3881e-04 - val_loss: 5.3825e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4015e-04 - val_loss: 5.3911e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4027e-04 - val_loss: 5.4379e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4160e-04 - val_loss: 5.4482e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4704e-04 - val_loss: 5.4483e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5856e-04 - val_loss: 5.5453e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5069e-04 - val_loss: 5.4191e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4586e-04 - val_loss: 5.4738e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6447e-04 - val_loss: 5.4708e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4665e-04 - val_loss: 5.5768e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7463e-04 - val_loss: 5.6944e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5667e-04 - val_loss: 5.3842e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5978e-04 - val_loss: 5.6357e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6349e-04 - val_loss: 5.5047e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7487e-04 - val_loss: 5.4897e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4719e-04 - val_loss: 5.6495e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4792e-04 - val_loss: 5.5834e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5039e-04 - val_loss: 5.3238e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4673e-04 - val_loss: 5.3307e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5762e-04 - val_loss: 5.5646e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4681e-04 - val_loss: 5.5014e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4247e-04 - val_loss: 5.3883e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4537e-04 - val_loss: 5.4320e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6081e-04 - val_loss: 5.3184e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3754e-04 - val_loss: 5.4951e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4940e-04 - val_loss: 5.4000e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5048e-04 - val_loss: 5.3748e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4298e-04 - val_loss: 5.4415e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4279e-04 - val_loss: 5.4153e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3491e-04 - val_loss: 5.3046e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3259e-04 - val_loss: 5.3310e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3912e-04 - val_loss: 5.3239e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3913e-04 - val_loss: 5.5137e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4089e-04 - val_loss: 5.2830e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3636e-04 - val_loss: 5.3291e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3908e-04 - val_loss: 5.5009e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4473e-04 - val_loss: 5.4398e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4148e-04 - val_loss: 5.4512e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4078e-04 - val_loss: 5.3754e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4233e-04 - val_loss: 5.7678e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3500e-04 - val_loss: 5.5495e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3545e-04 - val_loss: 5.4735e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0233e-04 - val_loss: 5.5459e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4793e-04 - val_loss: 5.4278e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3972e-04 - val_loss: 5.3243e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3666e-04 - val_loss: 5.4173e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5802e-04 - val_loss: 5.4448e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5309e-04 - val_loss: 5.4739e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3846e-04 - val_loss: 5.4015e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4404e-04 - val_loss: 5.5219e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5370e-04 - val_loss: 5.4042e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4304e-04 - val_loss: 5.2901e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4367e-04 - val_loss: 5.3860e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4789e-04 - val_loss: 5.4432e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4662e-04 - val_loss: 5.3997e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3821e-04 - val_loss: 5.5640e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4359e-04 - val_loss: 5.4695e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4026e-04 - val_loss: 5.4354e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4172e-04 - val_loss: 5.4301e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6925e-04 - val_loss: 5.4510e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5521e-04 - val_loss: 5.4323e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4277e-04 - val_loss: 5.4547e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3440e-04 - val_loss: 5.3616e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4741e-04 - val_loss: 5.4347e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5039e-04 - val_loss: 5.5076e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4777e-04 - val_loss: 5.5205e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5377e-04 - val_loss: 5.5520e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5081e-04 - val_loss: 5.4915e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7869e-04 - val_loss: 5.4709e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3820e-04 - val_loss: 5.3455e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3692e-04 - val_loss: 5.7059e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4290e-04 - val_loss: 5.4180e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3967e-04 - val_loss: 5.3209e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3796e-04 - val_loss: 5.3469e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3131e-04 - val_loss: 5.3595e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5148e-04 - val_loss: 6.4663e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7279e-04 - val_loss: 5.4486e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4207e-04 - val_loss: 5.3925e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4404e-04 - val_loss: 5.4495e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5221e-04 - val_loss: 5.3575e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3343e-04 - val_loss: 5.3500e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3418e-04 - val_loss: 5.2871e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4788e-04 - val_loss: 5.4646e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4972e-04 - val_loss: 5.4283e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4360e-04 - val_loss: 5.3299e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3299e-04 - val_loss: 5.2749e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4143e-04 - val_loss: 5.4511e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4144e-04 - val_loss: 5.3638e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3247e-04 - val_loss: 5.4333e-04\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_12\\assets\n",
      " 13%|█████████▊                                                                 | 13/100 [2:24:40<16:37:14, 687.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3109e-04 - val_loss: 5.2296e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5722e-04 - val_loss: 5.5976e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8623e-04 - val_loss: 6.3937e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.2809e-04 - val_loss: 7.1734e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.5011e-04 - val_loss: 6.9797e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.2635e-04 - val_loss: 5.7137e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7085e-04 - val_loss: 5.6488e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7266e-04 - val_loss: 5.8861e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6333e-04 - val_loss: 5.5081e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5258e-04 - val_loss: 5.3534e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3689e-04 - val_loss: 5.3913e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3193e-04 - val_loss: 5.2320e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4728e-04 - val_loss: 5.8410e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4928e-04 - val_loss: 5.4533e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5166e-04 - val_loss: 5.6577e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4275e-04 - val_loss: 5.4199e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5006e-04 - val_loss: 5.4693e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4469e-04 - val_loss: 5.4096e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3781e-04 - val_loss: 5.2930e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3411e-04 - val_loss: 5.3514e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2849e-04 - val_loss: 5.4420e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3409e-04 - val_loss: 5.4088e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5387e-04 - val_loss: 5.7732e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5519e-04 - val_loss: 5.3800e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3591e-04 - val_loss: 5.2487e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2985e-04 - val_loss: 5.4177e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3907e-04 - val_loss: 5.5544e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6337e-04 - val_loss: 5.4757e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4472e-04 - val_loss: 5.4710e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4424e-04 - val_loss: 5.3091e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4021e-04 - val_loss: 5.4328e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3245e-04 - val_loss: 5.2888e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3396e-04 - val_loss: 5.2006e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2542e-04 - val_loss: 5.1613e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2981e-04 - val_loss: 5.3484e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3644e-04 - val_loss: 5.4774e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3721e-04 - val_loss: 5.2840e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3866e-04 - val_loss: 5.3773e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2772e-04 - val_loss: 5.2672e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2668e-04 - val_loss: 5.3658e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4181e-04 - val_loss: 5.3517e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4827e-04 - val_loss: 5.3879e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3658e-04 - val_loss: 5.2887e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3335e-04 - val_loss: 5.2842e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3717e-04 - val_loss: 5.2860e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3003e-04 - val_loss: 5.2298e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2549e-04 - val_loss: 5.3386e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3089e-04 - val_loss: 5.3306e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4023e-04 - val_loss: 5.4367e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3127e-04 - val_loss: 5.3310e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2299e-04 - val_loss: 5.3141e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2279e-04 - val_loss: 5.1088e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2614e-04 - val_loss: 5.2493e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3504e-04 - val_loss: 5.3420e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3891e-04 - val_loss: 5.3346e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5427e-04 - val_loss: 6.0579e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5255e-04 - val_loss: 5.3707e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4456e-04 - val_loss: 5.4225e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3528e-04 - val_loss: 5.2400e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3285e-04 - val_loss: 5.3071e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2683e-04 - val_loss: 5.2202e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2686e-04 - val_loss: 5.2712e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2797e-04 - val_loss: 5.3849e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3413e-04 - val_loss: 5.4064e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2418e-04 - val_loss: 5.3415e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2992e-04 - val_loss: 5.2061e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4050e-04 - val_loss: 5.4756e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3363e-04 - val_loss: 5.1927e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1995e-04 - val_loss: 5.1634e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2607e-04 - val_loss: 5.3637e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2084e-04 - val_loss: 5.3601e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2671e-04 - val_loss: 5.2607e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3867e-04 - val_loss: 5.1688e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3204e-04 - val_loss: 5.2818e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2573e-04 - val_loss: 5.4481e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3063e-04 - val_loss: 5.3410e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2340e-04 - val_loss: 5.2469e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2800e-04 - val_loss: 5.6417e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6214e-04 - val_loss: 5.3624e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4452e-04 - val_loss: 5.3500e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3315e-04 - val_loss: 5.3712e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3547e-04 - val_loss: 5.2782e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3507e-04 - val_loss: 5.2262e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2702e-04 - val_loss: 5.4250e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3725e-04 - val_loss: 5.4714e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4512e-04 - val_loss: 5.4066e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5636e-04 - val_loss: 5.4625e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3249e-04 - val_loss: 5.4187e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3401e-04 - val_loss: 5.3698e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6350e-04 - val_loss: 5.9805e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7727e-04 - val_loss: 5.6459e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6101e-04 - val_loss: 5.4231e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3033e-04 - val_loss: 5.1425e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2287e-04 - val_loss: 5.2258e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3193e-04 - val_loss: 5.4236e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6600e-04 - val_loss: 5.5519e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6504e-04 - val_loss: 5.7475e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8525e-04 - val_loss: 5.6830e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5431e-04 - val_loss: 5.2970e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4169e-04 - val_loss: 5.4623e-04\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_13\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_13\\assets\n",
      " 14%|██████████▌                                                                | 14/100 [2:36:13<16:28:03, 689.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5127e-04 - val_loss: 5.7758e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4644e-04 - val_loss: 5.3364e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2306e-04 - val_loss: 5.1532e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2784e-04 - val_loss: 5.2678e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5433e-04 - val_loss: 5.4394e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3950e-04 - val_loss: 5.5028e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4786e-04 - val_loss: 5.3055e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3520e-04 - val_loss: 5.2576e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3892e-04 - val_loss: 5.3853e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3633e-04 - val_loss: 5.3940e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2387e-04 - val_loss: 5.3296e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2815e-04 - val_loss: 5.2840e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4153e-04 - val_loss: 5.3725e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2397e-04 - val_loss: 5.4308e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5573e-04 - val_loss: 5.5785e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6099e-04 - val_loss: 5.4400e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4048e-04 - val_loss: 5.3517e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2580e-04 - val_loss: 5.2439e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1864e-04 - val_loss: 5.2747e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2587e-04 - val_loss: 5.4743e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5352e-04 - val_loss: 5.2586e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1637e-04 - val_loss: 5.1799e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3668e-04 - val_loss: 5.4259e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4005e-04 - val_loss: 5.4155e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4691e-04 - val_loss: 5.5087e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8098e-04 - val_loss: 6.3532e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8706e-04 - val_loss: 5.5591e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3810e-04 - val_loss: 5.3570e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2201e-04 - val_loss: 5.2787e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2589e-04 - val_loss: 5.2108e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2359e-04 - val_loss: 5.1874e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3429e-04 - val_loss: 5.4085e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3003e-04 - val_loss: 5.2818e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3318e-04 - val_loss: 5.2927e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2501e-04 - val_loss: 5.2157e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2361e-04 - val_loss: 5.3009e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2709e-04 - val_loss: 5.5207e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2972e-04 - val_loss: 5.3271e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2376e-04 - val_loss: 5.1182e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2366e-04 - val_loss: 5.6097e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4127e-04 - val_loss: 5.1968e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2252e-04 - val_loss: 5.2336e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2443e-04 - val_loss: 5.5556e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2238e-04 - val_loss: 5.0553e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1405e-04 - val_loss: 5.0871e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1539e-04 - val_loss: 5.2273e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1932e-04 - val_loss: 5.0947e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1810e-04 - val_loss: 5.2198e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2929e-04 - val_loss: 5.3197e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1562e-04 - val_loss: 5.2162e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5554e-04 - val_loss: 5.4854e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2440e-04 - val_loss: 5.0923e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1962e-04 - val_loss: 5.2019e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2874e-04 - val_loss: 5.6746e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3391e-04 - val_loss: 5.2999e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4584e-04 - val_loss: 5.3859e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3608e-04 - val_loss: 5.1705e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4513e-04 - val_loss: 6.0552e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0866e-04 - val_loss: 6.1265e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0388e-04 - val_loss: 6.1717e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.4368e-04 - val_loss: 6.6095e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.9248e-04 - val_loss: 6.2208e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1610e-04 - val_loss: 6.1272e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7679e-04 - val_loss: 5.5130e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5546e-04 - val_loss: 5.4335e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3856e-04 - val_loss: 5.3581e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2716e-04 - val_loss: 5.2638e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3835e-04 - val_loss: 5.2460e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2423e-04 - val_loss: 5.2127e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3388e-04 - val_loss: 5.3133e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2895e-04 - val_loss: 5.2139e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2819e-04 - val_loss: 5.2121e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2135e-04 - val_loss: 5.2030e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4972e-04 - val_loss: 5.4800e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2280e-04 - val_loss: 5.2114e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1950e-04 - val_loss: 5.1929e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1704e-04 - val_loss: 5.2742e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2609e-04 - val_loss: 5.3022e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2681e-04 - val_loss: 5.1268e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1729e-04 - val_loss: 5.1500e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1910e-04 - val_loss: 5.3871e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1943e-04 - val_loss: 5.1903e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1846e-04 - val_loss: 5.2203e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1873e-04 - val_loss: 5.2891e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2441e-04 - val_loss: 5.1420e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3864e-04 - val_loss: 5.7510e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3514e-04 - val_loss: 5.4381e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5134e-04 - val_loss: 5.3534e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4879e-04 - val_loss: 5.1974e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2417e-04 - val_loss: 5.2610e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3287e-04 - val_loss: 5.2387e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2495e-04 - val_loss: 5.1841e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1391e-04 - val_loss: 5.0467e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1428e-04 - val_loss: 5.2288e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2163e-04 - val_loss: 5.2840e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2331e-04 - val_loss: 5.2181e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2130e-04 - val_loss: 5.2334e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2552e-04 - val_loss: 5.1180e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2927e-04 - val_loss: 5.3296e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2254e-04 - val_loss: 5.7375e-04\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_14\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_14\\assets\n",
      " 15%|███████████▎                                                               | 15/100 [2:46:39<15:49:43, 670.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1937e-04 - val_loss: 5.1797e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2187e-04 - val_loss: 5.1081e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1491e-04 - val_loss: 5.2119e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1931e-04 - val_loss: 5.2395e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1918e-04 - val_loss: 5.1299e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1657e-04 - val_loss: 5.1644e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1202e-04 - val_loss: 5.1945e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1842e-04 - val_loss: 5.1842e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1437e-04 - val_loss: 5.3406e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1688e-04 - val_loss: 5.1500e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1940e-04 - val_loss: 5.2278e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2092e-04 - val_loss: 5.1863e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1593e-04 - val_loss: 5.1743e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2302e-04 - val_loss: 5.2571e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3225e-04 - val_loss: 5.5573e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2435e-04 - val_loss: 5.0928e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1099e-04 - val_loss: 5.3277e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4810e-04 - val_loss: 5.4983e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3184e-04 - val_loss: 5.4876e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3842e-04 - val_loss: 5.4800e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7404e-04 - val_loss: 5.6083e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6448e-04 - val_loss: 5.3912e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4167e-04 - val_loss: 5.2429e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3300e-04 - val_loss: 5.3846e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3004e-04 - val_loss: 5.5903e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4185e-04 - val_loss: 5.2898e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3793e-04 - val_loss: 5.3092e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2066e-04 - val_loss: 5.2704e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5298e-04 - val_loss: 5.4061e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6482e-04 - val_loss: 5.4298e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3329e-04 - val_loss: 5.1997e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4683e-04 - val_loss: 5.6252e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4798e-04 - val_loss: 5.1917e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1972e-04 - val_loss: 5.1689e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1129e-04 - val_loss: 5.1626e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1609e-04 - val_loss: 5.1092e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1232e-04 - val_loss: 5.2211e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2175e-04 - val_loss: 5.2023e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4229e-04 - val_loss: 5.5907e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3482e-04 - val_loss: 5.2508e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1580e-04 - val_loss: 5.1934e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2686e-04 - val_loss: 5.1898e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1355e-04 - val_loss: 5.1306e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2450e-04 - val_loss: 5.3336e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3398e-04 - val_loss: 5.6316e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4568e-04 - val_loss: 5.5132e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4422e-04 - val_loss: 5.2171e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2417e-04 - val_loss: 5.1275e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1158e-04 - val_loss: 5.0938e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1848e-04 - val_loss: 5.2672e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4318e-04 - val_loss: 5.9609e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7525e-04 - val_loss: 5.7898e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3763e-04 - val_loss: 5.4720e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1816e-04 - val_loss: 5.1440e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1124e-04 - val_loss: 5.2908e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2213e-04 - val_loss: 5.5918e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4951e-04 - val_loss: 5.7627e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3272e-04 - val_loss: 5.2690e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2271e-04 - val_loss: 5.1716e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2972e-04 - val_loss: 5.3261e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2038e-04 - val_loss: 5.2458e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2174e-04 - val_loss: 5.2800e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2519e-04 - val_loss: 5.3903e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3588e-04 - val_loss: 5.4110e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1530e-04 - val_loss: 5.1801e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2415e-04 - val_loss: 5.2893e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1471e-04 - val_loss: 5.1679e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3790e-04 - val_loss: 5.2467e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6136e-04 - val_loss: 5.5099e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3117e-04 - val_loss: 5.2256e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2621e-04 - val_loss: 5.3967e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0034e-04 - val_loss: 5.7937e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6459e-04 - val_loss: 5.5723e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4066e-04 - val_loss: 5.6059e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3345e-04 - val_loss: 5.3767e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2641e-04 - val_loss: 5.1282e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2180e-04 - val_loss: 5.2417e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.0972e-04 - val_loss: 5.1665e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1864e-04 - val_loss: 5.1308e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1259e-04 - val_loss: 5.0636e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1281e-04 - val_loss: 5.4308e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1706e-04 - val_loss: 5.1478e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4297e-04 - val_loss: 5.6025e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7519e-04 - val_loss: 5.4400e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9181e-04 - val_loss: 6.3126e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.5868e-04 - val_loss: 6.0809e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0608e-04 - val_loss: 6.2991e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2646e-04 - val_loss: 6.0841e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9714e-04 - val_loss: 6.1420e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9244e-04 - val_loss: 5.5382e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8564e-04 - val_loss: 6.1018e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.5024e-04 - val_loss: 7.0143e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0223e-04 - val_loss: 5.4493e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4654e-04 - val_loss: 5.6909e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8448e-04 - val_loss: 5.7309e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5598e-04 - val_loss: 5.4205e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5894e-04 - val_loss: 5.6635e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5293e-04 - val_loss: 5.3436e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2300e-04 - val_loss: 5.2499e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2151e-04 - val_loss: 5.1885e-04\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_15\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_15\\assets\n",
      " 16%|████████████                                                               | 16/100 [2:57:02<15:18:38, 656.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2952e-04 - val_loss: 5.4777e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5319e-04 - val_loss: 5.8304e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6717e-04 - val_loss: 5.5379e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5103e-04 - val_loss: 5.5802e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6164e-04 - val_loss: 6.0201e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6509e-04 - val_loss: 5.4908e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3205e-04 - val_loss: 5.2876e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2382e-04 - val_loss: 5.2328e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4616e-04 - val_loss: 5.4891e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6597e-04 - val_loss: 6.0885e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1040e-04 - val_loss: 5.7743e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5590e-04 - val_loss: 5.5556e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4442e-04 - val_loss: 5.2734e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3417e-04 - val_loss: 5.4288e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4325e-04 - val_loss: 5.4552e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2899e-04 - val_loss: 5.2848e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2036e-04 - val_loss: 5.4561e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2159e-04 - val_loss: 5.1975e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1603e-04 - val_loss: 5.3506e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1851e-04 - val_loss: 5.1990e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2425e-04 - val_loss: 5.4179e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3598e-04 - val_loss: 5.2367e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1479e-04 - val_loss: 5.1245e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.0902e-04 - val_loss: 5.1387e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1726e-04 - val_loss: 5.2573e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1003e-04 - val_loss: 5.1364e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1198e-04 - val_loss: 5.0481e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1550e-04 - val_loss: 5.2558e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4755e-04 - val_loss: 5.0989e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2131e-04 - val_loss: 5.1899e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2243e-04 - val_loss: 5.3133e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1477e-04 - val_loss: 5.2543e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2056e-04 - val_loss: 5.2348e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1814e-04 - val_loss: 5.2224e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2716e-04 - val_loss: 5.2001e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1278e-04 - val_loss: 5.6093e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1627e-04 - val_loss: 5.3870e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1929e-04 - val_loss: 5.2908e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3080e-04 - val_loss: 5.3324e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1872e-04 - val_loss: 5.4243e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2888e-04 - val_loss: 5.1397e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1701e-04 - val_loss: 5.4585e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1972e-04 - val_loss: 5.0844e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.0404e-04 - val_loss: 5.0422e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1783e-04 - val_loss: 5.3126e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2487e-04 - val_loss: 5.4697e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4433e-04 - val_loss: 5.6745e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2705e-04 - val_loss: 5.1810e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3916e-04 - val_loss: 5.1381e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2838e-04 - val_loss: 5.4686e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2272e-04 - val_loss: 5.1325e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1126e-04 - val_loss: 5.2473e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2119e-04 - val_loss: 5.0992e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3129e-04 - val_loss: 5.2216e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3124e-04 - val_loss: 5.4571e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2397e-04 - val_loss: 5.2347e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.0861e-04 - val_loss: 5.1788e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1450e-04 - val_loss: 5.2482e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2590e-04 - val_loss: 5.4406e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5205e-04 - val_loss: 5.7145e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4309e-04 - val_loss: 5.3762e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1951e-04 - val_loss: 5.1995e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1228e-04 - val_loss: 5.1888e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1269e-04 - val_loss: 5.1113e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2117e-04 - val_loss: 5.1693e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1905e-04 - val_loss: 5.2394e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2429e-04 - val_loss: 5.2575e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1680e-04 - val_loss: 5.1580e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2669e-04 - val_loss: 5.0650e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1668e-04 - val_loss: 5.4339e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2265e-04 - val_loss: 5.2327e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2830e-04 - val_loss: 5.7348e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6173e-04 - val_loss: 5.3615e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2516e-04 - val_loss: 5.0215e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2200e-04 - val_loss: 5.0209e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1956e-04 - val_loss: 5.3614e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4395e-04 - val_loss: 5.4240e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0994e-04 - val_loss: 5.0743e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.0427e-04 - val_loss: 5.3153e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3407e-04 - val_loss: 5.7311e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3744e-04 - val_loss: 5.5842e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5717e-04 - val_loss: 5.4929e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4087e-04 - val_loss: 5.4591e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4055e-04 - val_loss: 5.7085e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3101e-04 - val_loss: 5.2652e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2446e-04 - val_loss: 5.3147e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5544e-04 - val_loss: 5.5995e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6960e-04 - val_loss: 5.9032e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8219e-04 - val_loss: 5.8721e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6191e-04 - val_loss: 5.3339e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5598e-04 - val_loss: 5.6640e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3667e-04 - val_loss: 5.2374e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2825e-04 - val_loss: 5.2304e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3039e-04 - val_loss: 5.7568e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3476e-04 - val_loss: 5.4141e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2531e-04 - val_loss: 5.0853e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.0677e-04 - val_loss: 5.0888e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4202e-04 - val_loss: 5.5372e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5766e-04 - val_loss: 5.5423e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5181e-04 - val_loss: 5.2611e-04\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_16\\assets\n",
      " 17%|████████████▊                                                              | 17/100 [3:07:31<14:56:19, 647.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1418e-04 - val_loss: 5.0676e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.0737e-04 - val_loss: 5.0322e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0655e-04 - val_loss: 5.1294e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.0223e-04 - val_loss: 5.0470e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2818e-04 - val_loss: 6.1636e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.4012e-04 - val_loss: 6.4855e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0594e-04 - val_loss: 5.9330e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8876e-04 - val_loss: 5.9390e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0517e-04 - val_loss: 5.9799e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2519e-04 - val_loss: 6.1428e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1217e-04 - val_loss: 7.7791e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.6340e-04 - val_loss: 6.5753e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.3784e-04 - val_loss: 6.2529e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2203e-04 - val_loss: 5.9226e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0247e-04 - val_loss: 5.9555e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1546e-04 - val_loss: 6.0088e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9504e-04 - val_loss: 5.8360e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0455e-04 - val_loss: 6.0176e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8733e-04 - val_loss: 5.9089e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8039e-04 - val_loss: 5.8425e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7825e-04 - val_loss: 5.7634e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7671e-04 - val_loss: 5.7918e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7105e-04 - val_loss: 5.7939e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7825e-04 - val_loss: 5.9072e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0318e-04 - val_loss: 5.7655e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7156e-04 - val_loss: 5.6192e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6661e-04 - val_loss: 5.5737e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6633e-04 - val_loss: 5.6125e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8502e-04 - val_loss: 6.6973e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0587e-04 - val_loss: 5.7085e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7025e-04 - val_loss: 5.5448e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5890e-04 - val_loss: 5.8784e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5994e-04 - val_loss: 5.7697e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6088e-04 - val_loss: 5.7092e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6357e-04 - val_loss: 5.6538e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6115e-04 - val_loss: 5.5524e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6343e-04 - val_loss: 5.7357e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6170e-04 - val_loss: 5.7554e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8256e-04 - val_loss: 5.5891e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5811e-04 - val_loss: 0.0010\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4988e-04 - val_loss: 6.3372e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5570e-04 - val_loss: 5.7276e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4751e-04 - val_loss: 6.0743e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5448e-04 - val_loss: 5.4350e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4428e-04 - val_loss: 5.4716e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5536e-04 - val_loss: 5.3889e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4375e-04 - val_loss: 5.5984e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5120e-04 - val_loss: 5.6489e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5063e-04 - val_loss: 5.6045e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4514e-04 - val_loss: 5.4984e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5128e-04 - val_loss: 5.4517e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6753e-04 - val_loss: 5.6845e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5086e-04 - val_loss: 5.5131e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5307e-04 - val_loss: 5.6466e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4477e-04 - val_loss: 5.3762e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5146e-04 - val_loss: 5.6180e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4428e-04 - val_loss: 5.3333e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4700e-04 - val_loss: 5.5370e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5822e-04 - val_loss: 5.4875e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4241e-04 - val_loss: 5.4014e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8158e-04 - val_loss: 7.4528e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2266e-04 - val_loss: 5.8643e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.4523e-04 - val_loss: 6.8305e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.5861e-04 - val_loss: 6.2049e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2592e-04 - val_loss: 6.1663e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9204e-04 - val_loss: 5.6265e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6532e-04 - val_loss: 5.6060e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7427e-04 - val_loss: 6.2170e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0033e-04 - val_loss: 5.9276e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.3742e-04 - val_loss: 6.1706e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1351e-04 - val_loss: 5.9452e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9816e-04 - val_loss: 5.9297e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9156e-04 - val_loss: 5.8396e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0065e-04 - val_loss: 5.8538e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8522e-04 - val_loss: 5.6033e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5624e-04 - val_loss: 5.4456e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5184e-04 - val_loss: 5.7868e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3955e-04 - val_loss: 5.3501e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4781e-04 - val_loss: 5.4228e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4378e-04 - val_loss: 5.4696e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5801e-04 - val_loss: 5.6512e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4850e-04 - val_loss: 5.7204e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6041e-04 - val_loss: 5.7180e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8170e-04 - val_loss: 5.6043e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7067e-04 - val_loss: 5.8232e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2940e-04 - val_loss: 6.5275e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2008e-04 - val_loss: 6.3083e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9787e-04 - val_loss: 5.8428e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2849e-04 - val_loss: 7.1263e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2235e-04 - val_loss: 6.0663e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.4626e-04 - val_loss: 6.2796e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1409e-04 - val_loss: 6.2096e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1628e-04 - val_loss: 6.4284e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0303e-04 - val_loss: 6.1909e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.2393e-04 - val_loss: 6.1199e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1596e-04 - val_loss: 6.3048e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0474e-04 - val_loss: 5.9597e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0138e-04 - val_loss: 6.1659e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0768e-04 - val_loss: 6.0070e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9991e-04 - val_loss: 5.9432e-04\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_17\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_17\\assets\n",
      " 18%|█████████████▌                                                             | 18/100 [3:17:57<14:36:33, 641.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0437e-04 - val_loss: 6.1594e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9422e-04 - val_loss: 5.8512e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0024e-04 - val_loss: 6.0156e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9360e-04 - val_loss: 6.0985e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0173e-04 - val_loss: 6.0762e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2197e-04 - val_loss: 5.7533e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9175e-04 - val_loss: 6.0685e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1263e-04 - val_loss: 5.8182e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9738e-04 - val_loss: 6.0283e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0244e-04 - val_loss: 5.8368e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1896e-04 - val_loss: 6.2582e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0253e-04 - val_loss: 5.9093e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9946e-04 - val_loss: 5.9674e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0286e-04 - val_loss: 5.8703e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9290e-04 - val_loss: 5.9679e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0922e-04 - val_loss: 6.1795e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0746e-04 - val_loss: 6.4174e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1065e-04 - val_loss: 6.1967e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0379e-04 - val_loss: 5.9444e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9865e-04 - val_loss: 5.9775e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9434e-04 - val_loss: 6.0118e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0547e-04 - val_loss: 6.0673e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0383e-04 - val_loss: 5.9994e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9951e-04 - val_loss: 6.1223e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0769e-04 - val_loss: 5.8776e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9107e-04 - val_loss: 5.8345e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1038e-04 - val_loss: 5.8833e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9845e-04 - val_loss: 5.8934e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9471e-04 - val_loss: 5.7878e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8612e-04 - val_loss: 5.8097e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8770e-04 - val_loss: 5.8394e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9452e-04 - val_loss: 5.9028e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9711e-04 - val_loss: 6.0457e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8091e-04 - val_loss: 5.8077e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9166e-04 - val_loss: 5.6782e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8531e-04 - val_loss: 6.0928e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0316e-04 - val_loss: 5.7504e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8523e-04 - val_loss: 5.8647e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8581e-04 - val_loss: 5.8185e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0286e-04 - val_loss: 5.8397e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8826e-04 - val_loss: 5.8260e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8725e-04 - val_loss: 5.8764e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1364e-04 - val_loss: 5.9023e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9433e-04 - val_loss: 5.9265e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8704e-04 - val_loss: 5.8249e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8640e-04 - val_loss: 5.7323e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7880e-04 - val_loss: 5.9912e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8655e-04 - val_loss: 5.7556e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8082e-04 - val_loss: 5.7297e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8463e-04 - val_loss: 5.6834e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8246e-04 - val_loss: 5.7752e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8531e-04 - val_loss: 5.6349e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7448e-04 - val_loss: 5.8791e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7597e-04 - val_loss: 5.7200e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8121e-04 - val_loss: 5.6242e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8127e-04 - val_loss: 5.6985e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7999e-04 - val_loss: 5.6687e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8886e-04 - val_loss: 5.8356e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8756e-04 - val_loss: 5.8100e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8737e-04 - val_loss: 5.8246e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8910e-04 - val_loss: 5.6519e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7803e-04 - val_loss: 5.9097e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7592e-04 - val_loss: 5.7197e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8141e-04 - val_loss: 5.8474e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8814e-04 - val_loss: 5.6787e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7997e-04 - val_loss: 5.6930e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7451e-04 - val_loss: 5.6683e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9674e-04 - val_loss: 5.9985e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2928e-04 - val_loss: 5.8369e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8856e-04 - val_loss: 5.6863e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7382e-04 - val_loss: 5.6155e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6562e-04 - val_loss: 5.5858e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7692e-04 - val_loss: 6.2247e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7301e-04 - val_loss: 5.6929e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7165e-04 - val_loss: 5.5722e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6866e-04 - val_loss: 5.7125e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8666e-04 - val_loss: 5.6406e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7585e-04 - val_loss: 5.6515e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6896e-04 - val_loss: 5.6849e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7824e-04 - val_loss: 6.2241e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9076e-04 - val_loss: 5.7861e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7424e-04 - val_loss: 5.8506e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7196e-04 - val_loss: 6.0742e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7917e-04 - val_loss: 5.7780e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7514e-04 - val_loss: 5.5312e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6519e-04 - val_loss: 6.2858e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6664e-04 - val_loss: 5.6236e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7552e-04 - val_loss: 5.6641e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7667e-04 - val_loss: 5.7057e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6998e-04 - val_loss: 5.6655e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7436e-04 - val_loss: 5.6305e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6590e-04 - val_loss: 5.6138e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6578e-04 - val_loss: 5.7905e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7933e-04 - val_loss: 5.6920e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6352e-04 - val_loss: 5.9180e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6059e-04 - val_loss: 5.8670e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7006e-04 - val_loss: 5.5931e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 7.1211e-04 - val_loss: 6.2941e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2341e-04 - val_loss: 5.7841e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8881e-04 - val_loss: 5.6734e-04\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_18\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_18\\assets\n",
      " 19%|██████████████▎                                                            | 19/100 [3:28:28<14:21:40, 638.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9875e-04 - val_loss: 5.6812e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8052e-04 - val_loss: 5.6339e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7396e-04 - val_loss: 5.8096e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8286e-04 - val_loss: 5.7628e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8711e-04 - val_loss: 5.6588e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7365e-04 - val_loss: 5.5648e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8375e-04 - val_loss: 6.3352e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6783e-04 - val_loss: 5.6027e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7734e-04 - val_loss: 5.6205e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7010e-04 - val_loss: 5.6546e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6753e-04 - val_loss: 5.6215e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6470e-04 - val_loss: 5.8546e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7143e-04 - val_loss: 5.7393e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8311e-04 - val_loss: 5.5216e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6513e-04 - val_loss: 5.6976e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7265e-04 - val_loss: 5.5984e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6852e-04 - val_loss: 5.9092e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7533e-04 - val_loss: 5.6141e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6289e-04 - val_loss: 5.6903e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5595e-04 - val_loss: 5.4324e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6686e-04 - val_loss: 5.6275e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7320e-04 - val_loss: 5.6580e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5893e-04 - val_loss: 5.4345e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5849e-04 - val_loss: 5.4821e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6847e-04 - val_loss: 6.0095e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8037e-04 - val_loss: 5.6662e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8120e-04 - val_loss: 6.1962e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8945e-04 - val_loss: 5.6681e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6790e-04 - val_loss: 5.7259e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6329e-04 - val_loss: 5.6580e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5926e-04 - val_loss: 5.5671e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6729e-04 - val_loss: 5.5700e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7173e-04 - val_loss: 5.8660e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6892e-04 - val_loss: 5.6149e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6395e-04 - val_loss: 5.5390e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8524e-04 - val_loss: 5.5423e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7335e-04 - val_loss: 5.7204e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6782e-04 - val_loss: 5.7620e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6734e-04 - val_loss: 5.4185e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6441e-04 - val_loss: 5.5091e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5378e-04 - val_loss: 5.6459e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6382e-04 - val_loss: 6.1916e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7147e-04 - val_loss: 6.0543e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8664e-04 - val_loss: 6.0114e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6595e-04 - val_loss: 5.6403e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6106e-04 - val_loss: 5.5072e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6253e-04 - val_loss: 5.7056e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6536e-04 - val_loss: 5.5731e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5284e-04 - val_loss: 5.3091e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5617e-04 - val_loss: 5.6328e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5245e-04 - val_loss: 5.4676e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6824e-04 - val_loss: 5.5179e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4771e-04 - val_loss: 5.5179e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6176e-04 - val_loss: 5.7454e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5886e-04 - val_loss: 5.5129e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5628e-04 - val_loss: 5.4618e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5334e-04 - val_loss: 5.4487e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6232e-04 - val_loss: 5.8363e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6684e-04 - val_loss: 5.7327e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7178e-04 - val_loss: 5.4805e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6846e-04 - val_loss: 5.3144e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5885e-04 - val_loss: 5.5063e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5695e-04 - val_loss: 5.4400e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5347e-04 - val_loss: 5.6319e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5237e-04 - val_loss: 5.5941e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7120e-04 - val_loss: 5.9046e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6456e-04 - val_loss: 5.5304e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4709e-04 - val_loss: 5.4286e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5482e-04 - val_loss: 5.8278e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6026e-04 - val_loss: 5.9044e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5313e-04 - val_loss: 5.3132e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5397e-04 - val_loss: 5.5621e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6752e-04 - val_loss: 5.3241e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5046e-04 - val_loss: 5.4939e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6105e-04 - val_loss: 5.5608e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6076e-04 - val_loss: 5.5661e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4890e-04 - val_loss: 5.5103e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5393e-04 - val_loss: 5.6060e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5675e-04 - val_loss: 5.5194e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5192e-04 - val_loss: 5.6848e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7050e-04 - val_loss: 5.7426e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6815e-04 - val_loss: 5.5881e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6960e-04 - val_loss: 5.7699e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5219e-04 - val_loss: 5.4612e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5679e-04 - val_loss: 5.9145e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7720e-04 - val_loss: 5.7681e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7176e-04 - val_loss: 5.6525e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7061e-04 - val_loss: 5.5498e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6554e-04 - val_loss: 6.0018e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7074e-04 - val_loss: 5.5336e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4935e-04 - val_loss: 5.5548e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6514e-04 - val_loss: 5.5844e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5721e-04 - val_loss: 5.4485e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6223e-04 - val_loss: 5.8036e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6247e-04 - val_loss: 6.0321e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5467e-04 - val_loss: 5.5731e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5467e-04 - val_loss: 5.5356e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5832e-04 - val_loss: 5.6915e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8229e-04 - val_loss: 5.5219e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6661e-04 - val_loss: 5.4186e-04\n",
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-7b7683302978>:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize = (8, 6));\n",
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_19\\assets\n",
      " 20%|███████████████                                                            | 20/100 [3:39:04<14:10:09, 637.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6270e-04 - val_loss: 5.3502e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5234e-04 - val_loss: 5.6242e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6112e-04 - val_loss: 5.7171e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5753e-04 - val_loss: 5.8418e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0166e-04 - val_loss: 6.3963e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8717e-04 - val_loss: 5.7015e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6355e-04 - val_loss: 5.6754e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5767e-04 - val_loss: 5.7669e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5695e-04 - val_loss: 5.5378e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6796e-04 - val_loss: 5.6377e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7189e-04 - val_loss: 5.9683e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6376e-04 - val_loss: 5.6194e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8811e-04 - val_loss: 5.5250e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4988e-04 - val_loss: 5.3727e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4994e-04 - val_loss: 5.4942e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4747e-04 - val_loss: 5.3560e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5624e-04 - val_loss: 5.6214e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7203e-04 - val_loss: 6.1357e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7464e-04 - val_loss: 5.6318e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5852e-04 - val_loss: 5.3787e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7383e-04 - val_loss: 5.8501e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6434e-04 - val_loss: 5.4525e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5219e-04 - val_loss: 5.3853e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4669e-04 - val_loss: 5.5134e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4851e-04 - val_loss: 5.4988e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5639e-04 - val_loss: 5.6177e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5189e-04 - val_loss: 5.4046e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4394e-04 - val_loss: 5.5078e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5585e-04 - val_loss: 5.3053e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4580e-04 - val_loss: 5.3979e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3956e-04 - val_loss: 5.4354e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5531e-04 - val_loss: 5.4630e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4725e-04 - val_loss: 5.3750e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4729e-04 - val_loss: 5.4651e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6282e-04 - val_loss: 5.2548e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3956e-04 - val_loss: 5.3723e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5415e-04 - val_loss: 5.6311e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5820e-04 - val_loss: 5.4560e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6345e-04 - val_loss: 5.7761e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5036e-04 - val_loss: 5.3996e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4685e-04 - val_loss: 5.4609e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4921e-04 - val_loss: 5.3189e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4330e-04 - val_loss: 5.4531e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5178e-04 - val_loss: 5.6111e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4490e-04 - val_loss: 5.4563e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4562e-04 - val_loss: 5.3261e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4504e-04 - val_loss: 5.2955e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7610e-04 - val_loss: 5.6288e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5924e-04 - val_loss: 5.7859e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5408e-04 - val_loss: 5.9809e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5577e-04 - val_loss: 5.5529e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4937e-04 - val_loss: 5.3208e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4421e-04 - val_loss: 5.5383e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5901e-04 - val_loss: 5.6123e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4476e-04 - val_loss: 5.3385e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4661e-04 - val_loss: 5.3509e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4251e-04 - val_loss: 5.2979e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4440e-04 - val_loss: 5.7949e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4204e-04 - val_loss: 5.4775e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5237e-04 - val_loss: 5.3071e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6703e-04 - val_loss: 5.2544e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4040e-04 - val_loss: 5.2583e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4499e-04 - val_loss: 5.2823e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5937e-04 - val_loss: 5.5335e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3959e-04 - val_loss: 5.3669e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3744e-04 - val_loss: 5.3474e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3960e-04 - val_loss: 5.4463e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4455e-04 - val_loss: 5.6727e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6153e-04 - val_loss: 5.6530e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5757e-04 - val_loss: 5.5151e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5401e-04 - val_loss: 5.5245e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6334e-04 - val_loss: 6.1693e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5769e-04 - val_loss: 5.4813e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5264e-04 - val_loss: 5.5173e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4187e-04 - val_loss: 5.5174e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4607e-04 - val_loss: 5.4110e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3277e-04 - val_loss: 5.3892e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4231e-04 - val_loss: 5.2328e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3673e-04 - val_loss: 5.4414e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3834e-04 - val_loss: 5.3316e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4279e-04 - val_loss: 5.6404e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4885e-04 - val_loss: 5.6061e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3640e-04 - val_loss: 5.3072e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3625e-04 - val_loss: 5.3775e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4982e-04 - val_loss: 5.4100e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4455e-04 - val_loss: 5.5763e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4967e-04 - val_loss: 5.5933e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3502e-04 - val_loss: 5.3231e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3644e-04 - val_loss: 5.4090e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4741e-04 - val_loss: 5.7004e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4977e-04 - val_loss: 5.3907e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4233e-04 - val_loss: 5.2289e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3209e-04 - val_loss: 5.3036e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3620e-04 - val_loss: 5.4463e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5681e-04 - val_loss: 5.3207e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4642e-04 - val_loss: 5.3300e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4038e-04 - val_loss: 5.8021e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4336e-04 - val_loss: 5.3759e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4117e-04 - val_loss: 5.5156e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4227e-04 - val_loss: 5.4833e-04\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_20\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_20\\assets\n",
      " 21%|███████████████▌                                                          | 21/100 [4:42:33<34:52:16, 1589.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4201e-04 - val_loss: 5.3989e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3895e-04 - val_loss: 5.3355e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4475e-04 - val_loss: 5.5404e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4188e-04 - val_loss: 5.1879e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3384e-04 - val_loss: 5.4563e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3860e-04 - val_loss: 5.3354e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5758e-04 - val_loss: 5.8582e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4251e-04 - val_loss: 5.5352e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3565e-04 - val_loss: 5.6764e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4792e-04 - val_loss: 5.2964e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4260e-04 - val_loss: 5.5947e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 5.6408e-04 - val_loss: 5.3329e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3529e-04 - val_loss: 5.2777e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3310e-04 - val_loss: 5.3141e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2944e-04 - val_loss: 5.2692e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3757e-04 - val_loss: 5.4646e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4275e-04 - val_loss: 6.5508e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5791e-04 - val_loss: 5.7099e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.6796e-04 - val_loss: 5.3816e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4952e-04 - val_loss: 5.3897e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4014e-04 - val_loss: 5.4257e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4597e-04 - val_loss: 5.6438e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4817e-04 - val_loss: 5.4805e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4718e-04 - val_loss: 5.3546e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4877e-04 - val_loss: 5.2761e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3661e-04 - val_loss: 5.3630e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3826e-04 - val_loss: 5.3079e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4368e-04 - val_loss: 5.5573e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3069e-04 - val_loss: 5.1988e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4120e-04 - val_loss: 5.5020e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4333e-04 - val_loss: 5.4868e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4068e-04 - val_loss: 5.2844e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4533e-04 - val_loss: 5.5077e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6688e-04 - val_loss: 5.9164e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4913e-04 - val_loss: 5.5493e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.7596e-04 - val_loss: 6.1310e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3934e-04 - val_loss: 5.3117e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5032e-04 - val_loss: 0.0011\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 6.5347e-04 - val_loss: 5.7519e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.7544e-04 - val_loss: 5.5869e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6186e-04 - val_loss: 5.3346e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4147e-04 - val_loss: 5.4898e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4909e-04 - val_loss: 5.4320e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5179e-04 - val_loss: 5.3964e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4598e-04 - val_loss: 5.4927e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4757e-04 - val_loss: 5.4274e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3608e-04 - val_loss: 5.4623e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3600e-04 - val_loss: 5.3893e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4380e-04 - val_loss: 5.3120e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4551e-04 - val_loss: 5.3706e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3729e-04 - val_loss: 5.3029e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5148e-04 - val_loss: 5.9069e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4033e-04 - val_loss: 5.3384e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3870e-04 - val_loss: 5.2805e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2831e-04 - val_loss: 5.2208e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5049e-04 - val_loss: 5.3525e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4451e-04 - val_loss: 5.5000e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5078e-04 - val_loss: 5.4165e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4569e-04 - val_loss: 5.4547e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3159e-04 - val_loss: 5.3832e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3407e-04 - val_loss: 5.6426e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5557e-04 - val_loss: 5.6448e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4916e-04 - val_loss: 6.1589e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5071e-04 - val_loss: 5.5619e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3905e-04 - val_loss: 5.2740e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3650e-04 - val_loss: 5.2975e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4848e-04 - val_loss: 5.5869e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4479e-04 - val_loss: 5.5258e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4106e-04 - val_loss: 5.3453e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5511e-04 - val_loss: 6.3569e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.7029e-04 - val_loss: 5.5689e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4761e-04 - val_loss: 5.4006e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4504e-04 - val_loss: 5.7002e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5433e-04 - val_loss: 5.5282e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4567e-04 - val_loss: 5.5189e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3270e-04 - val_loss: 5.2059e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4029e-04 - val_loss: 5.6728e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3298e-04 - val_loss: 5.4539e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3859e-04 - val_loss: 5.4164e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.2945e-04 - val_loss: 5.2820e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.4169e-04 - val_loss: 5.7412e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2984e-04 - val_loss: 5.1364e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3618e-04 - val_loss: 5.1068e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2844e-04 - val_loss: 5.2261e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4484e-04 - val_loss: 5.5126e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7288e-04 - val_loss: 5.3636e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6688e-04 - val_loss: 5.4015e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3449e-04 - val_loss: 5.2487e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4992e-04 - val_loss: 5.8018e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.7119e-04 - val_loss: 5.6368e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4910e-04 - val_loss: 5.6967e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3821e-04 - val_loss: 5.5928e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3347e-04 - val_loss: 5.2584e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 9.5312e-04 - val_loss: 6.8198e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 6.0879e-04 - val_loss: 5.7994e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.8455e-04 - val_loss: 5.8776e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.7861e-04 - val_loss: 6.2065e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.7526e-04 - val_loss: 5.7770e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.6999e-04 - val_loss: 5.6071e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5458e-04 - val_loss: 5.5435e-04\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_21\\assets\n",
      " 22%|████████████████▎                                                         | 22/100 [5:08:43<34:18:29, 1583.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5872e-04 - val_loss: 6.0174e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7180e-04 - val_loss: 5.8047e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7873e-04 - val_loss: 5.6917e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.7054e-04 - val_loss: 5.6272e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.7227e-04 - val_loss: 5.8128e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.7107e-04 - val_loss: 5.7078e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6342e-04 - val_loss: 5.5709e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.7009e-04 - val_loss: 5.6232e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6496e-04 - val_loss: 5.6004e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5769e-04 - val_loss: 5.5147e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5774e-04 - val_loss: 5.9327e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.7927e-04 - val_loss: 5.5091e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5367e-04 - val_loss: 6.3097e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5968e-04 - val_loss: 5.5326e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4685e-04 - val_loss: 5.4085e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5279e-04 - val_loss: 5.5399e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6149e-04 - val_loss: 5.5481e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6899e-04 - val_loss: 5.5198e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6479e-04 - val_loss: 5.4445e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5843e-04 - val_loss: 5.4648e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5894e-04 - val_loss: 5.6212e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.7121e-04 - val_loss: 5.7554e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6091e-04 - val_loss: 5.4992e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4739e-04 - val_loss: 5.6004e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4163e-04 - val_loss: 5.4586e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4953e-04 - val_loss: 5.3837e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5863e-04 - val_loss: 5.4664e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4733e-04 - val_loss: 5.4614e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5923e-04 - val_loss: 5.7289e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5478e-04 - val_loss: 5.4602e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4376e-04 - val_loss: 5.3101e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4399e-04 - val_loss: 5.4326e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4347e-04 - val_loss: 5.3949e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4584e-04 - val_loss: 5.3487e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3071e-04 - val_loss: 5.3274e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3820e-04 - val_loss: 5.4348e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4290e-04 - val_loss: 5.3904e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4457e-04 - val_loss: 6.2895e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4080e-04 - val_loss: 5.1868e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3238e-04 - val_loss: 5.2777e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4419e-04 - val_loss: 5.3617e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5013e-04 - val_loss: 5.5569e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5494e-04 - val_loss: 5.8619e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4854e-04 - val_loss: 5.4673e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6145e-04 - val_loss: 6.2967e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.8437e-04 - val_loss: 5.8035e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5941e-04 - val_loss: 5.4979e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3173e-04 - val_loss: 5.3515e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3271e-04 - val_loss: 5.2828e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3436e-04 - val_loss: 5.3251e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5235e-04 - val_loss: 6.0182e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5996e-04 - val_loss: 5.4442e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6446e-04 - val_loss: 5.8143e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4773e-04 - val_loss: 5.3261e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4421e-04 - val_loss: 5.5523e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4675e-04 - val_loss: 5.6437e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3818e-04 - val_loss: 5.3262e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4540e-04 - val_loss: 5.3736e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4681e-04 - val_loss: 5.5063e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3899e-04 - val_loss: 5.3825e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4532e-04 - val_loss: 5.6755e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4858e-04 - val_loss: 5.4600e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3527e-04 - val_loss: 5.2161e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2870e-04 - val_loss: 5.3092e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2756e-04 - val_loss: 5.1569e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1986e-04 - val_loss: 5.2100e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3189e-04 - val_loss: 5.2005e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3383e-04 - val_loss: 5.3155e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2406e-04 - val_loss: 5.1354e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1815e-04 - val_loss: 5.1921e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3607e-04 - val_loss: 5.3198e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5886e-04 - val_loss: 5.7207e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5055e-04 - val_loss: 5.5532e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4330e-04 - val_loss: 5.3339e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5757e-04 - val_loss: 5.9349e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3938e-04 - val_loss: 5.4064e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2814e-04 - val_loss: 5.2439e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1873e-04 - val_loss: 5.2181e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3886e-04 - val_loss: 5.2005e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2207e-04 - val_loss: 5.1874e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2442e-04 - val_loss: 5.3978e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3586e-04 - val_loss: 5.2950e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2958e-04 - val_loss: 5.1495e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2359e-04 - val_loss: 5.2303e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3678e-04 - val_loss: 5.4788e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2795e-04 - val_loss: 5.4173e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2884e-04 - val_loss: 5.9199e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3410e-04 - val_loss: 5.5180e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.1932e-04 - val_loss: 5.1992e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2516e-04 - val_loss: 5.1304e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2739e-04 - val_loss: 5.1684e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2060e-04 - val_loss: 5.1858e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2569e-04 - val_loss: 5.4483e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2260e-04 - val_loss: 5.2776e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2190e-04 - val_loss: 5.4123e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2575e-04 - val_loss: 5.2942e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3403e-04 - val_loss: 5.5177e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2770e-04 - val_loss: 5.3640e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4474e-04 - val_loss: 5.4805e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4074e-04 - val_loss: 5.1557e-04\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_22\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_22\\assets\n",
      " 23%|████████████████▌                                                       | 23/100 [11:20:46<166:56:42, 7805.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2382e-04 - val_loss: 5.5270e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4114e-04 - val_loss: 5.6841e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2851e-04 - val_loss: 5.0800e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2350e-04 - val_loss: 5.1312e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2296e-04 - val_loss: 5.0516e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2028e-04 - val_loss: 5.1881e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2005e-04 - val_loss: 5.2259e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3501e-04 - val_loss: 5.5592e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3972e-04 - val_loss: 5.2663e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2852e-04 - val_loss: 5.2168e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2021e-04 - val_loss: 5.1633e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3365e-04 - val_loss: 5.0224e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1812e-04 - val_loss: 5.0830e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4393e-04 - val_loss: 6.0267e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4944e-04 - val_loss: 5.3906e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3395e-04 - val_loss: 5.1800e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2286e-04 - val_loss: 5.3373e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2215e-04 - val_loss: 5.2239e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3235e-04 - val_loss: 6.2166e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5331e-04 - val_loss: 5.4707e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5545e-04 - val_loss: 5.3910e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4671e-04 - val_loss: 5.2699e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2845e-04 - val_loss: 5.4194e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4183e-04 - val_loss: 5.4716e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5280e-04 - val_loss: 5.5416e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4651e-04 - val_loss: 5.2403e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4031e-04 - val_loss: 5.3745e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5377e-04 - val_loss: 6.3615e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3266e-04 - val_loss: 5.2943e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2801e-04 - val_loss: 5.9324e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4214e-04 - val_loss: 5.1348e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1580e-04 - val_loss: 5.2945e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2444e-04 - val_loss: 5.3706e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2239e-04 - val_loss: 5.1032e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1438e-04 - val_loss: 5.1278e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1514e-04 - val_loss: 5.1019e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0612e-04 - val_loss: 5.0900e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1500e-04 - val_loss: 5.1676e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1749e-04 - val_loss: 5.2360e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3490e-04 - val_loss: 5.3652e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2765e-04 - val_loss: 5.3581e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4592e-04 - val_loss: 5.4120e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4559e-04 - val_loss: 5.4994e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5004e-04 - val_loss: 5.5163e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4878e-04 - val_loss: 5.3237e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4466e-04 - val_loss: 5.5047e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5448e-04 - val_loss: 5.5867e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4680e-04 - val_loss: 5.3872e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3240e-04 - val_loss: 5.3229e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5339e-04 - val_loss: 5.3532e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4107e-04 - val_loss: 5.5119e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7800e-04 - val_loss: 6.4190e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.3905e-04 - val_loss: 6.4321e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.4611e-04 - val_loss: 6.5226e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.3646e-04 - val_loss: 6.2726e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.2146e-04 - val_loss: 6.1293e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.1200e-04 - val_loss: 6.0614e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1007e-04 - val_loss: 6.0508e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0506e-04 - val_loss: 6.0138e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9084e-04 - val_loss: 5.9247e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.7551e-04 - val_loss: 5.4847e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5036e-04 - val_loss: 5.3609e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5710e-04 - val_loss: 5.5427e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5435e-04 - val_loss: 5.4579e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9435e-04 - val_loss: 6.4045e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7204e-04 - val_loss: 5.6209e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7470e-04 - val_loss: 5.6165e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5312e-04 - val_loss: 5.4799e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4696e-04 - val_loss: 5.4365e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3958e-04 - val_loss: 5.2313e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2366e-04 - val_loss: 5.3437e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2146e-04 - val_loss: 5.1847e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2284e-04 - val_loss: 5.2958e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3442e-04 - val_loss: 5.2762e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2509e-04 - val_loss: 5.1684e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1750e-04 - val_loss: 5.0451e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1625e-04 - val_loss: 5.2193e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1505e-04 - val_loss: 5.0450e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1438e-04 - val_loss: 5.0941e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0942e-04 - val_loss: 5.1589e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3025e-04 - val_loss: 5.4180e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4540e-04 - val_loss: 5.1968e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2031e-04 - val_loss: 5.2807e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.1793e-04 - val_loss: 5.3155e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3339e-04 - val_loss: 5.2681e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3081e-04 - val_loss: 5.4054e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2893e-04 - val_loss: 5.2485e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3891e-04 - val_loss: 5.5877e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7296e-04 - val_loss: 5.9168e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7451e-04 - val_loss: 5.3529e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3633e-04 - val_loss: 5.2827e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2822e-04 - val_loss: 5.3531e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3729e-04 - val_loss: 5.7637e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8495e-04 - val_loss: 5.5363e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0365e-04 - val_loss: 5.8852e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8786e-04 - val_loss: 5.8889e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6796e-04 - val_loss: 5.5729e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6295e-04 - val_loss: 5.3239e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4797e-04 - val_loss: 5.6938e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5230e-04 - val_loss: 5.6070e-04\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_23\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_23\\assets\n",
      " 24%|█████████████████▎                                                      | 24/100 [11:38:52<122:13:20, 5789.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4470e-04 - val_loss: 5.4858e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5220e-04 - val_loss: 5.5410e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5018e-04 - val_loss: 5.4418e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4778e-04 - val_loss: 5.3978e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4495e-04 - val_loss: 5.6609e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5092e-04 - val_loss: 5.4805e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3461e-04 - val_loss: 5.3726e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5042e-04 - val_loss: 5.3789e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5470e-04 - val_loss: 5.3855e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.6072e-04 - val_loss: 6.0429e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4579e-04 - val_loss: 5.2341e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3790e-04 - val_loss: 5.4696e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3099e-04 - val_loss: 5.3337e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5293e-04 - val_loss: 5.2112e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3838e-04 - val_loss: 5.6859e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4924e-04 - val_loss: 5.5477e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4318e-04 - val_loss: 5.5786e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4388e-04 - val_loss: 5.4074e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4116e-04 - val_loss: 5.3100e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4589e-04 - val_loss: 5.3755e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3860e-04 - val_loss: 5.6366e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3346e-04 - val_loss: 5.1629e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2449e-04 - val_loss: 5.2748e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5130e-04 - val_loss: 5.5675e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3747e-04 - val_loss: 5.2912e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4678e-04 - val_loss: 5.2631e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3743e-04 - val_loss: 5.5897e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3899e-04 - val_loss: 5.2775e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4059e-04 - val_loss: 5.5372e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3421e-04 - val_loss: 5.5435e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3233e-04 - val_loss: 5.3767e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3506e-04 - val_loss: 5.4103e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0950e-04 - val_loss: 5.5657e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4344e-04 - val_loss: 5.2400e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4841e-04 - val_loss: 5.6103e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4973e-04 - val_loss: 5.5017e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3491e-04 - val_loss: 5.1750e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4207e-04 - val_loss: 5.3466e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4237e-04 - val_loss: 5.6021e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4307e-04 - val_loss: 5.4476e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6627e-04 - val_loss: 5.8620e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6275e-04 - val_loss: 5.9262e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5420e-04 - val_loss: 5.4469e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3610e-04 - val_loss: 5.5562e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3680e-04 - val_loss: 5.3774e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5374e-04 - val_loss: 5.5286e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6036e-04 - val_loss: 5.4778e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4148e-04 - val_loss: 5.2917e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3640e-04 - val_loss: 5.3077e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.7396e-04 - val_loss: 5.8226e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7543e-04 - val_loss: 5.7478e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6478e-04 - val_loss: 5.6242e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5386e-04 - val_loss: 5.6146e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7548e-04 - val_loss: 6.0138e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5804e-04 - val_loss: 5.5652e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4795e-04 - val_loss: 5.4101e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4248e-04 - val_loss: 5.4720e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3799e-04 - val_loss: 5.2794e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3842e-04 - val_loss: 5.4053e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3676e-04 - val_loss: 5.3759e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4013e-04 - val_loss: 5.2223e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3719e-04 - val_loss: 5.4510e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7272e-04 - val_loss: 5.5199e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3401e-04 - val_loss: 5.2702e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3107e-04 - val_loss: 5.2345e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3665e-04 - val_loss: 5.3196e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4462e-04 - val_loss: 5.4922e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3904e-04 - val_loss: 5.2287e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2808e-04 - val_loss: 5.2780e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2677e-04 - val_loss: 5.5693e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3803e-04 - val_loss: 5.9390e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4549e-04 - val_loss: 5.5864e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4325e-04 - val_loss: 5.8275e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5628e-04 - val_loss: 5.4413e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3702e-04 - val_loss: 5.2951e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4397e-04 - val_loss: 5.3003e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2698e-04 - val_loss: 5.4414e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4025e-04 - val_loss: 5.2391e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2898e-04 - val_loss: 5.2950e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4053e-04 - val_loss: 5.3943e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4887e-04 - val_loss: 5.5454e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5508e-04 - val_loss: 5.4165e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8812e-04 - val_loss: 5.5374e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6456e-04 - val_loss: 5.9729e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5658e-04 - val_loss: 5.6183e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6687e-04 - val_loss: 5.4394e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5330e-04 - val_loss: 5.4099e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3560e-04 - val_loss: 5.2734e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3915e-04 - val_loss: 5.6020e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6205e-04 - val_loss: 5.4891e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3885e-04 - val_loss: 5.4580e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7633e-04 - val_loss: 6.0689e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9128e-04 - val_loss: 5.5993e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5288e-04 - val_loss: 5.6589e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2846e-04 - val_loss: 5.2970e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3377e-04 - val_loss: 5.4932e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5017e-04 - val_loss: 5.1686e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2559e-04 - val_loss: 5.3537e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4763e-04 - val_loss: 5.8672e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6919e-04 - val_loss: 5.2888e-04\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_24\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_24\\assets\n",
      " 25%|██████████████████▎                                                      | 25/100 [11:55:39<90:43:34, 4354.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 5.2980e-04 - val_loss: 5.2636e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 5.2068e-04 - val_loss: 5.2127e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2319e-04 - val_loss: 5.3890e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4348e-04 - val_loss: 5.3501e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3935e-04 - val_loss: 5.4728e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4083e-04 - val_loss: 5.3091e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2467e-04 - val_loss: 5.1317e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3307e-04 - val_loss: 5.5104e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4892e-04 - val_loss: 5.3487e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2917e-04 - val_loss: 5.2274e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2876e-04 - val_loss: 5.3364e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2993e-04 - val_loss: 5.2530e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3855e-04 - val_loss: 5.2766e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3412e-04 - val_loss: 5.6907e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8352e-04 - val_loss: 5.7130e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0638e-04 - val_loss: 6.8903e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.3980e-04 - val_loss: 6.2542e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.1281e-04 - val_loss: 6.0038e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0549e-04 - val_loss: 5.9993e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9088e-04 - val_loss: 5.9879e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9524e-04 - val_loss: 6.0761e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9092e-04 - val_loss: 5.8470e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9751e-04 - val_loss: 5.9075e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7953e-04 - val_loss: 5.7484e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7430e-04 - val_loss: 5.6072e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6788e-04 - val_loss: 5.6685e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8071e-04 - val_loss: 5.6210e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7839e-04 - val_loss: 5.5784e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8098e-04 - val_loss: 5.6732e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6049e-04 - val_loss: 5.5088e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6744e-04 - val_loss: 5.6170e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7899e-04 - val_loss: 6.0085e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 6.3408e-04 - val_loss: 6.3051e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 6.0752e-04 - val_loss: 6.2925e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9577e-04 - val_loss: 5.8350e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8655e-04 - val_loss: 5.7816e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7691e-04 - val_loss: 5.6713e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8051e-04 - val_loss: 5.7831e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6741e-04 - val_loss: 5.6233e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9739e-04 - val_loss: 5.9481e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9903e-04 - val_loss: 5.8442e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7726e-04 - val_loss: 5.8456e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8080e-04 - val_loss: 5.8025e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8731e-04 - val_loss: 5.7272e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7788e-04 - val_loss: 5.6337e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7193e-04 - val_loss: 5.5475e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6348e-04 - val_loss: 5.6109e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5762e-04 - val_loss: 5.6339e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.2299e-04 - val_loss: 6.3047e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.2713e-04 - val_loss: 6.3317e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.2114e-04 - val_loss: 5.9752e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0872e-04 - val_loss: 5.7520e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8784e-04 - val_loss: 5.7151e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7937e-04 - val_loss: 5.5032e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8559e-04 - val_loss: 5.7047e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7444e-04 - val_loss: 6.3478e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9404e-04 - val_loss: 5.7245e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7786e-04 - val_loss: 5.7318e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8290e-04 - val_loss: 5.5540e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6452e-04 - val_loss: 5.4333e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7171e-04 - val_loss: 5.6549e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7008e-04 - val_loss: 5.8439e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 5.5827e-04 - val_loss: 5.5916e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.8556e-04 - val_loss: 5.5054e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6451e-04 - val_loss: 5.7510e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.6537e-04 - val_loss: 5.6029e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5922e-04 - val_loss: 5.4936e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7162e-04 - val_loss: 5.5977e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6134e-04 - val_loss: 5.4939e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6476e-04 - val_loss: 5.5300e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7584e-04 - val_loss: 5.5442e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5763e-04 - val_loss: 5.5189e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6984e-04 - val_loss: 5.7147e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9746e-04 - val_loss: 6.1296e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8876e-04 - val_loss: 5.5523e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7710e-04 - val_loss: 5.7365e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7457e-04 - val_loss: 5.8823e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6886e-04 - val_loss: 5.6407e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5527e-04 - val_loss: 5.5385e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5316e-04 - val_loss: 5.4246e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5617e-04 - val_loss: 5.7578e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7336e-04 - val_loss: 5.8418e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6788e-04 - val_loss: 5.4637e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6792e-04 - val_loss: 5.5995e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7034e-04 - val_loss: 5.5801e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7257e-04 - val_loss: 6.0063e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6857e-04 - val_loss: 5.5352e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7101e-04 - val_loss: 5.9710e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.4339e-04 - val_loss: 5.9085e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9945e-04 - val_loss: 5.7460e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8992e-04 - val_loss: 5.6698e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7244e-04 - val_loss: 5.6474e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6886e-04 - val_loss: 5.8528e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8383e-04 - val_loss: 5.7164e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7938e-04 - val_loss: 5.5944e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5866e-04 - val_loss: 5.4559e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5154e-04 - val_loss: 5.2847e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5164e-04 - val_loss: 5.5780e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.6471e-04 - val_loss: 5.4966e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5854e-04 - val_loss: 5.5268e-04\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_25\\assets\n",
      " 26%|██████████████████▉                                                      | 26/100 [12:12:27<68:52:21, 3350.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 5.5770e-04 - val_loss: 5.4562e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.4849e-04 - val_loss: 5.5469e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4980e-04 - val_loss: 5.6735e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4935e-04 - val_loss: 5.3663e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5144e-04 - val_loss: 5.3627e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4526e-04 - val_loss: 5.4050e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5542e-04 - val_loss: 5.5247e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4523e-04 - val_loss: 5.3271e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6651e-04 - val_loss: 5.4896e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4315e-04 - val_loss: 5.4606e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4662e-04 - val_loss: 5.4535e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4605e-04 - val_loss: 5.4999e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4384e-04 - val_loss: 5.4379e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6212e-04 - val_loss: 5.6321e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5837e-04 - val_loss: 5.5247e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4281e-04 - val_loss: 5.4166e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4788e-04 - val_loss: 5.5558e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7024e-04 - val_loss: 5.7506e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8034e-04 - val_loss: 5.6570e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6504e-04 - val_loss: 5.5530e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4905e-04 - val_loss: 5.4655e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6102e-04 - val_loss: 5.6564e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4834e-04 - val_loss: 5.3977e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5198e-04 - val_loss: 5.5068e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5213e-04 - val_loss: 5.4713e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5280e-04 - val_loss: 6.1376e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5686e-04 - val_loss: 5.3912e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5835e-04 - val_loss: 5.8772e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.8623e-04 - val_loss: 5.3956e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.6048e-04 - val_loss: 5.8313e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5381e-04 - val_loss: 5.4500e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7189e-04 - val_loss: 5.8069e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6993e-04 - val_loss: 5.5253e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6380e-04 - val_loss: 5.8027e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5228e-04 - val_loss: 5.5114e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4062e-04 - val_loss: 5.4041e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3405e-04 - val_loss: 5.3380e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4090e-04 - val_loss: 5.5718e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5250e-04 - val_loss: 5.3946e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3782e-04 - val_loss: 5.3454e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4603e-04 - val_loss: 5.4620e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4032e-04 - val_loss: 5.6386e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4400e-04 - val_loss: 5.3966e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3234e-04 - val_loss: 5.3538e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6207e-04 - val_loss: 5.6238e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5400e-04 - val_loss: 5.5712e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6955e-04 - val_loss: 5.5164e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5822e-04 - val_loss: 5.5875e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4323e-04 - val_loss: 5.4836e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4863e-04 - val_loss: 5.8747e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6783e-04 - val_loss: 5.5332e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5278e-04 - val_loss: 5.6333e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5403e-04 - val_loss: 5.6348e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4629e-04 - val_loss: 5.6118e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4867e-04 - val_loss: 5.3612e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4608e-04 - val_loss: 5.3368e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4255e-04 - val_loss: 5.6138e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5428e-04 - val_loss: 5.4554e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3938e-04 - val_loss: 5.5075e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5319e-04 - val_loss: 5.3945e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4260e-04 - val_loss: 5.2655e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3556e-04 - val_loss: 5.3582e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 5.4098e-04 - val_loss: 5.4204e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3045e-04 - val_loss: 5.2859e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3480e-04 - val_loss: 5.3691e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3488e-04 - val_loss: 5.3099e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4383e-04 - val_loss: 6.1265e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5422e-04 - val_loss: 5.2988e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4699e-04 - val_loss: 5.2860e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3545e-04 - val_loss: 5.2148e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3429e-04 - val_loss: 5.5050e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4792e-04 - val_loss: 5.7593e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3485e-04 - val_loss: 5.5378e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3132e-04 - val_loss: 5.3169e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2829e-04 - val_loss: 5.3458e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3070e-04 - val_loss: 5.2840e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4194e-04 - val_loss: 5.4312e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2652e-04 - val_loss: 5.3473e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3968e-04 - val_loss: 5.3889e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7014e-04 - val_loss: 8.8189e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6764e-04 - val_loss: 5.4849e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4915e-04 - val_loss: 5.4376e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5832e-04 - val_loss: 5.4777e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4376e-04 - val_loss: 5.2846e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3842e-04 - val_loss: 5.3843e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2945e-04 - val_loss: 5.2411e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2734e-04 - val_loss: 5.3823e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2750e-04 - val_loss: 5.4760e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3220e-04 - val_loss: 5.3869e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3245e-04 - val_loss: 5.3607e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3850e-04 - val_loss: 5.4964e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3355e-04 - val_loss: 5.3724e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2583e-04 - val_loss: 5.2279e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2616e-04 - val_loss: 5.7257e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3363e-04 - val_loss: 5.2574e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6149e-04 - val_loss: 5.5221e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4230e-04 - val_loss: 5.7058e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4095e-04 - val_loss: 5.2952e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2119e-04 - val_loss: 5.3593e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2389e-04 - val_loss: 5.4493e-04\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_26\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_26\\assets\n",
      " 27%|███████████████████▋                                                     | 27/100 [12:31:08<54:22:49, 2681.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 5.4070e-04 - val_loss: 5.6601e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 5.4181e-04 - val_loss: 5.5827e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 5.4104e-04 - val_loss: 5.4163e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3840e-04 - val_loss: 5.5058e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2855e-04 - val_loss: 5.3027e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2304e-04 - val_loss: 5.4818e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3282e-04 - val_loss: 5.4120e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4645e-04 - val_loss: 5.4513e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2704e-04 - val_loss: 5.1821e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3281e-04 - val_loss: 5.4854e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3866e-04 - val_loss: 5.3835e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3766e-04 - val_loss: 5.4007e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2892e-04 - val_loss: 5.1885e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3317e-04 - val_loss: 5.3730e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4456e-04 - val_loss: 5.6097e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5288e-04 - val_loss: 5.7502e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4323e-04 - val_loss: 5.4090e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5145e-04 - val_loss: 5.4892e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4567e-04 - val_loss: 5.3616e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4656e-04 - val_loss: 5.5592e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4525e-04 - val_loss: 5.9845e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5564e-04 - val_loss: 5.2671e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3790e-04 - val_loss: 5.3701e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3079e-04 - val_loss: 5.3186e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4255e-04 - val_loss: 5.3858e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4317e-04 - val_loss: 5.3961e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3515e-04 - val_loss: 5.4599e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3040e-04 - val_loss: 5.2125e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3574e-04 - val_loss: 5.3095e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 6.3014e-04 - val_loss: 5.7343e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3942e-04 - val_loss: 5.5100e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.6382e-04 - val_loss: 5.6282e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5426e-04 - val_loss: 5.7458e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4651e-04 - val_loss: 5.6933e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3336e-04 - val_loss: 5.4890e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2992e-04 - val_loss: 5.2770e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3895e-04 - val_loss: 5.5111e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3039e-04 - val_loss: 5.3011e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3828e-04 - val_loss: 5.6243e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4518e-04 - val_loss: 5.3482e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3642e-04 - val_loss: 5.5038e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5935e-04 - val_loss: 5.9684e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.9977e-04 - val_loss: 5.6829e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 6.1775e-04 - val_loss: 5.9127e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.8903e-04 - val_loss: 6.2005e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 6.0506e-04 - val_loss: 5.4152e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5345e-04 - val_loss: 5.3312e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3962e-04 - val_loss: 5.3405e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3837e-04 - val_loss: 5.3283e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2637e-04 - val_loss: 5.2509e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2379e-04 - val_loss: 5.1955e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2125e-04 - val_loss: 5.3028e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2790e-04 - val_loss: 5.3630e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4275e-04 - val_loss: 5.3243e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2597e-04 - val_loss: 5.3810e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3579e-04 - val_loss: 5.3417e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3916e-04 - val_loss: 5.3079e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4384e-04 - val_loss: 5.5584e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 6.5845e-04 - val_loss: 7.0157e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 6.4017e-04 - val_loss: 6.3161e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 6.0669e-04 - val_loss: 6.0497e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8834e-04 - val_loss: 5.8305e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 6.1968e-04 - val_loss: 8.1198e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 6.1670e-04 - val_loss: 5.6583e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 5.8161e-04 - val_loss: 5.6789e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.6381e-04 - val_loss: 5.7188e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 6.0628e-04 - val_loss: 5.9014e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8424e-04 - val_loss: 5.7624e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7283e-04 - val_loss: 5.8726e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7439e-04 - val_loss: 5.7685e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7074e-04 - val_loss: 5.9799e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6654e-04 - val_loss: 5.5945e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7572e-04 - val_loss: 6.1399e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8020e-04 - val_loss: 5.9889e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6335e-04 - val_loss: 5.6585e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4489e-04 - val_loss: 5.3203e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3605e-04 - val_loss: 5.1945e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3160e-04 - val_loss: 5.2677e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2854e-04 - val_loss: 5.2631e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3152e-04 - val_loss: 5.3615e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.6906e-04 - val_loss: 5.6489e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5004e-04 - val_loss: 5.2971e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3162e-04 - val_loss: 5.3192e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5226e-04 - val_loss: 5.5291e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4340e-04 - val_loss: 5.3160e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2837e-04 - val_loss: 5.3389e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2942e-04 - val_loss: 5.4051e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3474e-04 - val_loss: 5.5418e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3714e-04 - val_loss: 5.3697e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3758e-04 - val_loss: 5.4571e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5954e-04 - val_loss: 5.6859e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5985e-04 - val_loss: 5.3884e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3706e-04 - val_loss: 5.2808e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5429e-04 - val_loss: 5.6376e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3868e-04 - val_loss: 5.3704e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3509e-04 - val_loss: 5.3090e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2466e-04 - val_loss: 5.4062e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3119e-04 - val_loss: 5.3721e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.5662e-04 - val_loss: 6.0267e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.7021e-04 - val_loss: 5.6446e-04\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_27\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_27\\assets\n",
      " 28%|████████████████████▍                                                    | 28/100 [12:51:34<44:54:14, 2245.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 5.5138e-04 - val_loss: 5.5054e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 5.5454e-04 - val_loss: 5.5654e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 6.3696e-04 - val_loss: 5.6500e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6964e-04 - val_loss: 5.4763e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5898e-04 - val_loss: 5.8076e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6612e-04 - val_loss: 5.6483e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.6842e-04 - val_loss: 6.1226e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 6.1109e-04 - val_loss: 5.8309e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 6.0531e-04 - val_loss: 7.2704e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 6.8133e-04 - val_loss: 5.9406e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.9871e-04 - val_loss: 5.7255e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.7444e-04 - val_loss: 5.6755e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.7651e-04 - val_loss: 5.7997e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.7706e-04 - val_loss: 6.3884e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.7725e-04 - val_loss: 5.9931e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.9881e-04 - val_loss: 5.7767e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5933e-04 - val_loss: 5.5537e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5726e-04 - val_loss: 5.5862e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5475e-04 - val_loss: 5.4420e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5112e-04 - val_loss: 5.5432e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4706e-04 - val_loss: 5.5099e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5561e-04 - val_loss: 5.4406e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4315e-04 - val_loss: 5.4474e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3798e-04 - val_loss: 5.4472e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3761e-04 - val_loss: 5.3443e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3870e-04 - val_loss: 5.3020e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3438e-04 - val_loss: 5.3383e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3645e-04 - val_loss: 5.6853e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7879e-04 - val_loss: 5.5930e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5804e-04 - val_loss: 5.6335e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6830e-04 - val_loss: 5.7262e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0749e-04 - val_loss: 6.8848e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.3628e-04 - val_loss: 5.9103e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1074e-04 - val_loss: 6.2787e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.2139e-04 - val_loss: 6.0423e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 7.2023e-04 - val_loss: 6.7563e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1460e-04 - val_loss: 6.4439e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8703e-04 - val_loss: 5.6135e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7256e-04 - val_loss: 5.6141e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6908e-04 - val_loss: 5.6601e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7890e-04 - val_loss: 5.8414e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6471e-04 - val_loss: 5.4886e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8269e-04 - val_loss: 5.9368e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6640e-04 - val_loss: 5.5895e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6628e-04 - val_loss: 5.5170e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4341e-04 - val_loss: 5.5326e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5277e-04 - val_loss: 5.7555e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5514e-04 - val_loss: 5.4910e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4556e-04 - val_loss: 5.4792e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5909e-04 - val_loss: 5.6444e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6544e-04 - val_loss: 5.6191e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5781e-04 - val_loss: 5.5791e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7518e-04 - val_loss: 5.6535e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5998e-04 - val_loss: 5.4453e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5336e-04 - val_loss: 5.4336e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5049e-04 - val_loss: 5.5714e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6190e-04 - val_loss: 5.5903e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8616e-04 - val_loss: 5.6378e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4945e-04 - val_loss: 6.0569e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 6.1724e-04 - val_loss: 6.0904e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.8143e-04 - val_loss: 6.0166e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6574e-04 - val_loss: 5.6723e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5913e-04 - val_loss: 5.5112e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3715e-04 - val_loss: 5.3942e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3794e-04 - val_loss: 5.3217e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3227e-04 - val_loss: 5.2021e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4390e-04 - val_loss: 5.3661e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3724e-04 - val_loss: 5.3974e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3173e-04 - val_loss: 5.4437e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6072e-04 - val_loss: 5.6420e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5196e-04 - val_loss: 5.4005e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5220e-04 - val_loss: 5.5307e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6727e-04 - val_loss: 5.4063e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4203e-04 - val_loss: 5.5536e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5717e-04 - val_loss: 5.6539e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5650e-04 - val_loss: 5.4774e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3680e-04 - val_loss: 5.4145e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4068e-04 - val_loss: 5.3559e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5211e-04 - val_loss: 5.4338e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4790e-04 - val_loss: 5.6203e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4175e-04 - val_loss: 5.4832e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3674e-04 - val_loss: 5.6337e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3074e-04 - val_loss: 5.3708e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4589e-04 - val_loss: 5.5022e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4838e-04 - val_loss: 5.4141e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4083e-04 - val_loss: 5.3432e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2746e-04 - val_loss: 5.1293e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3043e-04 - val_loss: 5.2871e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3662e-04 - val_loss: 5.3450e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3936e-04 - val_loss: 5.7140e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4819e-04 - val_loss: 5.2668e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5358e-04 - val_loss: 5.7561e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4507e-04 - val_loss: 5.3391e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3905e-04 - val_loss: 5.4620e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3566e-04 - val_loss: 5.3026e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5301e-04 - val_loss: 5.5589e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4360e-04 - val_loss: 5.5101e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7110e-04 - val_loss: 7.6372e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.6838e-04 - val_loss: 5.6587e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5480e-04 - val_loss: 5.4964e-04\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_28\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_28\\assets\n",
      " 29%|█████████████████████▏                                                   | 29/100 [13:06:02<36:07:35, 1831.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.8796e-04 - val_loss: 5.8780e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.7562e-04 - val_loss: 5.9476e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6983e-04 - val_loss: 5.5582e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7634e-04 - val_loss: 5.6595e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5777e-04 - val_loss: 5.5378e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5654e-04 - val_loss: 5.5680e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5580e-04 - val_loss: 5.5031e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5754e-04 - val_loss: 5.9539e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7184e-04 - val_loss: 5.4632e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5043e-04 - val_loss: 5.7508e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7229e-04 - val_loss: 5.5701e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5523e-04 - val_loss: 5.6148e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8070e-04 - val_loss: 5.6178e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6384e-04 - val_loss: 5.4052e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5005e-04 - val_loss: 5.5644e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5127e-04 - val_loss: 5.3935e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3819e-04 - val_loss: 5.3835e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3442e-04 - val_loss: 5.4350e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4245e-04 - val_loss: 5.3727e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4009e-04 - val_loss: 5.2866e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3465e-04 - val_loss: 5.5444e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 6.2403e-04 - val_loss: 6.0515e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9103e-04 - val_loss: 5.6763e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6100e-04 - val_loss: 5.5207e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5378e-04 - val_loss: 5.5454e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5142e-04 - val_loss: 5.6342e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3825e-04 - val_loss: 5.5424e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4252e-04 - val_loss: 5.4330e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3568e-04 - val_loss: 5.5278e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5596e-04 - val_loss: 5.7352e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4541e-04 - val_loss: 5.3839e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3545e-04 - val_loss: 5.3494e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3860e-04 - val_loss: 5.4910e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3605e-04 - val_loss: 5.7302e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4265e-04 - val_loss: 5.4917e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4448e-04 - val_loss: 5.3618e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4576e-04 - val_loss: 5.4451e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6305e-04 - val_loss: 5.7877e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5163e-04 - val_loss: 6.2323e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4269e-04 - val_loss: 5.3639e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2924e-04 - val_loss: 5.2453e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0075e-04 - val_loss: 6.7355e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.2695e-04 - val_loss: 6.1480e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9249e-04 - val_loss: 5.5660e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5661e-04 - val_loss: 5.5174e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4175e-04 - val_loss: 5.4224e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6811e-04 - val_loss: 5.5426e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5285e-04 - val_loss: 5.4919e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4710e-04 - val_loss: 5.4105e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3666e-04 - val_loss: 5.4283e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3561e-04 - val_loss: 5.4961e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.5100e-04 - val_loss: 5.4794e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3989e-04 - val_loss: 5.3586e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5386e-04 - val_loss: 5.6393e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7020e-04 - val_loss: 5.5956e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7521e-04 - val_loss: 5.5184e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6553e-04 - val_loss: 5.5840e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4112e-04 - val_loss: 5.3433e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3632e-04 - val_loss: 5.4081e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5771e-04 - val_loss: 5.6637e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.6795e-04 - val_loss: 5.7560e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4620e-04 - val_loss: 5.5468e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6271e-04 - val_loss: 5.5518e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4347e-04 - val_loss: 5.5302e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4277e-04 - val_loss: 5.5005e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4716e-04 - val_loss: 5.4067e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3670e-04 - val_loss: 5.4157e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3819e-04 - val_loss: 5.3441e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3606e-04 - val_loss: 5.4052e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3936e-04 - val_loss: 5.2445e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4089e-04 - val_loss: 5.2680e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2894e-04 - val_loss: 5.4440e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3464e-04 - val_loss: 5.4023e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3660e-04 - val_loss: 5.3993e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4084e-04 - val_loss: 5.6697e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6039e-04 - val_loss: 5.3225e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3038e-04 - val_loss: 5.3503e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6505e-04 - val_loss: 5.7763e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5929e-04 - val_loss: 5.6833e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6779e-04 - val_loss: 5.7744e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.2977e-04 - val_loss: 5.6553e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5003e-04 - val_loss: 5.3692e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4071e-04 - val_loss: 5.5065e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4152e-04 - val_loss: 5.3224e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4059e-04 - val_loss: 5.5152e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7413e-04 - val_loss: 5.8613e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4008e-04 - val_loss: 5.5164e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5245e-04 - val_loss: 6.3805e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5911e-04 - val_loss: 5.4098e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4083e-04 - val_loss: 5.9254e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4124e-04 - val_loss: 5.5544e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3524e-04 - val_loss: 5.4979e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3735e-04 - val_loss: 5.3089e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3490e-04 - val_loss: 5.5847e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4922e-04 - val_loss: 5.4102e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4712e-04 - val_loss: 5.3573e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3812e-04 - val_loss: 5.4658e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4412e-04 - val_loss: 5.4101e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3851e-04 - val_loss: 5.4316e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3226e-04 - val_loss: 5.3870e-04\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_29\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_29\\assets\n",
      " 30%|█████████████████████▉                                                   | 30/100 [13:20:43<30:04:22, 1546.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3267e-04 - val_loss: 5.4096e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3066e-04 - val_loss: 5.4548e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3159e-04 - val_loss: 5.3490e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3488e-04 - val_loss: 5.2898e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3011e-04 - val_loss: 5.3902e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2651e-04 - val_loss: 5.3101e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4151e-04 - val_loss: 5.3722e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2750e-04 - val_loss: 5.3615e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2607e-04 - val_loss: 5.2901e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2554e-04 - val_loss: 5.2139e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2725e-04 - val_loss: 5.3607e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3342e-04 - val_loss: 5.2540e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2726e-04 - val_loss: 5.4301e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2286e-04 - val_loss: 5.2425e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2864e-04 - val_loss: 5.4862e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4448e-04 - val_loss: 5.4391e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2732e-04 - val_loss: 5.3751e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2921e-04 - val_loss: 5.2428e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2598e-04 - val_loss: 5.4999e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4330e-04 - val_loss: 5.2820e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3199e-04 - val_loss: 5.3359e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3489e-04 - val_loss: 5.2582e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2491e-04 - val_loss: 5.3427e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4574e-04 - val_loss: 5.3992e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3251e-04 - val_loss: 5.2110e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2454e-04 - val_loss: 5.6046e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2886e-04 - val_loss: 5.1575e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1890e-04 - val_loss: 5.2387e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3246e-04 - val_loss: 5.2788e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3161e-04 - val_loss: 5.4186e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5122e-04 - val_loss: 5.5813e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7732e-04 - val_loss: 6.0425e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8080e-04 - val_loss: 5.3253e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3336e-04 - val_loss: 5.4088e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3028e-04 - val_loss: 5.4126e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2843e-04 - val_loss: 5.3512e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3086e-04 - val_loss: 5.1688e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2398e-04 - val_loss: 5.2207e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4831e-04 - val_loss: 5.4109e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3958e-04 - val_loss: 5.5897e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5532e-04 - val_loss: 5.4766e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3753e-04 - val_loss: 5.3270e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2853e-04 - val_loss: 5.6835e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3160e-04 - val_loss: 5.1770e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2019e-04 - val_loss: 5.2612e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2240e-04 - val_loss: 5.1686e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2499e-04 - val_loss: 5.2644e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4651e-04 - val_loss: 5.4058e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3219e-04 - val_loss: 5.3021e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2098e-04 - val_loss: 5.2349e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1996e-04 - val_loss: 5.4421e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2787e-04 - val_loss: 5.3068e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1992e-04 - val_loss: 5.3520e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3023e-04 - val_loss: 5.1879e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2685e-04 - val_loss: 5.4746e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2290e-04 - val_loss: 5.1179e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1435e-04 - val_loss: 5.1026e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2385e-04 - val_loss: 5.4344e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3299e-04 - val_loss: 5.3955e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4812e-04 - val_loss: 5.2961e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4293e-04 - val_loss: 5.4206e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2016e-04 - val_loss: 5.2622e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2051e-04 - val_loss: 5.2472e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1917e-04 - val_loss: 5.2237e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2032e-04 - val_loss: 5.5214e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2606e-04 - val_loss: 5.3487e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3246e-04 - val_loss: 5.2689e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2761e-04 - val_loss: 5.2360e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4556e-04 - val_loss: 5.2469e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3290e-04 - val_loss: 5.4037e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8392e-04 - val_loss: 5.5551e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4499e-04 - val_loss: 5.4366e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4024e-04 - val_loss: 5.2875e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6014e-04 - val_loss: 6.4997e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0629e-04 - val_loss: 5.8157e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9187e-04 - val_loss: 5.9707e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9314e-04 - val_loss: 5.8854e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8063e-04 - val_loss: 5.8879e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8928e-04 - val_loss: 5.9216e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9008e-04 - val_loss: 5.8144e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9319e-04 - val_loss: 5.7990e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8010e-04 - val_loss: 5.6591e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7276e-04 - val_loss: 5.8509e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6862e-04 - val_loss: 5.6813e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6411e-04 - val_loss: 5.7046e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7235e-04 - val_loss: 5.7434e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7160e-04 - val_loss: 5.6471e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7073e-04 - val_loss: 5.6081e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6237e-04 - val_loss: 5.7323e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5824e-04 - val_loss: 5.6002e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7034e-04 - val_loss: 5.8107e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6739e-04 - val_loss: 5.4998e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7947e-04 - val_loss: 5.4433e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6330e-04 - val_loss: 5.5450e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7025e-04 - val_loss: 5.6043e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6839e-04 - val_loss: 6.2302e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6378e-04 - val_loss: 5.6979e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7394e-04 - val_loss: 6.1527e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0227e-04 - val_loss: 5.9068e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6399e-04 - val_loss: 5.3865e-04\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_30\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_30\\assets\n",
      " 31%|██████████████████████▋                                                  | 31/100 [13:34:12<25:24:03, 1325.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.5455e-04 - val_loss: 5.4545e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.5070e-04 - val_loss: 5.7349e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5975e-04 - val_loss: 5.6023e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5945e-04 - val_loss: 5.6431e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6794e-04 - val_loss: 5.6066e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5105e-04 - val_loss: 5.4006e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5231e-04 - val_loss: 5.4299e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4755e-04 - val_loss: 5.4301e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4409e-04 - val_loss: 5.4293e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5132e-04 - val_loss: 5.4160e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4632e-04 - val_loss: 5.3365e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6191e-04 - val_loss: 5.6475e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7329e-04 - val_loss: 5.6882e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6217e-04 - val_loss: 5.3595e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4659e-04 - val_loss: 5.4395e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5106e-04 - val_loss: 5.4160e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5955e-04 - val_loss: 5.6677e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5645e-04 - val_loss: 5.5164e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4857e-04 - val_loss: 5.6767e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5298e-04 - val_loss: 5.5269e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6538e-04 - val_loss: 5.5212e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6048e-04 - val_loss: 5.6653e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6273e-04 - val_loss: 5.6189e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5893e-04 - val_loss: 5.8137e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5977e-04 - val_loss: 5.6167e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6594e-04 - val_loss: 6.0449e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6621e-04 - val_loss: 5.6758e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6748e-04 - val_loss: 5.7048e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7961e-04 - val_loss: 5.9145e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7447e-04 - val_loss: 5.6514e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5446e-04 - val_loss: 5.5287e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5178e-04 - val_loss: 5.6168e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5140e-04 - val_loss: 5.4827e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5801e-04 - val_loss: 5.4160e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5413e-04 - val_loss: 5.5125e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5552e-04 - val_loss: 5.4287e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3999e-04 - val_loss: 5.4390e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4595e-04 - val_loss: 5.5270e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4189e-04 - val_loss: 5.2852e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4465e-04 - val_loss: 5.3219e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3673e-04 - val_loss: 5.4225e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4290e-04 - val_loss: 5.4674e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3643e-04 - val_loss: 5.3821e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3961e-04 - val_loss: 5.3983e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4488e-04 - val_loss: 5.2629e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6890e-04 - val_loss: 5.7696e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6833e-04 - val_loss: 5.4637e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5467e-04 - val_loss: 5.8931e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4836e-04 - val_loss: 5.5987e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5258e-04 - val_loss: 5.6338e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6221e-04 - val_loss: 5.5542e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6460e-04 - val_loss: 5.5813e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5317e-04 - val_loss: 5.4582e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3983e-04 - val_loss: 5.4094e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4601e-04 - val_loss: 5.4298e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4927e-04 - val_loss: 5.6223e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4218e-04 - val_loss: 5.4577e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5028e-04 - val_loss: 5.5305e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7431e-04 - val_loss: 5.7065e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5304e-04 - val_loss: 5.4982e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4880e-04 - val_loss: 5.4734e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3926e-04 - val_loss: 5.3896e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4294e-04 - val_loss: 5.3770e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5033e-04 - val_loss: 5.4988e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.7612e-04 - val_loss: 5.8576e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5425e-04 - val_loss: 5.5708e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4118e-04 - val_loss: 5.2795e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4591e-04 - val_loss: 5.5478e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4597e-04 - val_loss: 5.3676e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5483e-04 - val_loss: 5.5832e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4622e-04 - val_loss: 5.4938e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4056e-04 - val_loss: 5.3984e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4156e-04 - val_loss: 5.4968e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4113e-04 - val_loss: 5.2886e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4759e-04 - val_loss: 5.6318e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9040e-04 - val_loss: 5.5180e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4884e-04 - val_loss: 5.4139e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4314e-04 - val_loss: 5.4208e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4830e-04 - val_loss: 5.3280e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4449e-04 - val_loss: 7.4868e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6515e-04 - val_loss: 5.5801e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5066e-04 - val_loss: 5.4577e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4294e-04 - val_loss: 5.4621e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4035e-04 - val_loss: 5.3745e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6370e-04 - val_loss: 5.7324e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4859e-04 - val_loss: 5.6245e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5390e-04 - val_loss: 5.4881e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4429e-04 - val_loss: 5.3572e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4271e-04 - val_loss: 5.4139e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3869e-04 - val_loss: 5.2168e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3308e-04 - val_loss: 5.3298e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4668e-04 - val_loss: 5.8098e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5998e-04 - val_loss: 5.6728e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5372e-04 - val_loss: 5.5279e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5038e-04 - val_loss: 5.5928e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5789e-04 - val_loss: 5.9914e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5550e-04 - val_loss: 5.5633e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4972e-04 - val_loss: 5.7358e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6273e-04 - val_loss: 5.3663e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3838e-04 - val_loss: 5.4574e-04\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_31\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_31\\assets\n",
      " 32%|███████████████████████▎                                                 | 32/100 [13:47:01<21:52:54, 1158.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3837e-04 - val_loss: 5.4148e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4027e-04 - val_loss: 5.2619e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2841e-04 - val_loss: 5.4792e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 6.4083e-04 - val_loss: 5.8966e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6724e-04 - val_loss: 5.4220e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5974e-04 - val_loss: 5.5789e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4658e-04 - val_loss: 5.2005e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3545e-04 - val_loss: 5.4480e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3076e-04 - val_loss: 5.2609e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3390e-04 - val_loss: 5.2973e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3130e-04 - val_loss: 5.1402e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2111e-04 - val_loss: 5.3039e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3011e-04 - val_loss: 5.1972e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2198e-04 - val_loss: 5.3138e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2774e-04 - val_loss: 5.2857e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2847e-04 - val_loss: 5.2707e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2603e-04 - val_loss: 5.3884e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4059e-04 - val_loss: 5.3685e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4025e-04 - val_loss: 5.2977e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3814e-04 - val_loss: 5.7396e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3838e-04 - val_loss: 5.5468e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4423e-04 - val_loss: 5.2794e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3837e-04 - val_loss: 5.1756e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8125e-04 - val_loss: 5.8437e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5484e-04 - val_loss: 5.3633e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4730e-04 - val_loss: 5.4903e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5702e-04 - val_loss: 5.4844e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5180e-04 - val_loss: 5.3824e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4443e-04 - val_loss: 5.5434e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6161e-04 - val_loss: 5.5543e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4865e-04 - val_loss: 5.4819e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5532e-04 - val_loss: 5.7828e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6461e-04 - val_loss: 5.5468e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5561e-04 - val_loss: 5.5348e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4738e-04 - val_loss: 5.4518e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4657e-04 - val_loss: 5.3303e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4488e-04 - val_loss: 5.4027e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4015e-04 - val_loss: 5.4634e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5531e-04 - val_loss: 5.4349e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4313e-04 - val_loss: 5.5981e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3791e-04 - val_loss: 5.3920e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5177e-04 - val_loss: 6.1521e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8681e-04 - val_loss: 5.5182e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9014e-04 - val_loss: 5.9573e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7811e-04 - val_loss: 5.3999e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4424e-04 - val_loss: 5.4259e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4840e-04 - val_loss: 5.7112e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4670e-04 - val_loss: 5.2662e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3628e-04 - val_loss: 5.3180e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2957e-04 - val_loss: 5.3557e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2405e-04 - val_loss: 5.2387e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2869e-04 - val_loss: 5.3915e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3488e-04 - val_loss: 5.3835e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4029e-04 - val_loss: 5.6870e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4328e-04 - val_loss: 5.4740e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8599e-04 - val_loss: 5.8031e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4748e-04 - val_loss: 5.9979e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4876e-04 - val_loss: 5.3924e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5227e-04 - val_loss: 5.6446e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5693e-04 - val_loss: 5.5856e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4243e-04 - val_loss: 5.4717e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4547e-04 - val_loss: 5.5953e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5217e-04 - val_loss: 5.4641e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4876e-04 - val_loss: 5.4175e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4984e-04 - val_loss: 5.4404e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4333e-04 - val_loss: 5.4047e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6630e-04 - val_loss: 5.6996e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4689e-04 - val_loss: 5.5779e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4108e-04 - val_loss: 5.4117e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5758e-04 - val_loss: 5.4684e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4544e-04 - val_loss: 5.3239e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3451e-04 - val_loss: 5.2572e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3594e-04 - val_loss: 5.2393e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4022e-04 - val_loss: 5.4454e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3983e-04 - val_loss: 5.6323e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7639e-04 - val_loss: 5.3848e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5579e-04 - val_loss: 5.4994e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5224e-04 - val_loss: 5.5736e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7245e-04 - val_loss: 5.6205e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4120e-04 - val_loss: 5.2266e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3938e-04 - val_loss: 5.4003e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3607e-04 - val_loss: 5.3362e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3724e-04 - val_loss: 5.3437e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5955e-04 - val_loss: 5.7812e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5833e-04 - val_loss: 5.3715e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4186e-04 - val_loss: 5.3920e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3523e-04 - val_loss: 5.3364e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5162e-04 - val_loss: 5.5077e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4954e-04 - val_loss: 5.7094e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5571e-04 - val_loss: 5.2931e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3990e-04 - val_loss: 5.3245e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4174e-04 - val_loss: 5.4991e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3918e-04 - val_loss: 5.3233e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3169e-04 - val_loss: 5.3946e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3192e-04 - val_loss: 5.3885e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4519e-04 - val_loss: 5.6606e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4501e-04 - val_loss: 5.3056e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4241e-04 - val_loss: 5.5514e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5369e-04 - val_loss: 5.3227e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3121e-04 - val_loss: 5.4215e-04\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_32\\assets\n",
      " 33%|████████████████████████                                                 | 33/100 [13:57:40<18:39:45, 1002.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2891e-04 - val_loss: 5.2631e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2665e-04 - val_loss: 5.2805e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2952e-04 - val_loss: 5.2214e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2682e-04 - val_loss: 5.3828e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5217e-04 - val_loss: 5.4758e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.5963e-04 - val_loss: 5.9951e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6399e-04 - val_loss: 5.4740e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4380e-04 - val_loss: 5.3952e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4108e-04 - val_loss: 5.7195e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6072e-04 - val_loss: 5.5184e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7158e-04 - val_loss: 5.3956e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6203e-04 - val_loss: 5.4490e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5425e-04 - val_loss: 5.6339e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5049e-04 - val_loss: 5.5773e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4064e-04 - val_loss: 5.3912e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7558e-04 - val_loss: 5.9012e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5384e-04 - val_loss: 5.2967e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3959e-04 - val_loss: 5.4461e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4163e-04 - val_loss: 5.4862e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3672e-04 - val_loss: 5.3654e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3918e-04 - val_loss: 5.4600e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5712e-04 - val_loss: 5.3882e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3083e-04 - val_loss: 5.6288e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4264e-04 - val_loss: 5.4457e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3876e-04 - val_loss: 5.3191e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3186e-04 - val_loss: 5.2193e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2870e-04 - val_loss: 5.2851e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2770e-04 - val_loss: 5.3438e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3158e-04 - val_loss: 5.4973e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3652e-04 - val_loss: 5.2984e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3623e-04 - val_loss: 5.3413e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2670e-04 - val_loss: 5.2478e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2053e-04 - val_loss: 5.1538e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2861e-04 - val_loss: 5.2311e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3724e-04 - val_loss: 5.3505e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3015e-04 - val_loss: 5.3452e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5115e-04 - val_loss: 5.3313e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3581e-04 - val_loss: 5.3083e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2574e-04 - val_loss: 5.3657e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2697e-04 - val_loss: 5.4270e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2509e-04 - val_loss: 5.1765e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3157e-04 - val_loss: 5.3962e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2380e-04 - val_loss: 5.2030e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5555e-04 - val_loss: 5.8111e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5121e-04 - val_loss: 5.1980e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3587e-04 - val_loss: 5.2632e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3123e-04 - val_loss: 5.2809e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3717e-04 - val_loss: 5.5119e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2561e-04 - val_loss: 5.2306e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2938e-04 - val_loss: 5.3272e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3346e-04 - val_loss: 5.4244e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4404e-04 - val_loss: 5.8377e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4861e-04 - val_loss: 5.2336e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5441e-04 - val_loss: 5.3467e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2751e-04 - val_loss: 5.1813e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2978e-04 - val_loss: 5.4138e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2645e-04 - val_loss: 5.3231e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3372e-04 - val_loss: 5.2124e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3275e-04 - val_loss: 5.3437e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4078e-04 - val_loss: 5.5180e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4637e-04 - val_loss: 5.5542e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3384e-04 - val_loss: 5.2469e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2591e-04 - val_loss: 5.4002e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2349e-04 - val_loss: 5.2153e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2089e-04 - val_loss: 5.2275e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2938e-04 - val_loss: 5.1590e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2786e-04 - val_loss: 5.2964e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3354e-04 - val_loss: 5.5480e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3441e-04 - val_loss: 5.3620e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2856e-04 - val_loss: 5.2210e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2477e-04 - val_loss: 5.3207e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3543e-04 - val_loss: 5.3603e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2836e-04 - val_loss: 5.0739e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0012 - val_loss: 6.7469e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.5009e-04 - val_loss: 6.2956e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2138e-04 - val_loss: 6.1674e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0783e-04 - val_loss: 6.0247e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0304e-04 - val_loss: 5.9080e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9914e-04 - val_loss: 5.9225e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9704e-04 - val_loss: 5.9734e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9486e-04 - val_loss: 5.9024e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9576e-04 - val_loss: 5.9355e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8496e-04 - val_loss: 5.7347e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8333e-04 - val_loss: 5.7042e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7554e-04 - val_loss: 5.7382e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7632e-04 - val_loss: 5.7375e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7691e-04 - val_loss: 5.6807e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7211e-04 - val_loss: 5.7857e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8151e-04 - val_loss: 5.6658e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7632e-04 - val_loss: 5.7119e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6864e-04 - val_loss: 5.7701e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7396e-04 - val_loss: 5.6142e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6848e-04 - val_loss: 5.6765e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7008e-04 - val_loss: 5.6564e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6679e-04 - val_loss: 5.5564e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6884e-04 - val_loss: 5.6737e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7178e-04 - val_loss: 5.7488e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7104e-04 - val_loss: 5.6657e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6655e-04 - val_loss: 5.6523e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8152e-04 - val_loss: 5.8918e-04\n",
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_33\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_33\\assets\n",
      " 34%|█████████████████████████▏                                                | 34/100 [14:08:18<16:22:31, 893.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7110e-04 - val_loss: 5.9339e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.7619e-04 - val_loss: 5.8310e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.6898e-04 - val_loss: 5.5905e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.6629e-04 - val_loss: 5.6268e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6660e-04 - val_loss: 5.6026e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5877e-04 - val_loss: 5.5711e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6857e-04 - val_loss: 5.7039e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7165e-04 - val_loss: 5.8069e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8673e-04 - val_loss: 5.7632e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8588e-04 - val_loss: 5.9077e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9278e-04 - val_loss: 5.7423e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6826e-04 - val_loss: 5.7049e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5739e-04 - val_loss: 5.6758e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6571e-04 - val_loss: 5.5630e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6396e-04 - val_loss: 5.5687e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6432e-04 - val_loss: 5.6525e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5969e-04 - val_loss: 5.6461e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5982e-04 - val_loss: 5.6585e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6681e-04 - val_loss: 5.9211e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7644e-04 - val_loss: 5.6814e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7026e-04 - val_loss: 5.5430e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6127e-04 - val_loss: 5.6703e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7000e-04 - val_loss: 5.5523e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6007e-04 - val_loss: 5.4072e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5429e-04 - val_loss: 5.6812e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5882e-04 - val_loss: 5.5017e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5268e-04 - val_loss: 5.6265e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5886e-04 - val_loss: 5.5191e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5701e-04 - val_loss: 5.6200e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5361e-04 - val_loss: 5.5576e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5406e-04 - val_loss: 5.7983e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5941e-04 - val_loss: 5.5006e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5319e-04 - val_loss: 5.4108e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6051e-04 - val_loss: 5.6190e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6787e-04 - val_loss: 5.6890e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6369e-04 - val_loss: 5.7080e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5491e-04 - val_loss: 5.5598e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5614e-04 - val_loss: 5.5360e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5701e-04 - val_loss: 5.6772e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5288e-04 - val_loss: 5.4966e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4770e-04 - val_loss: 5.4589e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5041e-04 - val_loss: 5.5452e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4952e-04 - val_loss: 5.5109e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5155e-04 - val_loss: 5.6143e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5487e-04 - val_loss: 5.6685e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5751e-04 - val_loss: 5.4942e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4252e-04 - val_loss: 5.4497e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4516e-04 - val_loss: 5.3750e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5758e-04 - val_loss: 5.4741e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5244e-04 - val_loss: 5.7443e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8239e-04 - val_loss: 5.6158e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6430e-04 - val_loss: 5.5026e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4928e-04 - val_loss: 5.4691e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6052e-04 - val_loss: 5.4487e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4927e-04 - val_loss: 5.4750e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4806e-04 - val_loss: 5.3565e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4757e-04 - val_loss: 5.3879e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4835e-04 - val_loss: 5.3378e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4728e-04 - val_loss: 5.5435e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5797e-04 - val_loss: 5.5103e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4553e-04 - val_loss: 5.4071e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4053e-04 - val_loss: 5.4178e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4583e-04 - val_loss: 5.4131e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4654e-04 - val_loss: 5.5462e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5193e-04 - val_loss: 5.4597e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4979e-04 - val_loss: 5.5503e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6992e-04 - val_loss: 5.5076e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5009e-04 - val_loss: 5.4734e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4390e-04 - val_loss: 5.4270e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4401e-04 - val_loss: 5.5107e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5557e-04 - val_loss: 5.4484e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5099e-04 - val_loss: 5.4371e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4782e-04 - val_loss: 5.5446e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4785e-04 - val_loss: 5.6334e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8082e-04 - val_loss: 5.8232e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6369e-04 - val_loss: 5.4299e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4566e-04 - val_loss: 5.3149e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3915e-04 - val_loss: 5.3143e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6960e-04 - val_loss: 5.6603e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4743e-04 - val_loss: 5.4571e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3961e-04 - val_loss: 5.3963e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3854e-04 - val_loss: 5.6073e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4171e-04 - val_loss: 5.4191e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4166e-04 - val_loss: 5.3219e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3211e-04 - val_loss: 5.3531e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3726e-04 - val_loss: 5.3610e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5412e-04 - val_loss: 5.4619e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3405e-04 - val_loss: 5.3029e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3378e-04 - val_loss: 5.2954e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4712e-04 - val_loss: 5.5451e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4422e-04 - val_loss: 5.4104e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4483e-04 - val_loss: 5.3303e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3466e-04 - val_loss: 5.3954e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4023e-04 - val_loss: 5.3792e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4354e-04 - val_loss: 5.3482e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5569e-04 - val_loss: 5.7431e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7341e-04 - val_loss: 5.4840e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4820e-04 - val_loss: 5.2837e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3790e-04 - val_loss: 5.4019e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3973e-04 - val_loss: 5.5275e-04\n",
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_34\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_34\\assets\n",
      " 35%|█████████████████████████▉                                                | 35/100 [14:18:52<14:43:33, 815.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3341e-04 - val_loss: 5.2814e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4044e-04 - val_loss: 5.3826e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4868e-04 - val_loss: 5.8164e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7264e-04 - val_loss: 5.8137e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6358e-04 - val_loss: 5.5262e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0266e-04 - val_loss: 5.7423e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5374e-04 - val_loss: 5.4622e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4358e-04 - val_loss: 5.3624e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3840e-04 - val_loss: 5.3611e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3610e-04 - val_loss: 5.4321e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4001e-04 - val_loss: 5.4305e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4039e-04 - val_loss: 5.4013e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3654e-04 - val_loss: 5.2748e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4521e-04 - val_loss: 5.3578e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3231e-04 - val_loss: 5.3196e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3458e-04 - val_loss: 5.4298e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3567e-04 - val_loss: 5.3394e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4507e-04 - val_loss: 5.5402e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5915e-04 - val_loss: 5.4281e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7101e-04 - val_loss: 6.2391e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.2107e-04 - val_loss: 5.8698e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5327e-04 - val_loss: 5.4434e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4554e-04 - val_loss: 5.5215e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3362e-04 - val_loss: 5.4713e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4775e-04 - val_loss: 5.7299e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9426e-04 - val_loss: 6.0402e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.1691e-04 - val_loss: 6.2514e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.2341e-04 - val_loss: 6.1736e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0460e-04 - val_loss: 5.8581e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8178e-04 - val_loss: 5.5313e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4054e-04 - val_loss: 5.5478e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3929e-04 - val_loss: 5.3888e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4325e-04 - val_loss: 5.5238e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3177e-04 - val_loss: 5.3600e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3295e-04 - val_loss: 5.2476e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3552e-04 - val_loss: 5.3114e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4210e-04 - val_loss: 5.4730e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4126e-04 - val_loss: 5.3281e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2960e-04 - val_loss: 5.2913e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3713e-04 - val_loss: 5.3881e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3292e-04 - val_loss: 5.4855e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3174e-04 - val_loss: 5.4767e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5094e-04 - val_loss: 5.4973e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4289e-04 - val_loss: 5.3481e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3717e-04 - val_loss: 5.3476e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6348e-04 - val_loss: 8.0910e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9199e-04 - val_loss: 5.7035e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4673e-04 - val_loss: 5.3988e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3833e-04 - val_loss: 5.4907e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3217e-04 - val_loss: 5.2857e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3210e-04 - val_loss: 5.3416e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4771e-04 - val_loss: 5.2942e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2700e-04 - val_loss: 5.3275e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3220e-04 - val_loss: 5.4316e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3667e-04 - val_loss: 5.3363e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3911e-04 - val_loss: 5.2892e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3142e-04 - val_loss: 5.3295e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2787e-04 - val_loss: 5.1744e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3456e-04 - val_loss: 5.3441e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.6810e-04 - val_loss: 5.6260e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5308e-04 - val_loss: 5.4249e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4507e-04 - val_loss: 5.3085e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3870e-04 - val_loss: 5.4143e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3858e-04 - val_loss: 5.3043e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3597e-04 - val_loss: 5.3299e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4661e-04 - val_loss: 5.3849e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3469e-04 - val_loss: 5.4405e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4448e-04 - val_loss: 5.4457e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3348e-04 - val_loss: 5.2364e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2710e-04 - val_loss: 5.1946e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2173e-04 - val_loss: 5.2358e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2973e-04 - val_loss: 5.3042e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3413e-04 - val_loss: 5.2494e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3037e-04 - val_loss: 5.2146e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2742e-04 - val_loss: 5.2150e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2651e-04 - val_loss: 5.2758e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2793e-04 - val_loss: 5.3264e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3508e-04 - val_loss: 5.3580e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2359e-04 - val_loss: 5.2264e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3235e-04 - val_loss: 5.7521e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2785e-04 - val_loss: 5.2222e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3726e-04 - val_loss: 5.2847e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2762e-04 - val_loss: 5.2952e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 9.0469e-04 - val_loss: 0.0013\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.8981e-04 - val_loss: 6.0569e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 6.0171e-04 - val_loss: 5.8240e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.8577e-04 - val_loss: 5.7729e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7503e-04 - val_loss: 5.6787e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7097e-04 - val_loss: 5.7599e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6646e-04 - val_loss: 5.6157e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6836e-04 - val_loss: 5.6699e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6422e-04 - val_loss: 5.5919e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5431e-04 - val_loss: 5.6728e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5793e-04 - val_loss: 5.4730e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4432e-04 - val_loss: 5.4456e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4005e-04 - val_loss: 5.4390e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4458e-04 - val_loss: 5.7548e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6873e-04 - val_loss: 5.4968e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4725e-04 - val_loss: 5.4413e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0272e-04 - val_loss: 5.7329e-04\n",
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_35\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_35\\assets\n",
      " 36%|██████████████████████████▋                                               | 36/100 [14:29:24<13:31:13, 760.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.6062e-04 - val_loss: 5.5667e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4491e-04 - val_loss: 5.5635e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4820e-04 - val_loss: 5.4164e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4628e-04 - val_loss: 5.5104e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4043e-04 - val_loss: 5.4546e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4448e-04 - val_loss: 5.7088e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4538e-04 - val_loss: 5.5284e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4552e-04 - val_loss: 5.8061e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7068e-04 - val_loss: 6.1139e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4829e-04 - val_loss: 5.3086e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3678e-04 - val_loss: 5.2586e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4384e-04 - val_loss: 5.3513e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5815e-04 - val_loss: 5.7941e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5690e-04 - val_loss: 5.3519e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3834e-04 - val_loss: 5.3549e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4146e-04 - val_loss: 5.3335e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4429e-04 - val_loss: 5.5375e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5005e-04 - val_loss: 5.5488e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3259e-04 - val_loss: 5.3052e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3763e-04 - val_loss: 5.3552e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3146e-04 - val_loss: 5.4455e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3045e-04 - val_loss: 5.3468e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3960e-04 - val_loss: 5.2550e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2887e-04 - val_loss: 5.3741e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3629e-04 - val_loss: 5.6115e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4013e-04 - val_loss: 5.2410e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2865e-04 - val_loss: 5.2932e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3737e-04 - val_loss: 5.5777e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3436e-04 - val_loss: 5.2892e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5072e-04 - val_loss: 5.8548e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4860e-04 - val_loss: 5.4814e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3511e-04 - val_loss: 5.3597e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3282e-04 - val_loss: 5.3565e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2779e-04 - val_loss: 5.3507e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4156e-04 - val_loss: 5.3215e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5200e-04 - val_loss: 5.4861e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6431e-04 - val_loss: 5.8167e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4167e-04 - val_loss: 5.1922e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2505e-04 - val_loss: 5.4135e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4982e-04 - val_loss: 5.2754e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3830e-04 - val_loss: 5.3620e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7476e-04 - val_loss: 5.8507e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6307e-04 - val_loss: 5.4561e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4909e-04 - val_loss: 5.3183e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3017e-04 - val_loss: 5.3392e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4027e-04 - val_loss: 5.3766e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2883e-04 - val_loss: 5.2621e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2863e-04 - val_loss: 5.2823e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2518e-04 - val_loss: 5.1728e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2746e-04 - val_loss: 5.4287e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3720e-04 - val_loss: 5.2943e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2497e-04 - val_loss: 5.2836e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2816e-04 - val_loss: 5.2300e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3229e-04 - val_loss: 5.2285e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2640e-04 - val_loss: 5.3933e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2706e-04 - val_loss: 5.3365e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2425e-04 - val_loss: 5.2436e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2617e-04 - val_loss: 5.1732e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2404e-04 - val_loss: 5.2408e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2296e-04 - val_loss: 5.2140e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3278e-04 - val_loss: 5.5530e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5770e-04 - val_loss: 5.5523e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3553e-04 - val_loss: 5.4063e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2913e-04 - val_loss: 5.2563e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2396e-04 - val_loss: 5.3859e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5503e-04 - val_loss: 6.2007e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6806e-04 - val_loss: 5.2064e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2227e-04 - val_loss: 5.4448e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5253e-04 - val_loss: 5.6303e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.9780e-04 - val_loss: 5.6683e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4932e-04 - val_loss: 5.5839e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5942e-04 - val_loss: 5.2461e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3929e-04 - val_loss: 5.2819e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3700e-04 - val_loss: 5.2545e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3921e-04 - val_loss: 5.5677e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7755e-04 - val_loss: 5.4719e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5325e-04 - val_loss: 5.5027e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4512e-04 - val_loss: 5.2322e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2461e-04 - val_loss: 5.2884e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2074e-04 - val_loss: 5.1990e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2108e-04 - val_loss: 5.1249e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1806e-04 - val_loss: 5.3620e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2137e-04 - val_loss: 5.3157e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1986e-04 - val_loss: 5.1777e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1419e-04 - val_loss: 5.1169e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2320e-04 - val_loss: 5.5801e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4655e-04 - val_loss: 5.2426e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3667e-04 - val_loss: 5.2226e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3022e-04 - val_loss: 5.2773e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2549e-04 - val_loss: 5.2778e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2689e-04 - val_loss: 5.1470e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1762e-04 - val_loss: 5.2711e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1982e-04 - val_loss: 5.2296e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3094e-04 - val_loss: 5.2196e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3836e-04 - val_loss: 5.2939e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5405e-04 - val_loss: 5.7668e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3016e-04 - val_loss: 5.2238e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6402e-04 - val_loss: 5.7040e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.6368e-04 - val_loss: 5.3066e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2712e-04 - val_loss: 5.3534e-04\n",
      "Model: \"model_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_36\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_36\\assets\n",
      " 37%|███████████████████████████▍                                              | 37/100 [14:39:50<12:36:12, 720.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3572e-04 - val_loss: 5.5885e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4678e-04 - val_loss: 5.4977e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3929e-04 - val_loss: 5.2591e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2288e-04 - val_loss: 5.3382e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6252e-04 - val_loss: 5.5152e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2571e-04 - val_loss: 5.2505e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1916e-04 - val_loss: 5.1744e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3063e-04 - val_loss: 5.4555e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6173e-04 - val_loss: 5.8715e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9780e-04 - val_loss: 5.8934e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9506e-04 - val_loss: 6.0206e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5029e-04 - val_loss: 5.2683e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2303e-04 - val_loss: 5.4422e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2546e-04 - val_loss: 5.2909e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1846e-04 - val_loss: 5.1984e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1546e-04 - val_loss: 5.1655e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1999e-04 - val_loss: 5.1807e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1749e-04 - val_loss: 5.0870e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1296e-04 - val_loss: 5.2877e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2750e-04 - val_loss: 5.4297e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5275e-04 - val_loss: 5.1955e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4222e-04 - val_loss: 5.6952e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4588e-04 - val_loss: 5.7571e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2046e-04 - val_loss: 5.0690e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1731e-04 - val_loss: 5.2025e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2309e-04 - val_loss: 5.4020e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2370e-04 - val_loss: 5.0554e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1801e-04 - val_loss: 5.1425e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1378e-04 - val_loss: 5.1271e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2551e-04 - val_loss: 5.2435e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1603e-04 - val_loss: 5.2056e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2371e-04 - val_loss: 5.1804e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.7150e-04 - val_loss: 6.2317e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5428e-04 - val_loss: 5.4307e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4401e-04 - val_loss: 5.3876e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3226e-04 - val_loss: 5.3099e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3324e-04 - val_loss: 5.4346e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3111e-04 - val_loss: 5.2768e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3903e-04 - val_loss: 5.3899e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3489e-04 - val_loss: 5.4960e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2614e-04 - val_loss: 5.2971e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3554e-04 - val_loss: 5.5190e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3608e-04 - val_loss: 5.2702e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3205e-04 - val_loss: 5.4459e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2687e-04 - val_loss: 5.2465e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2558e-04 - val_loss: 5.2418e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2696e-04 - val_loss: 5.3344e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2658e-04 - val_loss: 5.2651e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5666e-04 - val_loss: 5.4353e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3165e-04 - val_loss: 5.1838e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2924e-04 - val_loss: 5.4339e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2841e-04 - val_loss: 5.2578e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2161e-04 - val_loss: 5.2356e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2559e-04 - val_loss: 5.1381e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3643e-04 - val_loss: 5.1939e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1945e-04 - val_loss: 5.2745e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5450e-04 - val_loss: 6.7012e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.5741e-04 - val_loss: 5.1956e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3400e-04 - val_loss: 5.4526e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2784e-04 - val_loss: 5.1475e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.1881e-04 - val_loss: 5.1354e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1637e-04 - val_loss: 5.1255e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1935e-04 - val_loss: 5.2636e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2228e-04 - val_loss: 5.1413e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1548e-04 - val_loss: 5.0893e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2329e-04 - val_loss: 5.1431e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1986e-04 - val_loss: 5.2995e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2244e-04 - val_loss: 5.2456e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2142e-04 - val_loss: 5.1199e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1888e-04 - val_loss: 5.1045e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1503e-04 - val_loss: 5.1435e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1794e-04 - val_loss: 5.2787e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3152e-04 - val_loss: 5.3561e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4525e-04 - val_loss: 5.2784e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1770e-04 - val_loss: 5.0620e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1489e-04 - val_loss: 5.1641e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1902e-04 - val_loss: 5.1447e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1187e-04 - val_loss: 5.1743e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1597e-04 - val_loss: 5.1907e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1197e-04 - val_loss: 5.1669e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2670e-04 - val_loss: 5.2660e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1920e-04 - val_loss: 5.1923e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3303e-04 - val_loss: 5.4276e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2478e-04 - val_loss: 5.2170e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4261e-04 - val_loss: 5.4917e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3622e-04 - val_loss: 5.2410e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1597e-04 - val_loss: 5.1281e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1778e-04 - val_loss: 5.1039e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1549e-04 - val_loss: 5.1929e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1152e-04 - val_loss: 5.1441e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1883e-04 - val_loss: 5.2367e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1531e-04 - val_loss: 5.0897e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1592e-04 - val_loss: 5.3152e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1780e-04 - val_loss: 5.1916e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1382e-04 - val_loss: 5.0712e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1296e-04 - val_loss: 5.0892e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1109e-04 - val_loss: 5.3128e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3679e-04 - val_loss: 5.2833e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3626e-04 - val_loss: 5.3086e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2474e-04 - val_loss: 5.1044e-04\n",
      "Model: \"model_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_37\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_37\\assets\n",
      " 38%|████████████████████████████                                              | 38/100 [14:50:40<12:02:13, 698.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1794e-04 - val_loss: 5.4426e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1036e-04 - val_loss: 5.1143e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2107e-04 - val_loss: 5.1769e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1614e-04 - val_loss: 5.2048e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1534e-04 - val_loss: 5.0375e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1916e-04 - val_loss: 5.0725e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1236e-04 - val_loss: 5.0901e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1481e-04 - val_loss: 5.1803e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2159e-04 - val_loss: 5.2305e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1714e-04 - val_loss: 5.0960e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0695e-04 - val_loss: 5.1062e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1183e-04 - val_loss: 5.1741e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2202e-04 - val_loss: 5.2058e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4306e-04 - val_loss: 5.3382e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2284e-04 - val_loss: 5.0402e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0816e-04 - val_loss: 4.9942e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1759e-04 - val_loss: 5.1624e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1833e-04 - val_loss: 5.3529e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2567e-04 - val_loss: 5.2410e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2740e-04 - val_loss: 5.0879e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2302e-04 - val_loss: 5.1776e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1364e-04 - val_loss: 5.0865e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1230e-04 - val_loss: 5.1815e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0938e-04 - val_loss: 5.0996e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2033e-04 - val_loss: 5.1777e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2355e-04 - val_loss: 5.3602e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3914e-04 - val_loss: 5.4135e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1609e-04 - val_loss: 5.2299e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1895e-04 - val_loss: 5.0433e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0477e-04 - val_loss: 5.1230e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1239e-04 - val_loss: 5.0073e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1326e-04 - val_loss: 5.4784e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4025e-04 - val_loss: 5.1886e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4984e-04 - val_loss: 6.0775e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5144e-04 - val_loss: 5.2613e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3355e-04 - val_loss: 5.3248e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4228e-04 - val_loss: 5.1601e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2433e-04 - val_loss: 5.2449e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2000e-04 - val_loss: 5.2180e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1910e-04 - val_loss: 5.0558e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2033e-04 - val_loss: 5.1914e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3489e-04 - val_loss: 5.1741e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2265e-04 - val_loss: 5.1406e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2738e-04 - val_loss: 5.3790e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2320e-04 - val_loss: 5.2129e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1692e-04 - val_loss: 5.1191e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1372e-04 - val_loss: 5.0545e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1058e-04 - val_loss: 5.1705e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1360e-04 - val_loss: 5.0430e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0923e-04 - val_loss: 5.1040e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1105e-04 - val_loss: 5.1985e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1693e-04 - val_loss: 5.2246e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1562e-04 - val_loss: 5.3616e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1705e-04 - val_loss: 5.0813e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1019e-04 - val_loss: 5.0149e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2083e-04 - val_loss: 5.1664e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1212e-04 - val_loss: 5.0427e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1641e-04 - val_loss: 5.0178e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0578e-04 - val_loss: 4.9751e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0939e-04 - val_loss: 5.1057e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0523e-04 - val_loss: 5.0113e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.0603e-04 - val_loss: 5.0961e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0946e-04 - val_loss: 5.0806e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1613e-04 - val_loss: 5.3594e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5514e-04 - val_loss: 5.7488e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6582e-04 - val_loss: 5.4806e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1979e-04 - val_loss: 5.1434e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1677e-04 - val_loss: 5.1758e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2772e-04 - val_loss: 5.1172e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1355e-04 - val_loss: 5.1289e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1470e-04 - val_loss: 5.1319e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1630e-04 - val_loss: 5.0763e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1530e-04 - val_loss: 5.2727e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2932e-04 - val_loss: 5.1920e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3664e-04 - val_loss: 5.5268e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3161e-04 - val_loss: 5.3372e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3079e-04 - val_loss: 5.5385e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4081e-04 - val_loss: 5.2227e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3667e-04 - val_loss: 5.3580e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2924e-04 - val_loss: 5.5105e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4308e-04 - val_loss: 5.4009e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3836e-04 - val_loss: 5.1626e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1717e-04 - val_loss: 5.0037e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1227e-04 - val_loss: 5.0802e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0645e-04 - val_loss: 5.0619e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1854e-04 - val_loss: 5.2095e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3167e-04 - val_loss: 5.5081e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1787e-04 - val_loss: 5.1033e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0826e-04 - val_loss: 5.0692e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1275e-04 - val_loss: 5.0325e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1143e-04 - val_loss: 5.0296e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0928e-04 - val_loss: 5.0306e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0496e-04 - val_loss: 4.9723e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1340e-04 - val_loss: 5.1545e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1459e-04 - val_loss: 5.1307e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0956e-04 - val_loss: 5.0473e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1521e-04 - val_loss: 5.4840e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2526e-04 - val_loss: 5.3954e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2710e-04 - val_loss: 5.3354e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0747e-04 - val_loss: 5.0546e-04\n",
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_38\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_38\\assets\n",
      " 39%|████████████████████████████▊                                             | 39/100 [15:02:33<11:54:51, 703.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1434e-04 - val_loss: 5.1141e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.1697e-04 - val_loss: 5.3147e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1269e-04 - val_loss: 5.1563e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3659e-04 - val_loss: 5.3805e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4473e-04 - val_loss: 5.6225e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5276e-04 - val_loss: 5.4909e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3148e-04 - val_loss: 5.1272e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2052e-04 - val_loss: 5.1083e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1353e-04 - val_loss: 5.3856e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0949e-04 - val_loss: 5.0247e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0676e-04 - val_loss: 5.0511e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0645e-04 - val_loss: 5.0201e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2542e-04 - val_loss: 5.1820e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2026e-04 - val_loss: 5.0908e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1119e-04 - val_loss: 5.2602e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1309e-04 - val_loss: 5.1961e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1842e-04 - val_loss: 5.0513e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1823e-04 - val_loss: 5.1650e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1975e-04 - val_loss: 5.5157e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3589e-04 - val_loss: 5.1945e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1691e-04 - val_loss: 5.2688e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2263e-04 - val_loss: 5.1468e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1394e-04 - val_loss: 5.1262e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0989e-04 - val_loss: 5.0482e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1394e-04 - val_loss: 5.1080e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1439e-04 - val_loss: 5.2513e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1920e-04 - val_loss: 5.2510e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1691e-04 - val_loss: 4.9981e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3473e-04 - val_loss: 5.1885e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.0593e-04 - val_loss: 5.0136e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.0595e-04 - val_loss: 4.9815e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1474e-04 - val_loss: 5.4693e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3267e-04 - val_loss: 5.0638e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0105e-04 - val_loss: 5.0441e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0579e-04 - val_loss: 4.9561e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9810e-04 - val_loss: 4.9855e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0638e-04 - val_loss: 4.9362e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0544e-04 - val_loss: 4.9079e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0360e-04 - val_loss: 5.1153e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9972e-04 - val_loss: 5.1283e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1052e-04 - val_loss: 5.0364e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9669e-04 - val_loss: 4.9715e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0432e-04 - val_loss: 5.0336e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0589e-04 - val_loss: 5.0783e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1723e-04 - val_loss: 5.0037e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0752e-04 - val_loss: 5.1204e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0325e-04 - val_loss: 4.9120e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0635e-04 - val_loss: 4.9762e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9784e-04 - val_loss: 5.0921e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1007e-04 - val_loss: 4.9916e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9986e-04 - val_loss: 5.0722e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0468e-04 - val_loss: 4.9643e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0090e-04 - val_loss: 5.0277e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2353e-04 - val_loss: 5.5480e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1679e-04 - val_loss: 5.2290e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2496e-04 - val_loss: 5.1119e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0442e-04 - val_loss: 5.0686e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2533e-04 - val_loss: 5.0405e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.0768e-04 - val_loss: 4.9187e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 4.9634e-04 - val_loss: 4.9637e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0030e-04 - val_loss: 5.0664e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1346e-04 - val_loss: 5.1574e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0489e-04 - val_loss: 5.0728e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0585e-04 - val_loss: 5.0899e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0155e-04 - val_loss: 4.9553e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0610e-04 - val_loss: 5.0104e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0519e-04 - val_loss: 5.0033e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0230e-04 - val_loss: 4.9355e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0320e-04 - val_loss: 5.0150e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9543e-04 - val_loss: 5.1712e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2120e-04 - val_loss: 5.0567e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0907e-04 - val_loss: 5.0267e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9846e-04 - val_loss: 5.0763e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0214e-04 - val_loss: 5.0471e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0232e-04 - val_loss: 5.1386e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1941e-04 - val_loss: 5.3785e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0898e-04 - val_loss: 5.1212e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0474e-04 - val_loss: 5.0943e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0638e-04 - val_loss: 5.1459e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0275e-04 - val_loss: 5.0262e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9611e-04 - val_loss: 5.0064e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9417e-04 - val_loss: 4.9401e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1134e-04 - val_loss: 5.9246e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8540e-04 - val_loss: 5.7096e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7334e-04 - val_loss: 5.9033e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9904e-04 - val_loss: 5.7262e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5579e-04 - val_loss: 5.4225e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2873e-04 - val_loss: 5.2021e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2320e-04 - val_loss: 5.7118e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3350e-04 - val_loss: 5.3043e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4795e-04 - val_loss: 6.0894e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7313e-04 - val_loss: 6.0780e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.6871e-04 - val_loss: 6.0570e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7672e-04 - val_loss: 5.3506e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3808e-04 - val_loss: 5.1265e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2047e-04 - val_loss: 5.2905e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2813e-04 - val_loss: 5.1710e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1959e-04 - val_loss: 5.2717e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2548e-04 - val_loss: 5.8098e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6266e-04 - val_loss: 5.6414e-04\n",
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_39\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_39\\assets\n",
      " 40%|█████████████████████████████▌                                            | 40/100 [15:15:30<12:05:22, 725.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5355e-04 - val_loss: 5.4050e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1889e-04 - val_loss: 5.1996e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1342e-04 - val_loss: 5.0256e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1720e-04 - val_loss: 5.1526e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1280e-04 - val_loss: 5.1351e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1736e-04 - val_loss: 5.1519e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0773e-04 - val_loss: 5.1078e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1876e-04 - val_loss: 5.0955e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0874e-04 - val_loss: 5.0842e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1970e-04 - val_loss: 5.3353e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1795e-04 - val_loss: 5.0954e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0629e-04 - val_loss: 5.0986e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0587e-04 - val_loss: 5.1998e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6951e-04 - val_loss: 5.7535e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3706e-04 - val_loss: 5.2226e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3669e-04 - val_loss: 5.4492e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2568e-04 - val_loss: 5.1736e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1996e-04 - val_loss: 5.0675e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3547e-04 - val_loss: 5.5508e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2001e-04 - val_loss: 5.2586e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2829e-04 - val_loss: 5.3578e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0964e-04 - val_loss: 5.1432e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2918e-04 - val_loss: 5.7053e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4594e-04 - val_loss: 5.6460e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4284e-04 - val_loss: 5.3123e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4703e-04 - val_loss: 5.4565e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3627e-04 - val_loss: 5.3445e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3944e-04 - val_loss: 5.1026e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1090e-04 - val_loss: 5.0039e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1125e-04 - val_loss: 5.5451e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0881e-04 - val_loss: 4.9937e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0927e-04 - val_loss: 5.0892e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2221e-04 - val_loss: 5.2811e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0872e-04 - val_loss: 4.9973e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0766e-04 - val_loss: 5.2207e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0770e-04 - val_loss: 5.0954e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0801e-04 - val_loss: 4.9570e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9978e-04 - val_loss: 4.9048e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0202e-04 - val_loss: 5.1304e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0867e-04 - val_loss: 5.0614e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9742e-04 - val_loss: 4.9728e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9662e-04 - val_loss: 4.9117e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0004e-04 - val_loss: 4.9725e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0083e-04 - val_loss: 5.1367e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0796e-04 - val_loss: 5.0995e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0232e-04 - val_loss: 4.9241e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1015e-04 - val_loss: 5.0533e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0875e-04 - val_loss: 5.0296e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0225e-04 - val_loss: 5.0276e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0061e-04 - val_loss: 5.0273e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0149e-04 - val_loss: 5.2463e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0343e-04 - val_loss: 5.1133e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9300e-04 - val_loss: 4.8802e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9350e-04 - val_loss: 4.9446e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9639e-04 - val_loss: 5.0409e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9846e-04 - val_loss: 5.1890e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9326e-04 - val_loss: 4.9052e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1411e-04 - val_loss: 5.0646e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.1463e-04 - val_loss: 5.1769e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3027e-04 - val_loss: 5.2734e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.2319e-04 - val_loss: 4.9470e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4021e-04 - val_loss: 7.0805e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7259e-04 - val_loss: 5.1029e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2804e-04 - val_loss: 5.3586e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1610e-04 - val_loss: 5.1040e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0239e-04 - val_loss: 5.1304e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1179e-04 - val_loss: 5.2850e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0638e-04 - val_loss: 5.0360e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1305e-04 - val_loss: 5.1029e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0864e-04 - val_loss: 5.0649e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1386e-04 - val_loss: 4.9782e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0078e-04 - val_loss: 4.9691e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1455e-04 - val_loss: 5.1460e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3443e-04 - val_loss: 6.2604e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5971e-04 - val_loss: 5.4599e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3792e-04 - val_loss: 5.4034e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6325e-04 - val_loss: 5.7324e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4791e-04 - val_loss: 5.6922e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1709e-04 - val_loss: 5.2405e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1508e-04 - val_loss: 5.1441e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2486e-04 - val_loss: 5.2092e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0247e-04 - val_loss: 4.9347e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0420e-04 - val_loss: 5.0045e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2232e-04 - val_loss: 5.2186e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2226e-04 - val_loss: 5.1750e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1369e-04 - val_loss: 5.2237e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1795e-04 - val_loss: 5.7265e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0878e-04 - val_loss: 5.0717e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9897e-04 - val_loss: 5.0370e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0889e-04 - val_loss: 5.2268e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2059e-04 - val_loss: 4.9799e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0642e-04 - val_loss: 4.9087e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0036e-04 - val_loss: 4.8659e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9639e-04 - val_loss: 4.9784e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9899e-04 - val_loss: 5.0942e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0190e-04 - val_loss: 4.9139e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9704e-04 - val_loss: 4.9865e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0152e-04 - val_loss: 5.1432e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0510e-04 - val_loss: 5.0910e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0274e-04 - val_loss: 5.1726e-04\n",
      "Model: \"model_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_40\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_40\\assets\n",
      " 41%|██████████████████████████████▎                                           | 41/100 [15:27:48<11:57:05, 729.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1997e-04 - val_loss: 5.0080e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 4.9858e-04 - val_loss: 5.0008e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.0281e-04 - val_loss: 4.9513e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2773e-04 - val_loss: 5.4073e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1083e-04 - val_loss: 4.8831e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2058e-04 - val_loss: 4.9679e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9760e-04 - val_loss: 5.0268e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0934e-04 - val_loss: 5.2102e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2924e-04 - val_loss: 5.2651e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3436e-04 - val_loss: 5.3474e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3208e-04 - val_loss: 5.4230e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3169e-04 - val_loss: 5.3223e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1364e-04 - val_loss: 5.0540e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2308e-04 - val_loss: 5.1376e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1701e-04 - val_loss: 5.1762e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3408e-04 - val_loss: 5.5935e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4295e-04 - val_loss: 5.4110e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4676e-04 - val_loss: 5.4697e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8500e-04 - val_loss: 5.5541e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7556e-04 - val_loss: 5.5407e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6277e-04 - val_loss: 5.8281e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8062e-04 - val_loss: 5.9843e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6462e-04 - val_loss: 5.5404e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5619e-04 - val_loss: 5.6922e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5388e-04 - val_loss: 5.5511e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5753e-04 - val_loss: 5.6271e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5416e-04 - val_loss: 5.5971e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5816e-04 - val_loss: 5.5012e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5407e-04 - val_loss: 5.4731e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6147e-04 - val_loss: 5.9642e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6643e-04 - val_loss: 5.4187e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4676e-04 - val_loss: 5.9477e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7355e-04 - val_loss: 5.6406e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4575e-04 - val_loss: 5.5109e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3722e-04 - val_loss: 5.2952e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3521e-04 - val_loss: 5.3670e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3860e-04 - val_loss: 5.3527e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2751e-04 - val_loss: 5.2959e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3813e-04 - val_loss: 5.2417e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4909e-04 - val_loss: 5.6867e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7108e-04 - val_loss: 5.9189e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5969e-04 - val_loss: 5.4118e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3588e-04 - val_loss: 5.4246e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2683e-04 - val_loss: 5.3033e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2572e-04 - val_loss: 5.2363e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4030e-04 - val_loss: 5.2506e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1603e-04 - val_loss: 5.1586e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2104e-04 - val_loss: 5.1752e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2972e-04 - val_loss: 5.1532e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3346e-04 - val_loss: 5.6989e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5477e-04 - val_loss: 5.7615e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9687e-04 - val_loss: 5.6132e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8883e-04 - val_loss: 5.6625e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7951e-04 - val_loss: 6.2262e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8410e-04 - val_loss: 5.5526e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6952e-04 - val_loss: 5.6149e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8975e-04 - val_loss: 6.1234e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7174e-04 - val_loss: 5.7943e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6118e-04 - val_loss: 5.5409e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6928e-04 - val_loss: 5.3419e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.7190e-04 - val_loss: 6.6217e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 6.0215e-04 - val_loss: 5.6592e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.6240e-04 - val_loss: 5.5652e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5367e-04 - val_loss: 5.5816e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5540e-04 - val_loss: 5.3494e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5447e-04 - val_loss: 5.2662e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4795e-04 - val_loss: 5.3889e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5341e-04 - val_loss: 5.4521e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4050e-04 - val_loss: 5.4032e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6392e-04 - val_loss: 6.5113e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7460e-04 - val_loss: 6.0469e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4680e-04 - val_loss: 5.2780e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4603e-04 - val_loss: 5.6314e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4684e-04 - val_loss: 5.3192e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6109e-04 - val_loss: 5.4539e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5930e-04 - val_loss: 5.4945e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7346e-04 - val_loss: 5.5384e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4629e-04 - val_loss: 5.3748e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4424e-04 - val_loss: 5.3082e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6097e-04 - val_loss: 5.8535e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7090e-04 - val_loss: 5.3158e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4174e-04 - val_loss: 5.4955e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8508e-04 - val_loss: 5.8224e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6809e-04 - val_loss: 5.5293e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6638e-04 - val_loss: 5.3877e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6256e-04 - val_loss: 5.3603e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4752e-04 - val_loss: 5.4551e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5611e-04 - val_loss: 5.3066e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3790e-04 - val_loss: 5.6847e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5375e-04 - val_loss: 5.4680e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7159e-04 - val_loss: 5.5048e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5350e-04 - val_loss: 5.3927e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4391e-04 - val_loss: 5.3131e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3866e-04 - val_loss: 5.2360e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5211e-04 - val_loss: 5.8060e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5380e-04 - val_loss: 5.5902e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4965e-04 - val_loss: 5.4045e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4271e-04 - val_loss: 5.4024e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4503e-04 - val_loss: 5.5305e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3866e-04 - val_loss: 5.3718e-04\n",
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_41\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_41\\assets\n",
      " 42%|███████████████████████████████                                           | 42/100 [15:40:06<11:47:24, 731.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5974e-04 - val_loss: 5.8060e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4259e-04 - val_loss: 5.6819e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.8640e-04 - val_loss: 5.7030e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0065e-04 - val_loss: 5.6446e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5813e-04 - val_loss: 5.3160e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5869e-04 - val_loss: 5.2982e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4357e-04 - val_loss: 5.2485e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3199e-04 - val_loss: 5.4428e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3991e-04 - val_loss: 5.1483e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4080e-04 - val_loss: 5.4373e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3528e-04 - val_loss: 5.3362e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3316e-04 - val_loss: 5.4974e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3706e-04 - val_loss: 5.2065e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3979e-04 - val_loss: 5.1342e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3042e-04 - val_loss: 5.2403e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3104e-04 - val_loss: 5.3620e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3066e-04 - val_loss: 5.2479e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3180e-04 - val_loss: 5.2465e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5670e-04 - val_loss: 5.3310e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4016e-04 - val_loss: 5.7286e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3218e-04 - val_loss: 5.4120e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5682e-04 - val_loss: 5.5701e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2852e-04 - val_loss: 5.3497e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4465e-04 - val_loss: 5.2253e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2428e-04 - val_loss: 5.2981e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3333e-04 - val_loss: 5.1940e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4640e-04 - val_loss: 5.2621e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2509e-04 - val_loss: 5.2169e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3648e-04 - val_loss: 5.3706e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4243e-04 - val_loss: 5.2553e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3227e-04 - val_loss: 5.5533e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3800e-04 - val_loss: 5.4841e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2886e-04 - val_loss: 5.2367e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2575e-04 - val_loss: 5.2696e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3956e-04 - val_loss: 5.4279e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3015e-04 - val_loss: 5.3780e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3982e-04 - val_loss: 5.6510e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3872e-04 - val_loss: 5.2153e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2578e-04 - val_loss: 5.1328e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3069e-04 - val_loss: 5.4360e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3812e-04 - val_loss: 5.3050e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3774e-04 - val_loss: 5.1716e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3083e-04 - val_loss: 5.2359e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3536e-04 - val_loss: 5.6470e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3873e-04 - val_loss: 5.1928e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3059e-04 - val_loss: 5.5492e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3118e-04 - val_loss: 5.2045e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3303e-04 - val_loss: 5.4390e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2679e-04 - val_loss: 5.3441e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2164e-04 - val_loss: 5.8937e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8246e-04 - val_loss: 6.0981e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5930e-04 - val_loss: 5.1952e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5158e-04 - val_loss: 5.4268e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3325e-04 - val_loss: 5.2424e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2754e-04 - val_loss: 5.2283e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2658e-04 - val_loss: 5.1364e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5040e-04 - val_loss: 5.5378e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3779e-04 - val_loss: 5.2250e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3738e-04 - val_loss: 5.3079e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4226e-04 - val_loss: 5.4757e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.4040e-04 - val_loss: 5.3810e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5783e-04 - val_loss: 5.4512e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4472e-04 - val_loss: 5.3285e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3016e-04 - val_loss: 5.2097e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4068e-04 - val_loss: 5.4825e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5522e-04 - val_loss: 5.6455e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3127e-04 - val_loss: 5.3405e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2677e-04 - val_loss: 5.2551e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2518e-04 - val_loss: 5.3523e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2766e-04 - val_loss: 5.7367e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2540e-04 - val_loss: 5.5008e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3985e-04 - val_loss: 5.1953e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3678e-04 - val_loss: 5.4294e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3255e-04 - val_loss: 5.1877e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2768e-04 - val_loss: 5.1728e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4474e-04 - val_loss: 5.5204e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4562e-04 - val_loss: 5.2029e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2835e-04 - val_loss: 5.2421e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4903e-04 - val_loss: 5.7259e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6177e-04 - val_loss: 5.4461e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6616e-04 - val_loss: 5.5759e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4463e-04 - val_loss: 5.4984e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4278e-04 - val_loss: 5.4110e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3104e-04 - val_loss: 5.6447e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1791e-04 - val_loss: 5.1320e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4902e-04 - val_loss: 5.8290e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.1132e-04 - val_loss: 6.3832e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7976e-04 - val_loss: 5.4105e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5592e-04 - val_loss: 5.4844e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5033e-04 - val_loss: 5.4182e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5055e-04 - val_loss: 5.5616e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4052e-04 - val_loss: 5.8056e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3368e-04 - val_loss: 5.0885e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3756e-04 - val_loss: 5.2542e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3904e-04 - val_loss: 5.5865e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5155e-04 - val_loss: 5.4843e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4088e-04 - val_loss: 6.1552e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7377e-04 - val_loss: 5.4976e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4896e-04 - val_loss: 5.5741e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4613e-04 - val_loss: 5.4494e-04\n",
      "Model: \"model_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_42\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_42\\assets\n",
      " 43%|███████████████████████████████▊                                          | 43/100 [15:52:26<11:37:34, 734.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4068e-04 - val_loss: 5.4073e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.5339e-04 - val_loss: 5.5715e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.5625e-04 - val_loss: 5.4317e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4353e-04 - val_loss: 5.4221e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3833e-04 - val_loss: 5.3223e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4297e-04 - val_loss: 5.2309e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3757e-04 - val_loss: 5.2317e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2792e-04 - val_loss: 5.4801e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4158e-04 - val_loss: 5.5609e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4144e-04 - val_loss: 5.2959e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3011e-04 - val_loss: 5.2354e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4439e-04 - val_loss: 5.9974e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7523e-04 - val_loss: 5.8255e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7048e-04 - val_loss: 5.3665e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3850e-04 - val_loss: 5.5381e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4815e-04 - val_loss: 5.4452e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4351e-04 - val_loss: 5.4722e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4597e-04 - val_loss: 5.3736e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5007e-04 - val_loss: 5.5810e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3406e-04 - val_loss: 5.3311e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3987e-04 - val_loss: 5.2112e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3456e-04 - val_loss: 5.1829e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2560e-04 - val_loss: 5.2227e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2537e-04 - val_loss: 5.2029e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9039e-04 - val_loss: 5.7965e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7090e-04 - val_loss: 5.5381e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5318e-04 - val_loss: 5.5162e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3286e-04 - val_loss: 5.2436e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3608e-04 - val_loss: 5.4351e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3452e-04 - val_loss: 5.7703e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4163e-04 - val_loss: 5.3870e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5131e-04 - val_loss: 5.4801e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3462e-04 - val_loss: 5.2389e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7743e-04 - val_loss: 5.3871e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3538e-04 - val_loss: 5.4189e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4688e-04 - val_loss: 5.7882e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3728e-04 - val_loss: 5.1987e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2931e-04 - val_loss: 5.1447e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3130e-04 - val_loss: 5.2224e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2304e-04 - val_loss: 5.1222e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1806e-04 - val_loss: 5.0855e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6301e-04 - val_loss: 5.6886e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2837e-04 - val_loss: 5.2641e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3218e-04 - val_loss: 5.3418e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2306e-04 - val_loss: 5.2397e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2054e-04 - val_loss: 5.2909e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2680e-04 - val_loss: 5.1793e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4855e-04 - val_loss: 5.4889e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7706e-04 - val_loss: 5.9752e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6555e-04 - val_loss: 5.6217e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6281e-04 - val_loss: 5.5007e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5995e-04 - val_loss: 5.5489e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9881e-04 - val_loss: 6.1601e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9953e-04 - val_loss: 5.8661e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9453e-04 - val_loss: 5.9315e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7589e-04 - val_loss: 6.0720e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6035e-04 - val_loss: 5.4835e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6649e-04 - val_loss: 5.5153e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5368e-04 - val_loss: 5.3741e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4063e-04 - val_loss: 5.2874e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5222e-04 - val_loss: 5.3064e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.7852e-04 - val_loss: 5.4464e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4989e-04 - val_loss: 5.4724e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5405e-04 - val_loss: 5.4668e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3937e-04 - val_loss: 5.2012e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3361e-04 - val_loss: 5.2625e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4108e-04 - val_loss: 5.4613e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4011e-04 - val_loss: 5.3570e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4156e-04 - val_loss: 5.4966e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5553e-04 - val_loss: 5.5261e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6280e-04 - val_loss: 5.5929e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5463e-04 - val_loss: 5.4850e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3966e-04 - val_loss: 5.2800e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4994e-04 - val_loss: 5.3942e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5637e-04 - val_loss: 5.5470e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4429e-04 - val_loss: 6.0908e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5998e-04 - val_loss: 5.1712e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3602e-04 - val_loss: 5.3941e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5605e-04 - val_loss: 5.3879e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3504e-04 - val_loss: 5.2304e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3445e-04 - val_loss: 5.2445e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2204e-04 - val_loss: 5.3956e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6296e-04 - val_loss: 5.8457e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4849e-04 - val_loss: 5.1464e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3285e-04 - val_loss: 5.1808e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3542e-04 - val_loss: 5.2893e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3857e-04 - val_loss: 5.3223e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5254e-04 - val_loss: 5.3636e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6569e-04 - val_loss: 5.4663e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4812e-04 - val_loss: 5.3831e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5834e-04 - val_loss: 5.5382e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4723e-04 - val_loss: 5.3853e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2362e-04 - val_loss: 5.1813e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3546e-04 - val_loss: 5.4634e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6570e-04 - val_loss: 5.6253e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5178e-04 - val_loss: 5.2420e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5162e-04 - val_loss: 5.4775e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7977e-04 - val_loss: 5.6841e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5814e-04 - val_loss: 5.3635e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4235e-04 - val_loss: 5.7297e-04\n",
      "Model: \"model_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_43\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_43\\assets\n",
      " 44%|████████████████████████████████▌                                         | 44/100 [16:04:01<11:14:18, 722.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 5.4203e-04 - val_loss: 5.3408e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.3698e-04 - val_loss: 5.5074e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4743e-04 - val_loss: 5.2422e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4587e-04 - val_loss: 6.0500e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5363e-04 - val_loss: 5.2183e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4295e-04 - val_loss: 5.1294e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3004e-04 - val_loss: 5.1314e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2888e-04 - val_loss: 5.2699e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2223e-04 - val_loss: 5.2504e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2819e-04 - val_loss: 5.2571e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3901e-04 - val_loss: 5.3877e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3452e-04 - val_loss: 5.5304e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3514e-04 - val_loss: 5.4412e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2728e-04 - val_loss: 5.2577e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3546e-04 - val_loss: 5.4385e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3607e-04 - val_loss: 5.7356e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4712e-04 - val_loss: 5.5276e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2667e-04 - val_loss: 5.0575e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2965e-04 - val_loss: 5.2176e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2967e-04 - val_loss: 5.4159e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2218e-04 - val_loss: 5.1851e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3707e-04 - val_loss: 5.4474e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2811e-04 - val_loss: 5.2433e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1574e-04 - val_loss: 5.0946e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2669e-04 - val_loss: 5.2483e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1971e-04 - val_loss: 5.1948e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2948e-04 - val_loss: 5.5024e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2801e-04 - val_loss: 5.3453e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4162e-04 - val_loss: 5.3950e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4652e-04 - val_loss: 5.1949e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3179e-04 - val_loss: 5.3422e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3317e-04 - val_loss: 5.2014e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2636e-04 - val_loss: 5.0913e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2838e-04 - val_loss: 5.9694e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5402e-04 - val_loss: 5.3024e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4365e-04 - val_loss: 5.3484e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3206e-04 - val_loss: 5.5174e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4492e-04 - val_loss: 5.3621e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4848e-04 - val_loss: 5.4032e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3049e-04 - val_loss: 5.2394e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4366e-04 - val_loss: 5.6492e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4226e-04 - val_loss: 5.3824e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3442e-04 - val_loss: 5.2923e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5247e-04 - val_loss: 5.5135e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5719e-04 - val_loss: 5.4922e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3550e-04 - val_loss: 5.3784e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3936e-04 - val_loss: 5.4317e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2849e-04 - val_loss: 5.2650e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2809e-04 - val_loss: 5.1595e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2271e-04 - val_loss: 5.2405e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2099e-04 - val_loss: 5.1881e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2869e-04 - val_loss: 5.2568e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2451e-04 - val_loss: 5.1112e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3765e-04 - val_loss: 5.1893e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1858e-04 - val_loss: 5.1379e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1745e-04 - val_loss: 5.2793e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2282e-04 - val_loss: 5.3350e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3120e-04 - val_loss: 5.1490e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3272e-04 - val_loss: 5.1597e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.3308e-04 - val_loss: 5.7349e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.5832e-04 - val_loss: 6.1661e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.6830e-04 - val_loss: 5.5040e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3656e-04 - val_loss: 5.2676e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3731e-04 - val_loss: 5.2429e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4001e-04 - val_loss: 5.1383e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1463e-04 - val_loss: 5.0641e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2024e-04 - val_loss: 5.2247e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3484e-04 - val_loss: 5.1507e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1867e-04 - val_loss: 5.1461e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2737e-04 - val_loss: 5.4365e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2499e-04 - val_loss: 5.0527e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3414e-04 - val_loss: 5.2525e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5450e-04 - val_loss: 6.2512e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8822e-04 - val_loss: 5.6861e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4210e-04 - val_loss: 5.3897e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4302e-04 - val_loss: 5.6367e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4212e-04 - val_loss: 5.5840e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7132e-04 - val_loss: 5.7976e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6604e-04 - val_loss: 5.4930e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5522e-04 - val_loss: 5.5694e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4587e-04 - val_loss: 5.4485e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5421e-04 - val_loss: 5.4283e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5372e-04 - val_loss: 5.4208e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4918e-04 - val_loss: 5.7063e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5691e-04 - val_loss: 5.5633e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4235e-04 - val_loss: 5.4462e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4685e-04 - val_loss: 5.6560e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5103e-04 - val_loss: 5.3960e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4346e-04 - val_loss: 5.4367e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4189e-04 - val_loss: 5.4998e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3655e-04 - val_loss: 5.1829e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6132e-04 - val_loss: 7.4646e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5806e-04 - val_loss: 5.3843e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3241e-04 - val_loss: 5.2576e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3112e-04 - val_loss: 5.2673e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2557e-04 - val_loss: 5.5571e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3834e-04 - val_loss: 5.4468e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4338e-04 - val_loss: 5.6989e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5230e-04 - val_loss: 5.4226e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4838e-04 - val_loss: 5.4216e-04\n",
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_44\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_44\\assets\n",
      " 45%|█████████████████████████████████▎                                        | 45/100 [16:16:12<11:04:38, 725.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.4019e-04 - val_loss: 5.3662e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.7723e-04 - val_loss: 5.6515e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4704e-04 - val_loss: 5.3235e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3019e-04 - val_loss: 5.3190e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2955e-04 - val_loss: 5.4845e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2676e-04 - val_loss: 5.2137e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4683e-04 - val_loss: 5.6722e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3461e-04 - val_loss: 5.1839e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1989e-04 - val_loss: 5.1717e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3702e-04 - val_loss: 5.4186e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3900e-04 - val_loss: 5.3283e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3085e-04 - val_loss: 5.2846e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3215e-04 - val_loss: 5.2880e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2363e-04 - val_loss: 5.1851e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3797e-04 - val_loss: 5.3698e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3168e-04 - val_loss: 7.4970e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6600e-04 - val_loss: 5.4044e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3895e-04 - val_loss: 5.4571e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2815e-04 - val_loss: 5.2138e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4006e-04 - val_loss: 5.6753e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4212e-04 - val_loss: 5.9649e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3590e-04 - val_loss: 5.4405e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3811e-04 - val_loss: 5.2715e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4012e-04 - val_loss: 5.3803e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4492e-04 - val_loss: 5.5821e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4695e-04 - val_loss: 5.7398e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5335e-04 - val_loss: 5.7384e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4303e-04 - val_loss: 5.8026e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4158e-04 - val_loss: 5.3337e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3598e-04 - val_loss: 5.3160e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3409e-04 - val_loss: 5.2136e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3942e-04 - val_loss: 5.3958e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6994e-04 - val_loss: 6.0846e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.7499e-04 - val_loss: 5.9030e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5739e-04 - val_loss: 5.3442e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2600e-04 - val_loss: 5.0474e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2518e-04 - val_loss: 5.5079e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3088e-04 - val_loss: 5.1154e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1768e-04 - val_loss: 5.1456e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1381e-04 - val_loss: 5.1276e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2511e-04 - val_loss: 5.2293e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2140e-04 - val_loss: 5.2839e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2238e-04 - val_loss: 5.2791e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3278e-04 - val_loss: 5.2699e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2876e-04 - val_loss: 5.3061e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2728e-04 - val_loss: 5.0885e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1619e-04 - val_loss: 5.6303e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2157e-04 - val_loss: 5.2759e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2746e-04 - val_loss: 5.2577e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3383e-04 - val_loss: 5.2674e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2051e-04 - val_loss: 5.2216e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1654e-04 - val_loss: 5.1543e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2193e-04 - val_loss: 5.1097e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2167e-04 - val_loss: 5.2272e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3880e-04 - val_loss: 5.2800e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0809e-04 - val_loss: 5.1738e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1238e-04 - val_loss: 5.1813e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1791e-04 - val_loss: 5.5862e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2374e-04 - val_loss: 5.2884e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3487e-04 - val_loss: 5.2543e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.6205e-04 - val_loss: 5.5209e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3997e-04 - val_loss: 5.5224e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3214e-04 - val_loss: 5.4927e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2472e-04 - val_loss: 5.1735e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2707e-04 - val_loss: 5.1088e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2261e-04 - val_loss: 5.4429e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2293e-04 - val_loss: 5.2814e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3191e-04 - val_loss: 5.1707e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1869e-04 - val_loss: 5.2377e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2150e-04 - val_loss: 5.1628e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2945e-04 - val_loss: 5.0920e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3465e-04 - val_loss: 5.2426e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1996e-04 - val_loss: 5.1600e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2524e-04 - val_loss: 4.9729e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1705e-04 - val_loss: 5.1737e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2387e-04 - val_loss: 5.1892e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2219e-04 - val_loss: 5.0372e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1660e-04 - val_loss: 5.1280e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3294e-04 - val_loss: 5.1312e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1880e-04 - val_loss: 4.9992e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2066e-04 - val_loss: 5.3727e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2982e-04 - val_loss: 5.1353e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1236e-04 - val_loss: 4.9982e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1160e-04 - val_loss: 5.0498e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1770e-04 - val_loss: 5.1201e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1559e-04 - val_loss: 5.3274e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0993e-04 - val_loss: 4.9853e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0807e-04 - val_loss: 5.3906e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2669e-04 - val_loss: 5.1189e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2551e-04 - val_loss: 5.0124e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2488e-04 - val_loss: 5.3914e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3999e-04 - val_loss: 5.2009e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2256e-04 - val_loss: 5.4217e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0193e-04 - val_loss: 5.5513e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5872e-04 - val_loss: 5.4343e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3975e-04 - val_loss: 5.1555e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4775e-04 - val_loss: 5.7332e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3247e-04 - val_loss: 5.0923e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2263e-04 - val_loss: 5.1588e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4643e-04 - val_loss: 5.4194e-04\n",
      "Model: \"model_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_45\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_45\\assets\n",
      " 46%|██████████████████████████████████                                        | 46/100 [16:28:08<10:50:03, 722.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2104e-04 - val_loss: 5.1382e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1395e-04 - val_loss: 5.1049e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1219e-04 - val_loss: 5.0829e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1368e-04 - val_loss: 5.0960e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0529e-04 - val_loss: 5.0374e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2268e-04 - val_loss: 5.5320e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3021e-04 - val_loss: 5.0483e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1225e-04 - val_loss: 5.1185e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1620e-04 - val_loss: 5.0950e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1942e-04 - val_loss: 4.9814e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2061e-04 - val_loss: 5.0616e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1016e-04 - val_loss: 5.1760e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2171e-04 - val_loss: 5.3724e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3121e-04 - val_loss: 5.3106e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2044e-04 - val_loss: 5.1643e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2085e-04 - val_loss: 5.1160e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2053e-04 - val_loss: 5.0913e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1834e-04 - val_loss: 5.1520e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3198e-04 - val_loss: 5.3312e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5062e-04 - val_loss: 5.2800e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3390e-04 - val_loss: 5.4375e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3917e-04 - val_loss: 5.1096e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3143e-04 - val_loss: 5.3236e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4066e-04 - val_loss: 5.3228e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2702e-04 - val_loss: 5.2384e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2732e-04 - val_loss: 5.3621e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3302e-04 - val_loss: 5.2568e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3510e-04 - val_loss: 5.3209e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2961e-04 - val_loss: 5.2132e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1951e-04 - val_loss: 5.1241e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2286e-04 - val_loss: 5.1381e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4246e-04 - val_loss: 5.3122e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4325e-04 - val_loss: 5.4677e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3914e-04 - val_loss: 5.4612e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2180e-04 - val_loss: 5.1756e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1170e-04 - val_loss: 5.0610e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3033e-04 - val_loss: 5.3274e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2146e-04 - val_loss: 5.2251e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3403e-04 - val_loss: 5.4360e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4531e-04 - val_loss: 5.2263e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2870e-04 - val_loss: 5.0822e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1805e-04 - val_loss: 5.7319e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1961e-04 - val_loss: 5.0651e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2777e-04 - val_loss: 5.1585e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2767e-04 - val_loss: 5.3249e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4190e-04 - val_loss: 5.4791e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.2186e-04 - val_loss: 5.6621e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4123e-04 - val_loss: 5.2066e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1523e-04 - val_loss: 5.0498e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0947e-04 - val_loss: 5.0880e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1676e-04 - val_loss: 5.1724e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1300e-04 - val_loss: 5.0994e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1624e-04 - val_loss: 5.4114e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3509e-04 - val_loss: 5.3533e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3212e-04 - val_loss: 5.5539e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0512e-04 - val_loss: 6.0259e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.8545e-04 - val_loss: 5.4654e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5630e-04 - val_loss: 5.4852e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.4925e-04 - val_loss: 5.5578e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3174e-04 - val_loss: 5.1234e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3280e-04 - val_loss: 5.1043e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2934e-04 - val_loss: 5.5115e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3075e-04 - val_loss: 5.1302e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2331e-04 - val_loss: 5.3293e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1941e-04 - val_loss: 5.1347e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2000e-04 - val_loss: 5.3174e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3345e-04 - val_loss: 5.0885e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2277e-04 - val_loss: 5.3129e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1878e-04 - val_loss: 5.1238e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3355e-04 - val_loss: 5.5743e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3511e-04 - val_loss: 5.2004e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1452e-04 - val_loss: 5.3580e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0321e-04 - val_loss: 5.0211e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1187e-04 - val_loss: 5.1509e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2606e-04 - val_loss: 5.5323e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2322e-04 - val_loss: 5.1657e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3454e-04 - val_loss: 6.1472e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5315e-04 - val_loss: 5.1542e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1953e-04 - val_loss: 4.9879e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1006e-04 - val_loss: 5.0931e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9895e-04 - val_loss: 4.9817e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0743e-04 - val_loss: 5.0118e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3285e-04 - val_loss: 5.1588e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1455e-04 - val_loss: 5.1876e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1384e-04 - val_loss: 5.1032e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1689e-04 - val_loss: 5.3603e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1768e-04 - val_loss: 4.9965e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2196e-04 - val_loss: 5.1252e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4728e-04 - val_loss: 5.3977e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3759e-04 - val_loss: 5.1760e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1794e-04 - val_loss: 5.2508e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1283e-04 - val_loss: 5.1439e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0442e-04 - val_loss: 4.9984e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0212e-04 - val_loss: 5.0810e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2198e-04 - val_loss: 5.0584e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0692e-04 - val_loss: 5.0616e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0085e-04 - val_loss: 4.8522e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9785e-04 - val_loss: 4.9485e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1147e-04 - val_loss: 5.1261e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3511e-04 - val_loss: 5.2915e-04\n",
      "Model: \"model_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_46\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_46\\assets\n",
      " 47%|██████████████████████████████████▊                                       | 47/100 [16:40:16<10:39:31, 724.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 5.2743e-04 - val_loss: 5.2578e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 5.3826e-04 - val_loss: 5.3700e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 5.4884e-04 - val_loss: 5.5790e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.7313e-04 - val_loss: 5.9422e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.6635e-04 - val_loss: 5.7496e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4629e-04 - val_loss: 5.2087e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3775e-04 - val_loss: 5.4625e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3164e-04 - val_loss: 5.2864e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3402e-04 - val_loss: 5.2413e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5346e-04 - val_loss: 5.3501e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3054e-04 - val_loss: 5.4002e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2119e-04 - val_loss: 5.2325e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2526e-04 - val_loss: 5.2305e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2069e-04 - val_loss: 5.0519e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2657e-04 - val_loss: 5.6105e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3110e-04 - val_loss: 5.1618e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2713e-04 - val_loss: 5.2188e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1808e-04 - val_loss: 5.3399e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3976e-04 - val_loss: 5.1648e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2184e-04 - val_loss: 5.5521e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2298e-04 - val_loss: 5.2000e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2880e-04 - val_loss: 5.2111e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5261e-04 - val_loss: 5.4804e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2764e-04 - val_loss: 5.2098e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4024e-04 - val_loss: 5.4125e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2234e-04 - val_loss: 5.4264e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2432e-04 - val_loss: 5.0962e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3583e-04 - val_loss: 5.0693e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2337e-04 - val_loss: 5.1725e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4056e-04 - val_loss: 5.6303e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3456e-04 - val_loss: 5.2800e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2257e-04 - val_loss: 5.3985e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2486e-04 - val_loss: 5.1719e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2681e-04 - val_loss: 5.3567e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2469e-04 - val_loss: 5.2166e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4213e-04 - val_loss: 5.1816e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2223e-04 - val_loss: 5.3073e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.9920e-04 - val_loss: 5.4719e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3138e-04 - val_loss: 5.2851e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1399e-04 - val_loss: 5.1243e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1722e-04 - val_loss: 5.1240e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1514e-04 - val_loss: 5.0631e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2101e-04 - val_loss: 5.3906e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2582e-04 - val_loss: 5.1781e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1909e-04 - val_loss: 5.1164e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2205e-04 - val_loss: 5.2289e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2241e-04 - val_loss: 5.0567e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4277e-04 - val_loss: 5.3283e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1807e-04 - val_loss: 5.0772e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0675e-04 - val_loss: 5.1169e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2427e-04 - val_loss: 5.4170e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2386e-04 - val_loss: 5.2460e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3635e-04 - val_loss: 5.6847e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5324e-04 - val_loss: 5.2397e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2544e-04 - val_loss: 5.2834e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3274e-04 - val_loss: 5.2652e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5590e-04 - val_loss: 5.0525e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1706e-04 - val_loss: 5.1274e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2034e-04 - val_loss: 5.1483e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1643e-04 - val_loss: 5.1043e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3957e-04 - val_loss: 5.7594e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3138e-04 - val_loss: 5.3022e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4772e-04 - val_loss: 5.7261e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4586e-04 - val_loss: 5.1401e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1899e-04 - val_loss: 5.1276e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3767e-04 - val_loss: 5.6302e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3244e-04 - val_loss: 5.1339e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1308e-04 - val_loss: 5.4417e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1939e-04 - val_loss: 4.9957e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1929e-04 - val_loss: 5.2704e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1387e-04 - val_loss: 5.3595e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2130e-04 - val_loss: 5.4603e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2280e-04 - val_loss: 5.0780e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1756e-04 - val_loss: 5.2067e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1985e-04 - val_loss: 5.4767e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2457e-04 - val_loss: 5.3648e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4660e-04 - val_loss: 5.2977e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5099e-04 - val_loss: 5.6420e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5922e-04 - val_loss: 5.5219e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4455e-04 - val_loss: 5.2273e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3306e-04 - val_loss: 5.2334e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4154e-04 - val_loss: 5.5949e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5729e-04 - val_loss: 5.4539e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4435e-04 - val_loss: 5.3065e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3496e-04 - val_loss: 5.1841e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3061e-04 - val_loss: 5.4399e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4592e-04 - val_loss: 5.3626e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4132e-04 - val_loss: 5.2849e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3510e-04 - val_loss: 5.1330e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2795e-04 - val_loss: 5.2007e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1651e-04 - val_loss: 5.2191e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2275e-04 - val_loss: 5.1681e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1682e-04 - val_loss: 5.2065e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2779e-04 - val_loss: 5.3847e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3360e-04 - val_loss: 5.5292e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2978e-04 - val_loss: 5.0593e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1991e-04 - val_loss: 5.2154e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2683e-04 - val_loss: 5.4014e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3485e-04 - val_loss: 5.0692e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2010e-04 - val_loss: 5.3931e-04\n",
      "Model: \"model_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_47\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_47\\assets\n",
      " 48%|███████████████████████████████████▌                                      | 48/100 [16:52:28<10:29:26, 726.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2192e-04 - val_loss: 5.1313e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3663e-04 - val_loss: 5.6018e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3535e-04 - val_loss: 5.4476e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3059e-04 - val_loss: 5.3181e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2743e-04 - val_loss: 5.2582e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1259e-04 - val_loss: 5.0217e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0610e-04 - val_loss: 5.1493e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0643e-04 - val_loss: 5.1845e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0729e-04 - val_loss: 5.0572e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0504e-04 - val_loss: 5.1077e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0656e-04 - val_loss: 5.0073e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1762e-04 - val_loss: 5.0810e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1125e-04 - val_loss: 5.0839e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3799e-04 - val_loss: 5.2680e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4019e-04 - val_loss: 5.6465e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2116e-04 - val_loss: 5.0990e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2178e-04 - val_loss: 5.2703e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3125e-04 - val_loss: 5.2965e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2485e-04 - val_loss: 5.0673e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1329e-04 - val_loss: 5.2439e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1019e-04 - val_loss: 5.1747e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1864e-04 - val_loss: 5.2612e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5031e-04 - val_loss: 5.4722e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2849e-04 - val_loss: 5.0155e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3099e-04 - val_loss: 5.6788e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2288e-04 - val_loss: 5.0577e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1350e-04 - val_loss: 5.3796e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1165e-04 - val_loss: 4.9586e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2265e-04 - val_loss: 5.1394e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2009e-04 - val_loss: 5.2541e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1701e-04 - val_loss: 5.1498e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2071e-04 - val_loss: 5.3881e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1476e-04 - val_loss: 5.1109e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1586e-04 - val_loss: 5.1300e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2425e-04 - val_loss: 5.1214e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2889e-04 - val_loss: 5.1603e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5099e-04 - val_loss: 6.1232e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5734e-04 - val_loss: 5.5325e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4139e-04 - val_loss: 5.1849e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1931e-04 - val_loss: 5.1219e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2790e-04 - val_loss: 5.3972e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1857e-04 - val_loss: 5.0257e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1306e-04 - val_loss: 5.0623e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2049e-04 - val_loss: 5.1969e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1395e-04 - val_loss: 5.0638e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1285e-04 - val_loss: 5.4362e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1474e-04 - val_loss: 5.1840e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1046e-04 - val_loss: 5.1440e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2583e-04 - val_loss: 5.1903e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1892e-04 - val_loss: 5.2049e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1211e-04 - val_loss: 5.0702e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1282e-04 - val_loss: 5.2370e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3604e-04 - val_loss: 5.4023e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4194e-04 - val_loss: 5.2522e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3369e-04 - val_loss: 5.1619e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4345e-04 - val_loss: 5.2772e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5130e-04 - val_loss: 5.1844e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4004e-04 - val_loss: 5.3487e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2481e-04 - val_loss: 5.1969e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.8261e-04 - val_loss: 5.5118e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3591e-04 - val_loss: 5.3166e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4776e-04 - val_loss: 5.4420e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4917e-04 - val_loss: 5.3219e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4327e-04 - val_loss: 5.4574e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3271e-04 - val_loss: 5.2695e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5215e-04 - val_loss: 5.4273e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3064e-04 - val_loss: 5.1439e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1268e-04 - val_loss: 4.9886e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0813e-04 - val_loss: 5.0643e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0435e-04 - val_loss: 4.9045e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0574e-04 - val_loss: 5.2104e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0849e-04 - val_loss: 5.0802e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1026e-04 - val_loss: 4.9997e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0835e-04 - val_loss: 5.1617e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1288e-04 - val_loss: 5.2594e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1076e-04 - val_loss: 4.9839e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0441e-04 - val_loss: 4.9311e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3407e-04 - val_loss: 5.3601e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2901e-04 - val_loss: 5.9266e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5255e-04 - val_loss: 5.0822e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3240e-04 - val_loss: 5.4100e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2186e-04 - val_loss: 5.0861e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0881e-04 - val_loss: 5.2287e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1745e-04 - val_loss: 5.1431e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2612e-04 - val_loss: 5.8573e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4639e-04 - val_loss: 5.2920e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0641e-04 - val_loss: 5.1159e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0406e-04 - val_loss: 5.2719e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2030e-04 - val_loss: 5.2957e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2878e-04 - val_loss: 5.3703e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2828e-04 - val_loss: 5.2753e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1339e-04 - val_loss: 5.4231e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1942e-04 - val_loss: 5.0729e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2136e-04 - val_loss: 5.3855e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3467e-04 - val_loss: 5.3669e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1647e-04 - val_loss: 5.3323e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1065e-04 - val_loss: 5.2515e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1450e-04 - val_loss: 5.2867e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1057e-04 - val_loss: 5.1432e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1598e-04 - val_loss: 5.3503e-04\n",
      "Model: \"model_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_48\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_48\\assets\n",
      " 49%|████████████████████████████████████▎                                     | 49/100 [17:04:29<10:16:14, 724.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1264e-04 - val_loss: 5.0419e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1783e-04 - val_loss: 5.2063e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.2395e-04 - val_loss: 5.4535e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2490e-04 - val_loss: 5.1284e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2183e-04 - val_loss: 5.1694e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1471e-04 - val_loss: 5.1508e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2181e-04 - val_loss: 5.1172e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0540e-04 - val_loss: 4.9319e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2145e-04 - val_loss: 5.2241e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0991e-04 - val_loss: 5.0841e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0359e-04 - val_loss: 5.1282e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2049e-04 - val_loss: 5.1052e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3385e-04 - val_loss: 5.1627e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0997e-04 - val_loss: 5.1274e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4343e-04 - val_loss: 5.4408e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3492e-04 - val_loss: 5.0980e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4073e-04 - val_loss: 5.9693e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6716e-04 - val_loss: 5.3731e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2368e-04 - val_loss: 5.3432e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2021e-04 - val_loss: 4.9325e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0264e-04 - val_loss: 4.9408e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1191e-04 - val_loss: 5.1750e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1583e-04 - val_loss: 5.0573e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9491e-04 - val_loss: 4.8774e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9409e-04 - val_loss: 5.0187e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1000e-04 - val_loss: 5.3830e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0761e-04 - val_loss: 5.1483e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0100e-04 - val_loss: 4.9657e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1908e-04 - val_loss: 5.2026e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2821e-04 - val_loss: 5.3526e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2355e-04 - val_loss: 5.3326e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.1666e-04 - val_loss: 5.3012e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3008e-04 - val_loss: 5.3091e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.0654e-04 - val_loss: 4.9423e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9822e-04 - val_loss: 5.1144e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1751e-04 - val_loss: 5.1530e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1638e-04 - val_loss: 5.3991e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1600e-04 - val_loss: 5.0501e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0833e-04 - val_loss: 5.0348e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1211e-04 - val_loss: 5.1727e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0592e-04 - val_loss: 5.0399e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0432e-04 - val_loss: 5.0569e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1186e-04 - val_loss: 5.2315e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1305e-04 - val_loss: 5.0717e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0659e-04 - val_loss: 4.9663e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2130e-04 - val_loss: 4.9425e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9849e-04 - val_loss: 5.0802e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1610e-04 - val_loss: 4.9405e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0515e-04 - val_loss: 5.1256e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1315e-04 - val_loss: 5.0967e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2465e-04 - val_loss: 5.0510e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3539e-04 - val_loss: 5.3518e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2618e-04 - val_loss: 5.1831e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1006e-04 - val_loss: 5.2067e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1359e-04 - val_loss: 5.1635e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2344e-04 - val_loss: 5.0096e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1649e-04 - val_loss: 5.3998e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.3673e-04 - val_loss: 5.2556e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.5363e-04 - val_loss: 5.4162e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1778e-04 - val_loss: 5.0540e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0945e-04 - val_loss: 5.0098e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0414e-04 - val_loss: 5.0969e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2422e-04 - val_loss: 5.0248e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0756e-04 - val_loss: 5.1023e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0808e-04 - val_loss: 5.0546e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0242e-04 - val_loss: 4.9475e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0578e-04 - val_loss: 5.1349e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0949e-04 - val_loss: 5.2988e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3573e-04 - val_loss: 5.0275e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1390e-04 - val_loss: 4.9956e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9807e-04 - val_loss: 5.0806e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1336e-04 - val_loss: 5.1715e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0198e-04 - val_loss: 4.9558e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9165e-04 - val_loss: 5.0558e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0306e-04 - val_loss: 5.0867e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0536e-04 - val_loss: 5.0646e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1962e-04 - val_loss: 5.3726e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3452e-04 - val_loss: 5.2723e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0638e-04 - val_loss: 4.8713e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9858e-04 - val_loss: 4.9903e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0902e-04 - val_loss: 5.0176e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1059e-04 - val_loss: 5.5838e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0251e-04 - val_loss: 5.0727e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0251e-04 - val_loss: 4.9629e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9500e-04 - val_loss: 4.9905e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0145e-04 - val_loss: 5.0315e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0458e-04 - val_loss: 5.0366e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9924e-04 - val_loss: 4.9899e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2253e-04 - val_loss: 5.0799e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1918e-04 - val_loss: 5.0663e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2121e-04 - val_loss: 5.1424e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1630e-04 - val_loss: 5.1323e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5939e-04 - val_loss: 5.5546e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4090e-04 - val_loss: 5.1647e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2309e-04 - val_loss: 5.2693e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1172e-04 - val_loss: 5.0493e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8003e-04 - val_loss: 6.5042e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4935e-04 - val_loss: 5.3678e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7542e-04 - val_loss: 5.2710e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2499e-04 - val_loss: 5.1825e-04\n",
      "Model: \"model_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_49\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_49\\assets\n",
      " 50%|█████████████████████████████████████                                     | 50/100 [17:18:25<10:31:53, 758.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.1353e-04 - val_loss: 5.2209e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.1867e-04 - val_loss: 5.1396e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.1010e-04 - val_loss: 5.0001e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.5234e-04 - val_loss: 5.9657e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.1547e-04 - val_loss: 5.3818e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4204e-04 - val_loss: 5.0287e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9828e-04 - val_loss: 4.8936e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0402e-04 - val_loss: 5.2810e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3233e-04 - val_loss: 5.9569e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9497e-04 - val_loss: 5.5556e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3111e-04 - val_loss: 5.3980e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4857e-04 - val_loss: 5.2139e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2994e-04 - val_loss: 5.1076e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1275e-04 - val_loss: 5.1049e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1706e-04 - val_loss: 5.3397e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3572e-04 - val_loss: 5.3540e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2260e-04 - val_loss: 5.0201e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1561e-04 - val_loss: 5.2892e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1783e-04 - val_loss: 5.0870e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1429e-04 - val_loss: 5.0243e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0999e-04 - val_loss: 5.1178e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2163e-04 - val_loss: 5.0597e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0878e-04 - val_loss: 5.2115e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1236e-04 - val_loss: 5.1494e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0608e-04 - val_loss: 5.1265e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0549e-04 - val_loss: 4.9867e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0826e-04 - val_loss: 4.9651e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0606e-04 - val_loss: 5.1003e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1169e-04 - val_loss: 5.1537e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0440e-04 - val_loss: 5.1823e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1413e-04 - val_loss: 5.2176e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0314e-04 - val_loss: 4.9547e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9922e-04 - val_loss: 5.1672e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0661e-04 - val_loss: 5.1375e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.1561e-04 - val_loss: 5.0066e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 4.9644e-04 - val_loss: 4.9681e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0285e-04 - val_loss: 5.1002e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0725e-04 - val_loss: 5.2090e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0634e-04 - val_loss: 4.9287e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9984e-04 - val_loss: 5.0564e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1224e-04 - val_loss: 5.0163e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0908e-04 - val_loss: 4.9299e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1956e-04 - val_loss: 5.0616e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1670e-04 - val_loss: 5.1549e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3131e-04 - val_loss: 5.0717e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3926e-04 - val_loss: 5.2395e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2717e-04 - val_loss: 5.0913e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1498e-04 - val_loss: 5.0698e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0881e-04 - val_loss: 5.0871e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0969e-04 - val_loss: 5.2276e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0300e-04 - val_loss: 4.9611e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9908e-04 - val_loss: 5.1827e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1206e-04 - val_loss: 5.0028e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0705e-04 - val_loss: 5.1672e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4653e-04 - val_loss: 5.8629e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.9098e-04 - val_loss: 5.9325e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7875e-04 - val_loss: 5.6894e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.8397e-04 - val_loss: 5.7941e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 5.8506e-04 - val_loss: 6.0568e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.6520e-04 - val_loss: 5.4662e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3968e-04 - val_loss: 5.2486e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3445e-04 - val_loss: 5.0734e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2895e-04 - val_loss: 5.2677e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2649e-04 - val_loss: 5.1172e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1942e-04 - val_loss: 4.9820e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1033e-04 - val_loss: 5.2032e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1725e-04 - val_loss: 5.4417e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3620e-04 - val_loss: 5.3646e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1847e-04 - val_loss: 5.1086e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2271e-04 - val_loss: 5.5662e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1491e-04 - val_loss: 5.4421e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4491e-04 - val_loss: 5.4739e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3854e-04 - val_loss: 5.1472e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3182e-04 - val_loss: 5.5567e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1701e-04 - val_loss: 5.2263e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2746e-04 - val_loss: 5.2425e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3425e-04 - val_loss: 5.4091e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3068e-04 - val_loss: 5.2576e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3113e-04 - val_loss: 5.1991e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2992e-04 - val_loss: 5.5963e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4763e-04 - val_loss: 6.0304e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.7652e-04 - val_loss: 5.4447e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5983e-04 - val_loss: 5.4316e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4806e-04 - val_loss: 5.5295e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7091e-04 - val_loss: 5.8764e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5426e-04 - val_loss: 5.3923e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5255e-04 - val_loss: 5.6078e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5732e-04 - val_loss: 5.5093e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6298e-04 - val_loss: 6.1997e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7991e-04 - val_loss: 5.7679e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6423e-04 - val_loss: 5.2802e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5146e-04 - val_loss: 5.5530e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4351e-04 - val_loss: 5.4022e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5817e-04 - val_loss: 5.6974e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5670e-04 - val_loss: 5.7365e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7782e-04 - val_loss: 5.5355e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6728e-04 - val_loss: 5.3774e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4022e-04 - val_loss: 5.3699e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5036e-04 - val_loss: 6.2154e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6077e-04 - val_loss: 5.5851e-04\n",
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_50\\assets\n",
      " 51%|█████████████████████████████████████▋                                    | 51/100 [17:31:16<10:22:13, 761.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.4392e-04 - val_loss: 5.2979e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.4209e-04 - val_loss: 5.2252e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4326e-04 - val_loss: 5.2764e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5380e-04 - val_loss: 5.4836e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6086e-04 - val_loss: 5.8008e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6001e-04 - val_loss: 5.4321e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5838e-04 - val_loss: 5.6119e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5042e-04 - val_loss: 5.7016e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4377e-04 - val_loss: 5.1431e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6274e-04 - val_loss: 5.3314e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4163e-04 - val_loss: 5.2171e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2670e-04 - val_loss: 5.1368e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2916e-04 - val_loss: 5.2900e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4395e-04 - val_loss: 5.3944e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3236e-04 - val_loss: 5.3228e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4318e-04 - val_loss: 5.1442e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2245e-04 - val_loss: 5.1029e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1520e-04 - val_loss: 5.1789e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1846e-04 - val_loss: 5.1389e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1877e-04 - val_loss: 5.0648e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2388e-04 - val_loss: 5.1705e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1547e-04 - val_loss: 5.6090e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5374e-04 - val_loss: 5.3667e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2533e-04 - val_loss: 5.3971e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2928e-04 - val_loss: 5.2206e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2208e-04 - val_loss: 5.0653e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1301e-04 - val_loss: 5.0290e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1582e-04 - val_loss: 5.2404e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3053e-04 - val_loss: 5.1731e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2789e-04 - val_loss: 5.3538e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2222e-04 - val_loss: 5.1650e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2601e-04 - val_loss: 5.3044e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3171e-04 - val_loss: 5.2949e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4072e-04 - val_loss: 5.3130e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3895e-04 - val_loss: 5.4081e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3748e-04 - val_loss: 5.3355e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3185e-04 - val_loss: 5.3474e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.5124e-04 - val_loss: 5.9831e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6531e-04 - val_loss: 5.3452e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3063e-04 - val_loss: 5.3501e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3056e-04 - val_loss: 5.2288e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3108e-04 - val_loss: 5.1074e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2398e-04 - val_loss: 5.2107e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2355e-04 - val_loss: 5.0261e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1843e-04 - val_loss: 5.2256e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2630e-04 - val_loss: 5.3885e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1861e-04 - val_loss: 5.1534e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3430e-04 - val_loss: 5.0327e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2132e-04 - val_loss: 5.2204e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4849e-04 - val_loss: 5.1576e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1586e-04 - val_loss: 5.1118e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2734e-04 - val_loss: 5.1776e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2736e-04 - val_loss: 5.2353e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1649e-04 - val_loss: 5.0708e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1710e-04 - val_loss: 5.3105e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3196e-04 - val_loss: 5.1759e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2450e-04 - val_loss: 5.1781e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1938e-04 - val_loss: 5.1666e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2067e-04 - val_loss: 5.0241e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.1664e-04 - val_loss: 5.0776e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2002e-04 - val_loss: 5.2825e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2432e-04 - val_loss: 5.2761e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2268e-04 - val_loss: 5.2472e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1889e-04 - val_loss: 5.1037e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1491e-04 - val_loss: 5.2667e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1436e-04 - val_loss: 5.2616e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3378e-04 - val_loss: 5.4086e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3596e-04 - val_loss: 5.3708e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3836e-04 - val_loss: 5.0819e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1372e-04 - val_loss: 5.2043e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3097e-04 - val_loss: 5.7746e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1796e-04 - val_loss: 5.1450e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1888e-04 - val_loss: 5.1801e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2987e-04 - val_loss: 5.2907e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2929e-04 - val_loss: 5.4319e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4353e-04 - val_loss: 5.5334e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4896e-04 - val_loss: 5.3631e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3746e-04 - val_loss: 5.3751e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4404e-04 - val_loss: 5.4108e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3714e-04 - val_loss: 5.4515e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3856e-04 - val_loss: 5.3473e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4023e-04 - val_loss: 5.2131e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.3222e-04 - val_loss: 5.4019e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2403e-04 - val_loss: 5.0508e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2015e-04 - val_loss: 5.3820e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.4736e-04 - val_loss: 5.4069e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2693e-04 - val_loss: 5.1449e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1927e-04 - val_loss: 5.2473e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2602e-04 - val_loss: 5.0987e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2559e-04 - val_loss: 5.3074e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1707e-04 - val_loss: 5.1083e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1624e-04 - val_loss: 5.0509e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1873e-04 - val_loss: 5.3169e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1961e-04 - val_loss: 5.0438e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1328e-04 - val_loss: 5.1136e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1646e-04 - val_loss: 5.2441e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.1896e-04 - val_loss: 5.2104e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2037e-04 - val_loss: 5.0661e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1919e-04 - val_loss: 5.2511e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 5.2538e-04 - val_loss: 5.0696e-04\n",
      "Model: \"model_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_51\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_51\\assets\n",
      " 52%|████████████████████████████████████▉                                  | 52/100 [34:17:59<248:43:30, 18654.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.2041e-04 - val_loss: 5.2987e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1234e-04 - val_loss: 4.9635e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1558e-04 - val_loss: 5.1617e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1171e-04 - val_loss: 5.0864e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4006e-04 - val_loss: 5.2740e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2464e-04 - val_loss: 5.1536e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2278e-04 - val_loss: 5.2052e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3964e-04 - val_loss: 5.2655e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2564e-04 - val_loss: 5.3052e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2271e-04 - val_loss: 5.2167e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2790e-04 - val_loss: 5.5049e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2898e-04 - val_loss: 5.2545e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3109e-04 - val_loss: 5.2433e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3894e-04 - val_loss: 5.3882e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4488e-04 - val_loss: 5.3615e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2945e-04 - val_loss: 5.3832e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6296e-04 - val_loss: 5.2984e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4463e-04 - val_loss: 5.2386e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4579e-04 - val_loss: 5.2968e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4200e-04 - val_loss: 5.3105e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2998e-04 - val_loss: 5.1224e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2495e-04 - val_loss: 5.2146e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2305e-04 - val_loss: 5.0964e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1404e-04 - val_loss: 5.0445e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1524e-04 - val_loss: 5.1563e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3427e-04 - val_loss: 6.0130e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6256e-04 - val_loss: 5.5904e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4449e-04 - val_loss: 5.7227e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4710e-04 - val_loss: 5.4827e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4972e-04 - val_loss: 5.5226e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4157e-04 - val_loss: 5.6187e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3948e-04 - val_loss: 5.9370e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5440e-04 - val_loss: 5.2903e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6045e-04 - val_loss: 5.4070e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4843e-04 - val_loss: 5.3476e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3755e-04 - val_loss: 5.2218e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3467e-04 - val_loss: 5.3159e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5831e-04 - val_loss: 5.4242e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9016e-04 - val_loss: 5.5429e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5141e-04 - val_loss: 5.4294e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4265e-04 - val_loss: 5.2862e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4056e-04 - val_loss: 5.2357e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3969e-04 - val_loss: 5.5316e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4485e-04 - val_loss: 5.4835e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4604e-04 - val_loss: 5.3803e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4968e-04 - val_loss: 5.1879e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3329e-04 - val_loss: 5.1861e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3047e-04 - val_loss: 5.3039e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3267e-04 - val_loss: 5.4265e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2509e-04 - val_loss: 5.4448e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3146e-04 - val_loss: 5.2244e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2445e-04 - val_loss: 5.3184e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2729e-04 - val_loss: 5.1200e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2448e-04 - val_loss: 5.1221e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.2040e-04 - val_loss: 5.1559e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2022e-04 - val_loss: 5.1537e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3031e-04 - val_loss: 5.0820e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1774e-04 - val_loss: 4.9276e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1713e-04 - val_loss: 5.3301e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2513e-04 - val_loss: 5.2737e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.2852e-04 - val_loss: 5.2324e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2656e-04 - val_loss: 5.2941e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3159e-04 - val_loss: 5.4803e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3487e-04 - val_loss: 5.1369e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1721e-04 - val_loss: 5.0629e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2646e-04 - val_loss: 5.1760e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1136e-04 - val_loss: 5.0930e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1296e-04 - val_loss: 4.9980e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0680e-04 - val_loss: 5.0299e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0227e-04 - val_loss: 4.9956e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1088e-04 - val_loss: 5.1692e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2025e-04 - val_loss: 5.0675e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0894e-04 - val_loss: 4.9704e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1802e-04 - val_loss: 5.1731e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1537e-04 - val_loss: 5.4316e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3071e-04 - val_loss: 5.3126e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4297e-04 - val_loss: 5.4900e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3005e-04 - val_loss: 5.2485e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2277e-04 - val_loss: 5.0718e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2417e-04 - val_loss: 5.1961e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2770e-04 - val_loss: 5.2070e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1768e-04 - val_loss: 5.1896e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2813e-04 - val_loss: 5.5543e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2234e-04 - val_loss: 5.1430e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2029e-04 - val_loss: 5.0665e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3250e-04 - val_loss: 5.1675e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0837e-04 - val_loss: 5.0649e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2506e-04 - val_loss: 5.3031e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2205e-04 - val_loss: 5.1869e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2417e-04 - val_loss: 5.0700e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1898e-04 - val_loss: 5.2142e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2663e-04 - val_loss: 5.3200e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2054e-04 - val_loss: 5.2036e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1636e-04 - val_loss: 5.3683e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4420e-04 - val_loss: 5.3994e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2768e-04 - val_loss: 5.1767e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3332e-04 - val_loss: 5.2638e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3291e-04 - val_loss: 5.3595e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2285e-04 - val_loss: 5.1087e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1534e-04 - val_loss: 5.1046e-04\n",
      "Model: \"model_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_52\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_52\\assets\n",
      " 53%|█████████████████████████████████████▋                                 | 53/100 [34:36:42<174:52:43, 13394.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 5.3064e-04 - val_loss: 5.5006e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 5.6796e-04 - val_loss: 5.2030e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 5.2696e-04 - val_loss: 5.2857e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3082e-04 - val_loss: 5.1461e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2262e-04 - val_loss: 5.2030e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2365e-04 - val_loss: 5.5004e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2969e-04 - val_loss: 5.0818e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2184e-04 - val_loss: 5.2281e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3117e-04 - val_loss: 5.1825e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3393e-04 - val_loss: 5.1744e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2143e-04 - val_loss: 5.1652e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2229e-04 - val_loss: 5.4530e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1484e-04 - val_loss: 5.1091e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1952e-04 - val_loss: 5.1996e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 5.1917e-04 - val_loss: 5.4007e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1747e-04 - val_loss: 5.0121e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2768e-04 - val_loss: 5.2986e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2753e-04 - val_loss: 5.2724e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2117e-04 - val_loss: 5.1299e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1344e-04 - val_loss: 5.0982e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1639e-04 - val_loss: 5.1191e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1919e-04 - val_loss: 5.2499e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4814e-04 - val_loss: 5.2277e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2296e-04 - val_loss: 5.1316e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2260e-04 - val_loss: 5.1982e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2451e-04 - val_loss: 5.1658e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1793e-04 - val_loss: 5.4310e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2201e-04 - val_loss: 5.3296e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1773e-04 - val_loss: 5.1435e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1803e-04 - val_loss: 5.1028e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1629e-04 - val_loss: 5.2210e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1313e-04 - val_loss: 5.0391e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1217e-04 - val_loss: 5.0085e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1852e-04 - val_loss: 5.0473e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1655e-04 - val_loss: 5.1210e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1464e-04 - val_loss: 5.0868e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1790e-04 - val_loss: 5.2385e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3213e-04 - val_loss: 5.1773e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2592e-04 - val_loss: 5.1978e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2176e-04 - val_loss: 5.1907e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2779e-04 - val_loss: 5.1852e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3065e-04 - val_loss: 5.1688e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1945e-04 - val_loss: 5.0259e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.0587e-04 - val_loss: 5.1896e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.0908e-04 - val_loss: 5.1740e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2052e-04 - val_loss: 5.1642e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2468e-04 - val_loss: 5.3388e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4199e-04 - val_loss: 5.1938e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3753e-04 - val_loss: 5.5816e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1652e-04 - val_loss: 5.1803e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2246e-04 - val_loss: 5.3070e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1583e-04 - val_loss: 5.0696e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1989e-04 - val_loss: 5.4358e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4156e-04 - val_loss: 5.3436e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.5232e-04 - val_loss: 5.6944e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4812e-04 - val_loss: 5.2638e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2147e-04 - val_loss: 5.2138e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2755e-04 - val_loss: 5.1637e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 5.2608e-04 - val_loss: 5.1851e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 5.4173e-04 - val_loss: 5.1780e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3243e-04 - val_loss: 5.7498e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3874e-04 - val_loss: 5.3971e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 6.1152e-04 - val_loss: 5.9647e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.7390e-04 - val_loss: 5.4473e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.4236e-04 - val_loss: 5.0984e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2505e-04 - val_loss: 5.1971e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2745e-04 - val_loss: 5.1654e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1624e-04 - val_loss: 5.3255e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2791e-04 - val_loss: 5.6425e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2977e-04 - val_loss: 5.1438e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2592e-04 - val_loss: 5.2898e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2716e-04 - val_loss: 5.4140e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2619e-04 - val_loss: 5.2367e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1200e-04 - val_loss: 5.3249e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.0924e-04 - val_loss: 5.1801e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1391e-04 - val_loss: 5.3347e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2701e-04 - val_loss: 5.1036e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2670e-04 - val_loss: 5.2880e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1721e-04 - val_loss: 5.0885e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3337e-04 - val_loss: 5.3600e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2339e-04 - val_loss: 4.9649e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2629e-04 - val_loss: 5.1045e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3460e-04 - val_loss: 5.1945e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3011e-04 - val_loss: 5.0685e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1518e-04 - val_loss: 5.5463e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 5.0647e-04 - val_loss: 5.0295e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0598e-04 - val_loss: 4.9565e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1546e-04 - val_loss: 5.2594e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.3401e-04 - val_loss: 5.2560e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2907e-04 - val_loss: 5.3391e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2135e-04 - val_loss: 5.3310e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2602e-04 - val_loss: 5.2160e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2201e-04 - val_loss: 5.0647e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1267e-04 - val_loss: 5.0017e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.0373e-04 - val_loss: 5.0584e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.0889e-04 - val_loss: 4.9345e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1057e-04 - val_loss: 4.9962e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.0004e-04 - val_loss: 4.9168e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.0764e-04 - val_loss: 5.1023e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1340e-04 - val_loss: 5.2191e-04\n",
      "Model: \"model_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_53\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_53\\assets\n",
      " 54%|██████████████████████████████████████▉                                 | 54/100 [34:59:12<124:59:05, 9781.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 5.1381e-04 - val_loss: 5.0676e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 5.0064e-04 - val_loss: 4.9832e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 5.0531e-04 - val_loss: 5.0146e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.1394e-04 - val_loss: 5.1247e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.0646e-04 - val_loss: 5.0060e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.0804e-04 - val_loss: 4.9669e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1384e-04 - val_loss: 4.9826e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0141e-04 - val_loss: 5.0479e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0229e-04 - val_loss: 5.4324e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1953e-04 - val_loss: 5.0803e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1585e-04 - val_loss: 5.1391e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1060e-04 - val_loss: 5.1239e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.0414e-04 - val_loss: 4.9169e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.0088e-04 - val_loss: 4.9123e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 4.9438e-04 - val_loss: 4.9115e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0725e-04 - val_loss: 5.1739e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1564e-04 - val_loss: 5.1594e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0578e-04 - val_loss: 5.3352e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1017e-04 - val_loss: 4.9947e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.2968e-04 - val_loss: 5.3687e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3989e-04 - val_loss: 6.2385e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.4866e-04 - val_loss: 5.3786e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.2321e-04 - val_loss: 5.5882e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1783e-04 - val_loss: 4.9696e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1757e-04 - val_loss: 5.0442e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3024e-04 - val_loss: 5.3438e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.4136e-04 - val_loss: 5.3322e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3507e-04 - val_loss: 5.4170e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.4090e-04 - val_loss: 5.3628e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.4386e-04 - val_loss: 5.2190e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3800e-04 - val_loss: 5.2417e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1650e-04 - val_loss: 5.0466e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1021e-04 - val_loss: 5.1629e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1498e-04 - val_loss: 5.1786e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3040e-04 - val_loss: 5.4051e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.2735e-04 - val_loss: 5.1496e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3846e-04 - val_loss: 5.1483e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1915e-04 - val_loss: 5.3450e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3777e-04 - val_loss: 5.3571e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3956e-04 - val_loss: 5.3968e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3545e-04 - val_loss: 5.2833e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.3181e-04 - val_loss: 5.2234e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.2794e-04 - val_loss: 5.0476e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.2385e-04 - val_loss: 5.1294e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.2788e-04 - val_loss: 5.2080e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3036e-04 - val_loss: 5.0905e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0787e-04 - val_loss: 5.0441e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2232e-04 - val_loss: 5.2384e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1424e-04 - val_loss: 5.1441e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1412e-04 - val_loss: 5.2398e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0815e-04 - val_loss: 5.0161e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1186e-04 - val_loss: 5.1503e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1496e-04 - val_loss: 5.1648e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.0902e-04 - val_loss: 5.0546e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.0829e-04 - val_loss: 5.1323e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0591e-04 - val_loss: 4.8116e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0081e-04 - val_loss: 4.8997e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0115e-04 - val_loss: 5.2457e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 5.0168e-04 - val_loss: 4.8333e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 5.0386e-04 - val_loss: 4.9063e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 5.0679e-04 - val_loss: 5.1187e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.1773e-04 - val_loss: 5.1367e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1231e-04 - val_loss: 4.9358e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1684e-04 - val_loss: 4.9726e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0240e-04 - val_loss: 5.2125e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1661e-04 - val_loss: 5.0378e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0537e-04 - val_loss: 5.1857e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1001e-04 - val_loss: 4.9822e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.0499e-04 - val_loss: 5.2673e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 5.0765e-04 - val_loss: 5.2359e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 4.9807e-04 - val_loss: 4.9549e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0926e-04 - val_loss: 5.3310e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1865e-04 - val_loss: 5.1891e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0657e-04 - val_loss: 4.9251e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.0834e-04 - val_loss: 4.9184e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2520e-04 - val_loss: 6.0277e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3505e-04 - val_loss: 5.2938e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0944e-04 - val_loss: 5.2028e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2498e-04 - val_loss: 4.9957e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0821e-04 - val_loss: 4.9070e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0667e-04 - val_loss: 5.0384e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0508e-04 - val_loss: 5.1051e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1142e-04 - val_loss: 5.1572e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0652e-04 - val_loss: 5.0370e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0240e-04 - val_loss: 4.9359e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0160e-04 - val_loss: 5.0537e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0044e-04 - val_loss: 4.9594e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0437e-04 - val_loss: 5.0916e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 4.9540e-04 - val_loss: 5.1775e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.0957e-04 - val_loss: 4.9230e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 4.9158e-04 - val_loss: 4.9508e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1044e-04 - val_loss: 5.1156e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2429e-04 - val_loss: 5.1893e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0436e-04 - val_loss: 5.0149e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9284e-04 - val_loss: 4.8530e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9911e-04 - val_loss: 5.2585e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0088e-04 - val_loss: 4.7626e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9476e-04 - val_loss: 5.1092e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0109e-04 - val_loss: 4.9081e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9650e-04 - val_loss: 4.9901e-04\n",
      "Model: \"model_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_54\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_54\\assets\n",
      " 55%|████████████████████████████████████████▏                                | 55/100 [35:13:06<88:42:52, 7097.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1050e-04 - val_loss: 4.9269e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0742e-04 - val_loss: 5.1270e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.0811e-04 - val_loss: 5.0439e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1963e-04 - val_loss: 5.2137e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2796e-04 - val_loss: 5.1888e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2642e-04 - val_loss: 5.0996e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0871e-04 - val_loss: 5.0277e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2188e-04 - val_loss: 5.3027e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2561e-04 - val_loss: 5.2133e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2311e-04 - val_loss: 5.1090e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2578e-04 - val_loss: 5.2761e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2400e-04 - val_loss: 5.3540e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3180e-04 - val_loss: 5.4990e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3668e-04 - val_loss: 5.0884e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2058e-04 - val_loss: 5.3866e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2668e-04 - val_loss: 5.2827e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1799e-04 - val_loss: 5.0415e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0897e-04 - val_loss: 5.0684e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1050e-04 - val_loss: 5.1661e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0932e-04 - val_loss: 5.1337e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0333e-04 - val_loss: 5.0883e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0859e-04 - val_loss: 5.0504e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0610e-04 - val_loss: 5.0261e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1984e-04 - val_loss: 5.7054e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3998e-04 - val_loss: 5.5214e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3724e-04 - val_loss: 5.1755e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2934e-04 - val_loss: 5.1787e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0933e-04 - val_loss: 5.5130e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4965e-04 - val_loss: 5.2223e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2651e-04 - val_loss: 5.1176e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2141e-04 - val_loss: 5.1901e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2629e-04 - val_loss: 5.4033e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.4205e-04 - val_loss: 5.4136e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2709e-04 - val_loss: 5.3199e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2901e-04 - val_loss: 5.2508e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3008e-04 - val_loss: 5.2494e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3841e-04 - val_loss: 5.5567e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5574e-04 - val_loss: 5.3589e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4871e-04 - val_loss: 5.3802e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5043e-04 - val_loss: 5.4434e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4776e-04 - val_loss: 5.3855e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5461e-04 - val_loss: 5.5284e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6862e-04 - val_loss: 5.4935e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4921e-04 - val_loss: 5.3854e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5205e-04 - val_loss: 5.4781e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4729e-04 - val_loss: 5.5224e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5423e-04 - val_loss: 5.5355e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5089e-04 - val_loss: 5.5710e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4474e-04 - val_loss: 5.3712e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5863e-04 - val_loss: 5.5322e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4827e-04 - val_loss: 5.2936e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4004e-04 - val_loss: 5.9520e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4259e-04 - val_loss: 5.4420e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3338e-04 - val_loss: 5.5176e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3687e-04 - val_loss: 5.3078e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4014e-04 - val_loss: 5.3041e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3651e-04 - val_loss: 5.1736e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2597e-04 - val_loss: 5.3946e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1763e-04 - val_loss: 5.1380e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2487e-04 - val_loss: 5.2646e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4454e-04 - val_loss: 5.2157e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2491e-04 - val_loss: 5.1889e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2428e-04 - val_loss: 5.1325e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1329e-04 - val_loss: 5.1104e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2677e-04 - val_loss: 5.2928e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.2860e-04 - val_loss: 5.0794e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2274e-04 - val_loss: 5.1030e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2258e-04 - val_loss: 5.1250e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1951e-04 - val_loss: 5.2054e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3652e-04 - val_loss: 5.6027e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2966e-04 - val_loss: 5.0894e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3119e-04 - val_loss: 5.5231e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3097e-04 - val_loss: 5.1412e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1916e-04 - val_loss: 5.2802e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1453e-04 - val_loss: 5.2711e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1778e-04 - val_loss: 5.5661e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3741e-04 - val_loss: 5.4377e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3007e-04 - val_loss: 5.5857e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3274e-04 - val_loss: 5.3432e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3479e-04 - val_loss: 5.3349e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4644e-04 - val_loss: 5.6971e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6082e-04 - val_loss: 5.4278e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3762e-04 - val_loss: 5.4147e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2868e-04 - val_loss: 5.4443e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3830e-04 - val_loss: 5.3062e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3599e-04 - val_loss: 5.2975e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3775e-04 - val_loss: 5.3783e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2763e-04 - val_loss: 5.2464e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3500e-04 - val_loss: 5.1879e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2175e-04 - val_loss: 5.2593e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2758e-04 - val_loss: 5.2065e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1822e-04 - val_loss: 5.2240e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2801e-04 - val_loss: 5.2826e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2299e-04 - val_loss: 5.0691e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3952e-04 - val_loss: 5.2118e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3048e-04 - val_loss: 5.5330e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2510e-04 - val_loss: 5.2115e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1720e-04 - val_loss: 5.2397e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3232e-04 - val_loss: 5.0848e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3305e-04 - val_loss: 4.9441e-04\n",
      "Model: \"model_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_6_layer_call_fn, leaky_re_lu_6_layer_call_and_return_conditional_losses, leaky_re_lu_7_layer_call_fn, leaky_re_lu_7_layer_call_and_return_conditional_losses, leaky_re_lu_8_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_55\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model_FILT_02_55\\assets\n",
      " 56%|████████████████████████████████████████▉                                | 56/100 [35:24:56<63:19:21, 5180.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1936e-04 - val_loss: 5.2693e-04\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3080e-04 - val_loss: 5.4063e-04\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1207e-04 - val_loss: 5.2080e-04\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1038e-04 - val_loss: 5.1757e-04\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1559e-04 - val_loss: 5.3641e-04\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1785e-04 - val_loss: 5.1715e-04\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1980e-04 - val_loss: 5.0584e-04\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.3312e-04 - val_loss: 5.0974e-04\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1693e-04 - val_loss: 5.1703e-04\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0503e-04 - val_loss: 5.2049e-04\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.0714e-04 - val_loss: 5.0444e-04\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1998e-04 - val_loss: 5.0650e-04\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1216e-04 - val_loss: 5.0463e-04\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0749e-04 - val_loss: 5.0920e-04\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1118e-04 - val_loss: 4.9293e-04\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0684e-04 - val_loss: 4.9630e-04\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0570e-04 - val_loss: 5.0201e-04\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0855e-04 - val_loss: 5.2740e-04\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1149e-04 - val_loss: 5.0377e-04\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 5.1407e-04 - val_loss: 4.9532e-04\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 5.1675e-04 - val_loss: 5.0643e-04\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 5.2285e-04 - val_loss: 5.2539e-04\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 5.1756e-04 - val_loss: 4.9191e-04\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.0733e-04 - val_loss: 4.9163e-04\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1208e-04 - val_loss: 5.1353e-04\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.0485e-04 - val_loss: 5.1647e-04\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 5.1003e-04 - val_loss: 5.0462e-04\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1943e-04 - val_loss: 5.1526e-04\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2705e-04 - val_loss: 5.2556e-04\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.1716e-04 - val_loss: 5.5306e-04\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.3472e-04 - val_loss: 5.2832e-04\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3270e-04 - val_loss: 5.5240e-04\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.2334e-04 - val_loss: 5.3686e-04\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2854e-04 - val_loss: 5.2612e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1916e-04 - val_loss: 5.0078e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.1068e-04 - val_loss: 5.2249e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1232e-04 - val_loss: 5.2009e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.1531e-04 - val_loss: 5.0766e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1234e-04 - val_loss: 5.0175e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2106e-04 - val_loss: 5.2762e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0965e-04 - val_loss: 5.1406e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.1403e-04 - val_loss: 4.9741e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0805e-04 - val_loss: 5.0836e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2234e-04 - val_loss: 5.1360e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3526e-04 - val_loss: 5.0433e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 5.1169e-04 - val_loss: 5.1249e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1058e-04 - val_loss: 5.1103e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1568e-04 - val_loss: 5.1665e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0576e-04 - val_loss: 5.0730e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0824e-04 - val_loss: 4.9280e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9928e-04 - val_loss: 4.9163e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1400e-04 - val_loss: 4.9849e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0677e-04 - val_loss: 4.8648e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1012e-04 - val_loss: 5.0569e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0292e-04 - val_loss: 4.9737e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 4.9944e-04 - val_loss: 5.0057e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0649e-04 - val_loss: 5.1046e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.1231e-04 - val_loss: 5.1831e-04\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 5.1213e-04 - val_loss: 4.9618e-04\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 5.0263e-04 - val_loss: 5.0757e-04\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2776e-04 - val_loss: 5.1816e-04\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1719e-04 - val_loss: 5.5697e-04\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0308e-04 - val_loss: 4.9242e-04\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0074e-04 - val_loss: 4.9078e-04\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0350e-04 - val_loss: 5.0489e-04\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9752e-04 - val_loss: 5.0627e-04\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0664e-04 - val_loss: 5.0648e-04\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0845e-04 - val_loss: 5.2020e-04\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1257e-04 - val_loss: 5.3611e-04\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1335e-04 - val_loss: 5.0956e-04\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0513e-04 - val_loss: 5.0092e-04\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1958e-04 - val_loss: 5.1490e-04\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1118e-04 - val_loss: 5.1018e-04\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1146e-04 - val_loss: 5.1369e-04\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1055e-04 - val_loss: 5.1469e-04\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1748e-04 - val_loss: 5.1177e-04\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1252e-04 - val_loss: 5.0849e-04\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0674e-04 - val_loss: 5.1598e-04\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9849e-04 - val_loss: 4.9724e-04\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0438e-04 - val_loss: 5.0046e-04\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0694e-04 - val_loss: 5.0838e-04\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2163e-04 - val_loss: 5.2793e-04\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2836e-04 - val_loss: 5.2211e-04\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2390e-04 - val_loss: 4.9646e-04\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0763e-04 - val_loss: 5.2669e-04\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1825e-04 - val_loss: 5.2848e-04\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2089e-04 - val_loss: 5.1610e-04\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0808e-04 - val_loss: 5.0084e-04\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9881e-04 - val_loss: 5.0531e-04\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9757e-04 - val_loss: 5.3479e-04\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.0157e-04 - val_loss: 5.1741e-04\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2725e-04 - val_loss: 5.2205e-04\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2106e-04 - val_loss: 4.9836e-04\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0323e-04 - val_loss: 4.9702e-04\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.9991e-04 - val_loss: 5.0119e-04\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0022e-04 - val_loss: 5.0814e-04\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0670e-04 - val_loss: 4.9942e-04\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.1066e-04 - val_loss: 5.3765e-04\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.0390e-04 - val_loss: 4.9656e-04\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1411e-04 - val_loss: 5.1678e-04\n",
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 256)               2816      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 64)                16448     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,394\n",
      "Trainable params: 19,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████▉                                | 56/100 [35:34:00<27:56:43, 2286.44s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\u001b[0m in \u001b[0;36mtf_buffer\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    198\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2689\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2690\u001b[1;33m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Operation 'Reshape' has no attr named '_read_only_resource_inputs'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7b7683302978>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid_f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdr_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_valid_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1949\u001b[0m               stacklevel=2)\n\u001b[0;32m   1950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1951\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1952\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1953\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1398\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   2058\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \"\"\"\n\u001b[1;32m-> 2060\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m   def interleave(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m   5277\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5278\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5279\u001b[1;33m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   5280\u001b[0m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0;32m   5281\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;31m# There is no graph to add in eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3068\u001b[0m          \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m     \"\"\"\n\u001b[1;32m-> 3070\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   3071\u001b[0m         *args, **kwargs)\n\u001b[0;32m   3072\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3034\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3035\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3036\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3037\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3038\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3292\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   3294\u001b[0m                                    graph_function)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3128\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3129\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3130\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3131\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3132\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1200\u001b[0m         if x is not None)\n\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m     \u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[0;32m    463\u001b[0m       \u001b[1;31m# Check for any resource inputs. If we find any, we update control_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m       \u001b[1;31m# and last_write_to_resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m         \u001b[0mis_read\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mResourceType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mREAD_ONLY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[0minput_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py\u001b[0m in \u001b[0;36m_get_resource_inputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m   \u001b[1;34m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m   \u001b[0mreads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrites\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_read_write_resource_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m   \u001b[0msaturated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m   \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msaturated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps_utils.py\u001b[0m in \u001b[0;36mget_read_write_resource_inputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[0mread_only_input_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mREAD_ONLY_RESOURCE_INPUTS_ATTR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;31m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2689\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2691\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2692\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2693\u001b[0m       \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train ae and extract latent layer after each epoch set\n",
    "\n",
    "for counts in tqdm(range(100)): #this determines the number of epoch sets\n",
    "    history = autoencoder.fit(X_train_f, X_train_f, batch_size = 256, \n",
    "                              epochs = 1000, validation_data = (X_valid_f, X_valid_f), verbose=1)\n",
    "    name = \"02_FILT_SAE_complex_0.2_lr5_10e5_bs256_e1000_ws3_12_20f\"\n",
    "    # convert history object to dataframe and plot rates\n",
    "    training_history = pd.DataFrame(history.history)\n",
    "    plt.plot (training_history);\n",
    "    file_name_0 = name + \"_training_history\" + str(counts)\n",
    "    training_history.to_pickle(file_name_0)\n",
    "    file_name_1 = name + str(counts) + \"_#1.png\"\n",
    "    plt.savefig(file_name_1, dpi=300)\n",
    "    plt.clf()\n",
    "    \n",
    "    # read in latent layer\n",
    "    dr_model = tf.keras.models.Model(inputs  = autoencoder.get_layer('ae_input').input, \n",
    "                                     outputs = autoencoder.get_layer('ae_latent').output)\n",
    "    dr_model.summary()\n",
    "    \n",
    "    # put the validation data through current latent layer model\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for i in range(16000):\n",
    "        z.append(y_valid_f[i])\n",
    "        op = dr_model.predict(np.array([X_valid_f.iloc[i]]))\n",
    "        x.append(op[0][0])\n",
    "        y.append(op[0][1])\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['x'] = x\n",
    "    df['y'] = y\n",
    "    df['z'] = [\"trajectory-\" + str(k) for k in z]\n",
    " \n",
    "    plt.figure(figsize = (8, 6));\n",
    "    fig = sns.scatterplot(x = 'x', y='y', hue='z', data=df, s=10)\n",
    "    file_name_2 = name + str(counts) + \"_#2.png\"\n",
    "    fig.figure.savefig(file_name_2, dpi = 300)\n",
    "    plt.clf()\n",
    "    \n",
    "    #\n",
    "    file_name_3 = '02_ws3_12_20_f'+str(counts)\n",
    "    df.to_pickle(file_name_3)\n",
    "\n",
    "    file_name = 'models/saved_model_FILT_02_' + str(counts)\n",
    "    autoencoder.save(file_name) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "#print(X_train_f.index.to_list() ==  y_train_f.index.to_list())\n",
    "#print(X_valid_f.index.to_list() ==  y_valid_f.index.to_list())\n",
    "\n",
    "# Save index list\n",
    "shuffled_index_train = X_train_f.index.to_list()\n",
    "shuffled_index_valid = X_valid_f.index.to_list()\n",
    "\n",
    "# open a binary file in write mode\n",
    "file = open(\"shufftrain\", \"wb\")\n",
    "# save array to the file\n",
    "np.save(file, shuffled_index_train)\n",
    "# close the file\n",
    "file.close\n",
    "# open a binary file in write mode\n",
    "file = open(\"shuffval\", \"wb\")\n",
    "# save array to the file\n",
    "np.save(file, shuffled_index_valid)\n",
    "# close the file\n",
    "file.close"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_wt-D132-H_trajectory_autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
